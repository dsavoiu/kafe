% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[a4paper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}

\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\floatname{literal-block}{Listing }

\usepackage{enumitem}\setlistdepth{48}

\title{kafe Documentation}
\date{October 16, 2016}
\release{1.2.0}
\author{D. Savoiu, G. Quast}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index_latex::doc}

\begin{quote}

\textbf{kafe} is a data fitting framework designed for use in undergraduate
physics lab courses. It provides a basic Python toolkit for fitting
models to data as well as visualisation of the data and the model function.
It relies on Python packages such as \code{numpy} and \code{matplotlib},
and uses the Python interface to the minimizer \emph{Minuit} contained in the data
analysis framework \emph{ROOT} or in the Python package \emph{iminuit}.
\end{quote}


\chapter{\emph{kafe} Overview}
\label{overview:welcome-to-kafe-the-karlsruhe-fit-environment}\label{overview::doc}\label{overview:kafe-overview}\begin{figure}[htbp]\begin{flushright}
\capstart

\scalebox{0.500000}{\includegraphics{kafe_graphics.png}}
\caption{\emph{Graphical output generated with kafe}.}\end{flushright}\end{figure}

The \emph{kafe} package provides a rather general approach to fitting of
a model function to two-dimensional data points with correlated uncertainties
in both dimensions. The Python API guarantees full flexibility
for data input. Helper functions for file-based input and some
examples are available for own applications.

Applications range from performing a simple average of measurements
to complex situations with both correlated (systematic) and
uncorrelated (statistical) uncertainties on the measurements
of the x and y values described by a non-linear model function
depending on a large number of parameters.

The model function describes the y values as a function of the
x-values and a set of model parameters \{p\}, \emph{y=f(x; \{p\})}. Full
flexibility exists as model functions are implemented as
Python code. Again, examples are provided, but user
implementations are supported as well.

Fitting is based on the \(\chi\)²-method, assuming Gaussian errors and
correlations described by covariance matrices. The level of agreement
between data points and the fit model is expressed in terms of the
\emph{\(\chi\)² probability}, i. e. the probability to find less agreement between
data and model than actually observed. Full access to the covariance
matrix of the - typically correlated - model parameters is provided.

The graphical output visualises the data and the fit model at the
best-fit-point of the parameters and also shows the uncertainty
of the fit model as a light band surrounding the line representing
the model function. Plotting of confidence level contours for pairs
of parameters or profiling of the \(\chi\)² curves for each of the fit
parameters are also provided.


\section{Code Structure}
\label{overview:code-structure}\begin{figure}[htbp]\begin{flushright}
\capstart

\scalebox{0.800000}{\includegraphics{kafeDiagram.jpg}}
\caption{\emph{Code structure of the kafe package}}\end{flushright}\end{figure}

The code of \emph{kafe} is centred around very few classes to handle Data input,
fitting and plotting, as illustrated in the figure on the right-hand side.

Data, their uncertainties, and, optionally, the correlations of the
uncertainties - are passed through the interface of the \emph{kafe} class
{\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}). Input can be included in the Python code
or is read from files in standardised or user-defined formats. The representation
of the data within the {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) class is minimalistic,
consisting of the x and y values and the full covariance matrices of their
uncertainties. Correlated errors between x and y values are not
supported yet, as such use cases are rare.

A helper function, {\hyperref[module_doc:kafe.dataset_tools.build_dataset]{\emph{\code{build\_dataset()}}}} (\autopageref*{module_doc:kafe.dataset_tools.build_dataset}), is available
to transform various error models, like a combination of independent
and correlated errors or common absolute or relative errors, to this
basic format.

Adding a model function, taken either from a prepared set of fit
functions within kafe or from a user's own Python implementation,
results in a {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object, which controls the
minimizer {\hyperref[module_doc:kafe.minuit.Minuit]{\emph{\code{Minuit}}}} (\autopageref*{module_doc:kafe.minuit.Minuit}). Access to the final
results of the fitting procedure is provided by data members of
the \emph{Fit} class.

One or multiple fit objects, i. e. the input data and model
functions(s) at the best-fit point in parameter-space, are
visualised by the class {\hyperref[module_doc:kafe.plot.Plot]{\emph{\code{Plot}}}} (\autopageref*{module_doc:kafe.plot.Plot}) with the help
of \code{matplotlib} functionality. The {\hyperref[module_doc:module-plot]{\emph{\code{plot}}}} (\autopageref*{module_doc:module-plot}) module
also contains functionality to display the model uncertainty by
surrounding the model function at the best-fit values of the parameters
by a light band, the one-\(\sigma\) uncertainty band, which is obtained by
propagation of the uncertainties of the fit parameters taking
into account their correlations.

Two-dimensional contour lines of pairs of parameters
are obtained with the method {\hyperref[module_doc:kafe.fit.Fit.plot_contour]{\emph{\code{plot\_contour()}}}} (\autopageref*{module_doc:kafe.fit.Fit.plot_contour})
of the \code{Fit} class, which internally relies on the
\emph{mncont} method of the \emph{Minuit} package. Contour curves are
obtained from a scan of the \(\chi\)²-function around a fixed value,
where each point on the curve represents the minimum with
respect to all other free parameters in the fit, thus taking
into account the correlation of the considered pair of parameters
with all other parameters of the model.

In a similar way, the method {\hyperref[module_doc:kafe.fit.Fit.plot_profile]{\emph{\code{plot\_profile()}}}} (\autopageref*{module_doc:kafe.fit.Fit.plot_profile})
provides profiled \(\chi\)² curves, i. e. the value of the minimal
\(\chi\)² as a function of one parameter while all other parameters
are allowed to vary.


\section{Fitting in a Nutshell}
\label{overview:fitting-in-a-nutshell}
Fitting with \textbf{kafe} in a nutshell goes like this:
\begin{enumerate}
\item {} 
create a {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) object from your measurement
data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}d} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.}\PYG{p}{,} \PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.23}\PYG{p}{,} \PYG{l+m+mf}{3.45}\PYG{p}{,} \PYG{l+m+mf}{5.62}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}

\item {} 
add errors (uncertainties) to your {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}d}\PYG{o}{.}\PYG{n}{add\PYGZus{}error\PYGZus{}source}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{simple}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}  \PYG{c}{\PYGZsh{} y errors, all +/\PYGZhy{} 0.5}
\end{Verbatim}

\item {} 
import a model function from {\hyperref[module_doc:module-kafe.function_library]{\emph{\code{kafe.function\_library}}}} (\autopageref*{module_doc:module-kafe.function_library}) (or
define one yourself):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{kafe.function\PYGZus{}library} \PYG{k+kn}{import} \PYG{n}{linear\PYGZus{}2par}
\end{Verbatim}

\item {} 
create a {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object from your
{\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) and your model function:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}f} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}d}\PYG{p}{,} \PYG{n}{linear\PYGZus{}2par}\PYG{p}{)}
\end{Verbatim}

\item {} 
do the fit:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}f}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

\item {} 
\emph{(optional)} if you want to see a plot of the result, use the
{\hyperref[module_doc:kafe.plot.Plot]{\emph{\code{Plot}}}} (\autopageref*{module_doc:kafe.plot.Plot}) object:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}p} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Plot}\PYG{p}{(}\PYG{n}{my\PYGZus{}f}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}p}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}p}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

\end{enumerate}


\section{Example}
\label{overview:example}
Only very few lines of Python code are needed to perform fits with
kafe. The snippet of code shown below performs a fit of a quadratic
function to some data points with uncertainties:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{kafe} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{from} \PYG{n+nn}{kafe.function\PYGZus{}library} \PYG{k+kn}{import} \PYG{n}{quadratic\PYGZus{}3par}

\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{} build a Dataset instance:}
\PYG{n}{myDataset} \PYG{o}{=} \PYG{n}{build\PYGZus{}dataset}\PYG{p}{(}
    \PYG{p}{[}\PYG{l+m+mf}{0.05}\PYG{p}{,}\PYG{l+m+mf}{0.36}\PYG{p}{,}\PYG{l+m+mf}{0.68}\PYG{p}{,}\PYG{l+m+mf}{0.80}\PYG{p}{,}\PYG{l+m+mf}{1.09}\PYG{p}{,}\PYG{l+m+mf}{1.46}\PYG{p}{,}\PYG{l+m+mf}{1.71}\PYG{p}{,}\PYG{l+m+mf}{1.83}\PYG{p}{,}\PYG{l+m+mf}{2.44}\PYG{p}{,}\PYG{l+m+mf}{2.09}\PYG{p}{,}\PYG{l+m+mf}{3.72}\PYG{p}{,}\PYG{l+m+mf}{4.36}\PYG{p}{,}\PYG{l+m+mf}{4.60}\PYG{p}{]}\PYG{p}{,}
    \PYG{p}{[}\PYG{l+m+mf}{0.35}\PYG{p}{,}\PYG{l+m+mf}{0.26}\PYG{p}{,}\PYG{l+m+mf}{0.52}\PYG{p}{,}\PYG{l+m+mf}{0.44}\PYG{p}{,}\PYG{l+m+mf}{0.48}\PYG{p}{,}\PYG{l+m+mf}{0.55}\PYG{p}{,}\PYG{l+m+mf}{0.66}\PYG{p}{,}\PYG{l+m+mf}{0.48}\PYG{p}{,}\PYG{l+m+mf}{0.75}\PYG{p}{,}\PYG{l+m+mf}{0.70}\PYG{p}{,}\PYG{l+m+mf}{0.75}\PYG{p}{,}\PYG{l+m+mf}{0.80}\PYG{p}{,}\PYG{l+m+mf}{0.90}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{yabserr}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{0.06}\PYG{p}{,}\PYG{l+m+mf}{0.07}\PYG{p}{,}\PYG{l+m+mf}{0.05}\PYG{p}{,}\PYG{l+m+mf}{0.05}\PYG{p}{,}\PYG{l+m+mf}{0.07}\PYG{p}{,}\PYG{l+m+mf}{0.07}\PYG{p}{,}\PYG{l+m+mf}{0.09}\PYG{p}{,}\PYG{l+m+mf}{0.1}\PYG{p}{,}\PYG{l+m+mf}{0.11}\PYG{p}{,}\PYG{l+m+mf}{0.1}\PYG{p}{,}\PYG{l+m+mf}{0.11}\PYG{p}{,}\PYG{l+m+mf}{0.12}\PYG{p}{,}\PYG{l+m+mf}{0.1}\PYG{p}{]}\PYG{p}{,}
    \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{some data}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
    \PYG{n}{axis\PYGZus{}labels}\PYG{o}{=}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZdl{}x\PYGZdl{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZdl{}y=f(x)\PYGZdl{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{} Create the Fit object}
\PYG{n}{myFit} \PYG{o}{=} \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{myDataset}\PYG{p}{,} \PYG{n}{quadratic\PYGZus{}3par}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Set initial values and error estimates}
\PYG{n}{myFit}\PYG{o}{.}\PYG{n}{set\PYGZus{}parameters}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mf}{0.}\PYG{p}{,} \PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{0.2}\PYG{p}{)}\PYG{p}{,} \PYG{p}{(}\PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Do the Fit}
\PYG{n}{myFit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}

\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{} Create result plots and output them}
\PYG{n}{myPlot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{myFit}\PYG{p}{)}
\PYG{n}{myPlot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{myPlot}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{kafe\PYGZus{}example0.pdf}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)} \PYG{c}{\PYGZsh{} to file}

\PYG{n}{myPlot}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}                    \PYG{c}{\PYGZsh{} to screen}
\end{Verbatim}

The output in text form (also available via various \code{get\_...()} methods
of the {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) class) contains the values of the parameters
at the best-fit point, their correlation matrix and the fit probability.
The example produces the following graphical output:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example0.png}}
\caption{Example: \emph{Data points with one-dimensional error bars compared
to a quadratic model function with} \textbf{kafe}.}\end{figure}

The parametrisation chosen in this example leads to a
strong correlation of the fit parameters. This can
be graphically visualised by adding the following
lines at the end of the example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create and save contour plots}
\PYG{n}{contour1} \PYG{o}{=} \PYG{n}{myFit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.3}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{contour2} \PYG{o}{=} \PYG{n}{myFit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.3}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{contour3} \PYG{o}{=} \PYG{n}{myFit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.3}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{contour1}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{kafe\PYGZus{}example0\PYGZus{}contour1.pdf}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{contour2}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{kafe\PYGZus{}example0\PYGZus{}contour2.pdf}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{contour3}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{kafe\PYGZus{}example0\PYGZus{}contour3.pdf}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

The example code produces two confidence-level contours
for each pair of parameters (with \emph{id=0}, \emph{id=1} and \emph{id=2}),
corresponding to an increase of the \(\chi\)²-function
with respect to the minimum by the values given
in the list passed as the third parameter to the
method \code{myFit.plot\_contour()}. The resulting
graphical representation, as shown below, displays the
39\% contours, corresponding to the one-sigma errors, and
the 68\% contours. The uncertainties on each parameter,
indicated by the error bars, are also shown. They
correspond to the projections of the one-sigma contours
on the axes.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{kafe_example0_contours.png}
\caption{\emph{Contour curves of a pairs of paramters a, b and c
of the example above, calculated with} \textbf{kafe}.}\end{figure}

More and advanced examples - like fitting different models
to one data set, comparison of different data sets with model
functions, averaging of correlated measurements or fits with
a large number of parameters -
are provided as part of the \emph{kafe} distribution and are
described in the section \emph{Examples} below. They may serve as
a starting point for own applications.


\chapter{Installing \emph{kafe}}
\label{installation:installing-kafe}\label{installation::doc}

\section{Requirements}
\label{installation:requirements}
\emph{kafe} needs some additional Python packages. The recommended versions of these are
as follows:
\begin{itemize}
\item {} 
\href{http://www.scipy.org}{SciPy} \textgreater{}= 0.12.0

\item {} 
\href{http://www.numpy.org}{NumPy} \textgreater{}= 1.10.4

\item {} 
\href{http://matplotlib.org}{matplotlib} \textgreater{}= 1.5.0

\end{itemize}

Additionally, a function minimizer is needed. \emph{kafe} implements interfaces to two
function minimizers and requires at least one of them to be installed:
\begin{itemize}
\item {} 
\emph{MINUIT}, which is included in \emph{CERN}`s data analysis package \href{http://root.cern.ch}{ROOT} (\textgreater{}= 5.34), or

\item {} 
\href{https://github.com/iminuit/iminuit}{iminuit} (\textgreater{}= 1.1.1), which is independent of ROOT (this is the default)

\end{itemize}

Finally, \emph{kafe} requires a number of external programs:
\begin{itemize}
\item {} 
Qt4 (\textgreater{}= 4.8.5) and the Python bindings PyQt4 (\textgreater{}= 3.18.1) are needed because \emph{Qt} is the supported
interactive frontend for matplotlib. Other frontends are not supported and may cause unexpected behavior.

\item {} 
A \emph{LaTeX} distribution (tested with \href{https://www.tug.org/texlive/}{TeX Live}), since \emph{LaTeX} is
used by matplotlib for typesetting labels and mathematical expressions.

\item {} 
\href{http://www.nongnu.org/dvipng/}{dvipng} for converting DVI files to PNG graphics

\end{itemize}


\section{Installation notes (Linux)}
\label{installation:installation-notes-linux}
Most of the above packages and programs can be installed through the package manager on most Linux
distributions.

\emph{kafe} was developed for use on Linux desktop systems. Please note that all
commands below should be run as root.


\subsection{Install \emph{NumPy}, \emph{SciPy} and \emph{matplotlib}}
\label{installation:install-numpy-scipy-and-matplotlib}
These packages should be available in the package manager.

In Ubuntu/Mint/Debian:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
apt\PYGZhy{}get install python\PYGZhy{}numpy python\PYGZhy{}scipy python\PYGZhy{}matplotlib
\end{Verbatim}
\end{quote}

In Fedora/RHEL/CentOS:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
yum install numpy scipy python\PYGZhy{}matplotlib
\end{Verbatim}
\end{quote}


\subsection{Install \emph{ROOT}}
\label{installation:install-root}
ROOT and its Python bindings can be obtained via the package manager in
Ubuntu/Mint/Debian:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
apt\PYGZhy{}get install root\PYGZhy{}system libroot\PYGZhy{}bindings\PYGZhy{}python5.34 libroot\PYGZhy{}bindings\PYGZhy{}python\PYGZhy{}dev
\end{Verbatim}
\end{quote}

Or, in Fedora/RHEL/CentOS:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
yum install root root\PYGZhy{}python
\end{Verbatim}
\end{quote}

This setup is usually sufficient. However, you may decide to build ROOT yourself. In this case,
be sure to compile with \emph{PyROOT} support. Additionally, for Python to see the \emph{PyROOT} bindings,
the following environment variables have to be set correctly (:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
export ROOTSYS=\PYGZlt{}directory where ROOT is installed\PYGZgt{}
export LD\PYGZus{}LIBRARY\PYGZus{}PATH=\PYGZdl{}ROOTSYS/lib:\PYGZdl{}PYTHONDIR/lib:\PYGZdl{}LD\PYGZus{}LIBRARY\PYGZus{}PATH
export PYTHONPATH=\PYGZdl{}ROOTSYS/lib:\PYGZdl{}PYTHONPATH
\end{Verbatim}
\end{quote}

For more info, refer to \href{http://root.cern.ch/drupal/content/pyroot}{http://root.cern.ch/drupal/content/pyroot}.


\subsection{Install \emph{iminuit}}
\label{installation:install-iminuit}
\emph{iminuit} is a Python wrapper for the Minuit minimizer which is
independent of ROOT. If compiling/installing ROOT is not possible,
this minimizer can be used instead.

To install the \emph{iminuit} package for Python, the \href{http://www.pip-installer.org/}{Pip installer} is recommended:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
pip install iminuit
\end{Verbatim}
\end{quote}

If you don't have \emph{Pip} installed, get it from the package manager.

In Ubuntu/Mint/Debian, do:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
apt\PYGZhy{}get install python\PYGZhy{}pip
\end{Verbatim}
\end{quote}

In Fedora/RHEL/CentOS, do:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
yum install python\PYGZhy{}pip
\end{Verbatim}
\end{quote}

or use \code{easy\_install} (included with \href{https://pypi.python.org/pypi/setuptools}{setuptools}):
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
easy\PYGZus{}install pip
\end{Verbatim}
\end{quote}

You might also need to install the Python headers for \emph{iminuit} to
compile properly.

In Ubuntu/Mint/Debian, do:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
apt\PYGZhy{}get install libpython2.7\PYGZhy{}dev
\end{Verbatim}
\end{quote}

In Fedora/RHEL/CentOS, do:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
yum install python\PYGZhy{}devel
\end{Verbatim}
\end{quote}

Read the README file for more information on other dependencies
(there should be adequate packages for your Linux distribution
to satisfy these).


\subsection{Install \emph{kafe}}
\label{installation:install-kafe}
To install \emph{kafe} using \emph{Pip}, simply run the helper script as root:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
./install.sh
\end{Verbatim}
\end{quote}

To remove kafe using \emph{Pip}, just run the helper script:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
./uninstall.sh
\end{Verbatim}
\end{quote}

Alternatively, installing using Python's \emph{setuptools} also works, but may not
provide a clean uninstall. Use this method if installing with \emph{Pip} is not possible:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
python setup.py install
\end{Verbatim}
\end{quote}


\section{Installation notes (Windows)}
\label{installation:installation-notes-windows}
\emph{kafe} can be installed under Windows, but requires some additional configuration.

The recommended Python distribution for working with \emph{kafe} under Windows is
\href{https://winpython.github.io/}{WinPython}, which has the advantage that it is
portable and comes with a number of useful pre-installed packages. Particularly,
\emph{NumPy}, \emph{SciPy} and \emph{matplotlib} are all pre-installed in \emph{WinPython}, as are
all \emph{Qt}-related dependencies.

Be sure to install \emph{WinPython} version \textbf{2.7}, since \emph{kafe} does not currently
run under Python 3.


\subsection{Install \emph{iminuit}}
\label{installation:id1}
After installing \emph{WinPython}, start `WinPython Command Prompt.exe' in the
\emph{WinPython} installation directory and run
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
pip install iminuit
\end{Verbatim}
\end{quote}


\subsection{Install \emph{kafe}}
\label{installation:id2}
Now \emph{kafe} can be installed from PyPI by running:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
pip install kafe
\end{Verbatim}
\end{quote}

Alternatively, it may be installed directly using \emph{setuptools}. Just run
the following in `WinPython Command Prompt.exe' after switching to the
directory into which you have downloaded \emph{kafe}:
\begin{quote}

\begin{Verbatim}[commandchars=\\\{\}]
python setup.py install
\end{Verbatim}
\end{quote}


\subsection{Using \emph{kafe} with ROOT under Windows}
\label{installation:using-kafe-with-root-under-windows}
If you want \emph{kafe} to work with ROOT's \code{TMinuit} instead of using
\emph{iminuit}, then ROOT has to be installed. Please note that ROOT releases
for Windows are 32-bit and using the PyROOT bindings on a 64-bit \emph{WinPython}
distribution will not work.

A pre-built verson of ROOT for Windows is available on the ROOT homepage as a Windows
Installer package. The recommended version is
\href{https://root.cern.ch/content/release-53434}{ROOT 5.34}.
During the installation process, select ``Add ROOT to the system PATH for all users''
when prompted. This will set the \code{PATH} environment variable to include
the relevant ROOT directories. The installer also sets the \code{ROOTSYS} environment
variable, which points to the directory where ROOT in installed. By default,
this is \code{C:\textbackslash{}root\_v5.34.34}.

Additionally, for Python to find the \emph{PyROOT} bindings, the \code{PYTHONPATH}
environment variable must be modified to include the \code{bin} subdirectory
of path where ROOT is installed. On Windows 10, assuming ROOT has been installed
in the default directory (\code{C:\textbackslash{}root\_v5.34.34}), this is achieved as follows:
\begin{enumerate}
\item {} 
open the Start Menu and start typing ``environment variables''

\item {} 
select ``Edit the system environment variables''

\item {} 
click the ``Environment Variables...'' button

\item {} 
in the lower part, under ``System variables'', look for the ``PYTHONPATH'' entry

\item {} 
modify/add the ``PYTHONPATH'' entry:
\begin{itemize}
\item {} 
if it doesn't exist, create it by choosing ``New...'',
enter PYTHONPATH as the variable name
and \code{C:\textbackslash{}root\_v5.34.34\textbackslash{}bin} as the variable value

\item {} 
if it already exists and contains only one path, edit it via ``Edit...'' and
insert \code{C:\textbackslash{}root\_v5.34.34\textbackslash{}bin;} at the beginning of the variable value.
(Note the semicolon!)

\item {} 
if the variable already contains several paths, choosing ``Edit...'' will
show a dialog box to manage them. Choose ``New'' and write
\code{C:\textbackslash{}root\_v5.34.34\textbackslash{}bin}

\end{itemize}

\item {} 
close all opened dialogs with ``OK''

\end{enumerate}

Now you may try to \code{import ROOT} in the \emph{WinPython} interpreter to check
if everything has been set up correctly.

For more information please refer to ROOT's official
\href{https://root.cern.ch/pyroot}{PyROOT Guide}.


\chapter{Fit examples, utilities, tips and tricks}
\label{examples:fit-examples-utilities-tips-and-tricks}\label{examples::doc}
A wide range of applications of the \emph{kafe} core and the usage of
the helper functions is exemplified below. All of them
are contained in the sub-directory \code{examples/} of the
\emph{kafe} distribution and are intended to serve as a basis for
user projects.


\section{Example 1 - model comparison}
\label{examples:example-1-model-comparison}
To decide whether a model is adequate to describe a given
set of data, typically several models have to be fit to the
same data. Here is the code for a comparison of a data set
to two models, namely a linear and an exponential function:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} import everything we need from kafe}
\PYG{k+kn}{from} \PYG{n+nn}{kafe} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{c}{\PYGZsh{} additionally, import the two model functions we want to fit:}
\PYG{k+kn}{from} \PYG{n+nn}{kafe.function\PYGZus{}library} \PYG{k+kn}{import} \PYG{n}{linear\PYGZus{}2par}\PYG{p}{,} \PYG{n}{exp\PYGZus{}2par}

\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c}{\PYGZsh{} Load the Dataset from the file}
\PYG{n}{my\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{input\PYGZus{}file}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dataset.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Example Dataset}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create the Fits}
\PYG{n}{my\PYGZus{}fits} \PYG{o}{=} \PYG{p}{[}\PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{exp\PYGZus{}2par}\PYG{p}{)}\PYG{p}{,}
           \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{linear\PYGZus{}2par}\PYG{p}{)}\PYG{p}{]}
\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Do the Fits}
\PYG{k}{for} \PYG{n}{fit} \PYG{o+ow}{in} \PYG{n}{my\PYGZus{}fits}\PYG{p}{:}
\PYG{n}{fit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{} Create the plots, save and show output}
\PYG{n}{my\PYGZus{}plot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{my\PYGZus{}fits}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{my\PYGZus{}fits}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{n}{show\PYGZus{}data\PYGZus{}for}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)} \PYG{c}{\PYGZsh{} show data only once (it\PYGZsq{}s the same data)}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{plot.pdf}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The file \emph{dataset.dat} contains x and y data in the standard \emph{kafe} data
format, where values and errors (and optionally also correlation coefficients)
are given for each axis separately. \emph{\#} indicates a comment line, which
is ignored when reading the data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} axis 0: x
\PYGZsh{} datapoints  uncor. err.
0.957426  3.0e\PYGZhy{}01
2.262212  3.0e\PYGZhy{}01
3.061167  3.0e\PYGZhy{}01
3.607280  3.0e\PYGZhy{}01
4.933100  3.0e\PYGZhy{}01
5.992332  3.0e\PYGZhy{}01
7.021234  3.0e\PYGZhy{}01
8.272489  3.0e\PYGZhy{}01
9.250817  3.0e\PYGZhy{}01
9.757758  3.0e\PYGZhy{}01

\PYGZsh{} axis 1: y
\PYGZsh{} datapoints  uncor. err.
1.672481  2.0e\PYGZhy{}01
1.743410  2.0e\PYGZhy{}01
1.805217  2.0e\PYGZhy{}01
2.147802  2.0e\PYGZhy{}01
2.679615  2.0e\PYGZhy{}01
3.110055  2.0e\PYGZhy{}01
3.723173  2.0e\PYGZhy{}01
4.430122  2.0e\PYGZhy{}01
4.944116  2.0e\PYGZhy{}01
5.698063  2.0e\PYGZhy{}01
\end{Verbatim}

The resulting output is shown below. As can be seen already
from the graph, the exponential model better describes the
data. The \(\chi\)² probability in the printed output shows, however,
that the linear model would be marginally acceptable as well:

\begin{Verbatim}[commandchars=\\\{\}]
linear\PYGZus{}2par
chi2prob 0.052
HYPTEST  accepted (CL 5\PYGZpc{})

exp\PYGZus{}2par
chi2prob 0.96
HYPTEST  accepted (CL 5\PYGZpc{})
\end{Verbatim}
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example1.png}}
\caption{\emph{Output of example1 - compare two models}}\end{figure}

The contour curves of the two fits are shown below
and reflect the large correlations between the fit parameters.
The right plot of the profile \(\chi\)² curve shows that there
is a slight deviation from the parabolic curve in the
fist fit of a non-linear (exponential) function. For more
details on the profiled \(\chi\)² curve see the discussion of
example 3, where the difference is more prominent.
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{kafe_example1_contours.png}
\caption{\emph{Contour curves and a profile \(\chi\)² curve for the fits in example 1}}\end{figure}


\section{Example 2 - two fits and models}
\label{examples:example-2-two-fits-and-models}
Another typical use case consists of comparing two sets
of measurements and the models derived from them. This is
very similar to the previous example with minor
modifications:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}

\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c}{\PYGZsh{} Workflow \PYGZsh{}}
\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}}
\PYG{c}{\PYGZsh{} Load two Datasets from files}
\PYG{n}{my\PYGZus{}datasets} \PYG{o}{=} \PYG{p}{[}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{input\PYGZus{}file}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dataset1.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Example Dataset 1}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
               \PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{input\PYGZus{}file}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dataset2.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Example Dataset 2}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}
\PYG{c}{\PYGZsh{} Create the Fits}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} Do the Fits}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} Create the plots}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}  \PYG{c}{\PYGZsh{} this time without any arguments, i.e. show everything}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

This results in the following output:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example2.png}}
\caption{\emph{Output of example2 - comparison of two linear fits.}}\end{figure}

Although the parameters extracted from the two data sets agree within
errors, the uncertainty bands of the two functions do not overlap
in the region where the data of Dataset 2 are located, so the data
are most probably incompatible with the assumption of an underlying
single linear model.


\section{Example 3 - non-linear fit with non-parabolic errors}
\label{examples:example-3-non-linear-fit-with-non-parabolic-errors}
Very often, when the fit model is a non-linear function
of the parameters, the \(\chi\)² function is not parabolic around
the minimum. A very common example of such a case is an
exponential function prarametrised as shown in the code
fragment below. \emph{Minuit} contains a spacial algorithm, \emph{Minos},
which returns correct errors also in this case. Instead of
using the curvature the minimum, \emph{Minos} follows the
\(\chi\)² function from the minimum to the point where it
crosses the the value \emph{minimum+up}, where \emph{up=1} corresponds
to one standard deviation in \(\chi\)² fits. During the scan of the
\(\chi\)² function at different values of each parameter the minimum
with respect to all other parameters in the fit is determined,
thus making sure that all correlations among the parameters
are taken into account. In case of a parabolic \(\chi\)² function,
the \emph{Minos} errors are identical to those obtained by
the \emph{Hesse} algorithm, but are typically larger or
asymmetric in other cases.

The method \code{kafe.do\_fit()} executes the \emph{Minos} algorithm
after completion of a fit and prints the \emph{Minos} errors if
the deviation from the parabolic result are larger than 5\% .

A graphical visualisation is provided
by the method \code{plot\_profile()} , which
displays the profile \(\chi\)² curve for the parameter
with name or index passed as an argument to the method.

The relevant code fragments and the usage of
the method \code{kafe.fit.plot\_profile()} are
illustrated here:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} definition of the fit function}
\PYG{n+nd}{@ASCII}\PYG{p}{(}\PYG{n}{x\PYGZus{}name}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{t}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{expression}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{A0*exp(\PYGZhy{}t/tau)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Set some LaTeX\PYGZhy{}related parameters for this function}
\PYG{n+nd}{@LaTeX}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{A}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{x\PYGZus{}name}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{t}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
   \PYG{n}{parameter\PYGZus{}names}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{A\PYGZus{}0}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{tau\PYGZob{}\PYGZcb{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
   \PYG{n}{expression}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{A\PYGZus{}0}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{exp(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{frac\PYGZob{}\PYGZhy{}t\PYGZcb{}\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{tau\PYGZcb{})}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nd}{@FitFunction}
\PYG{k}{def} \PYG{n+nf}{exponential}\PYG{p}{(}\PYG{n}{t}\PYG{p}{,} \PYG{n}{A0}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{tau}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{:}
   \PYG{k}{return} \PYG{n}{A0} \PYG{o}{*} \PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{t}\PYG{o}{/}\PYG{n}{tau}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} Load the data, perform fit and plot}
\PYG{n}{my\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{input\PYGZus{}file}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{dataset.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Example Dataset}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{my\PYGZus{}fit} \PYG{o}{=} \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{exponential}\PYG{p}{)}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{my\PYGZus{}plot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{my\PYGZus{}fit}\PYG{p}{)}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZgt{} display contours and profile}
\PYG{n}{contour} \PYG{o}{=} \PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{2.3}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{profile1}\PYG{o}{=}\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}profile}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n}{profile2}\PYG{o}{=}\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}profile}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Show the plots}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The data points were generated using a normalisation factor
of \emph{A0=1.} and a lifetime \emph{\(\tau\)=1.}. The resulting fit output
below demonstrates that this is well reproduced within
uncertainties:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example3.png}}
\caption{\emph{Output of example 3 - Fit of an exponential}}\end{figure}

The contour \emph{A}$_{\text{0}}$ \emph{vs \(\tau\)}, however, is not an ellipse,
as shown in the figure below. The profiled \(\chi\)² curves are
also shown; they deviate significantly from parabolas.
The proper one-sigma uncertainty in the sense of a 68\%
confidence interval is read from these curves by determining
the parameter values where the \(\chi\)² curves cross the horizontal
lines at a value of \(\Delta\)\(\chi\)²=1 above the minimum. The two-sigma
uncertainties correspond to the intersections with the
horizontal line at \(\Delta\)\(\chi\)²=4.
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example3_contours.png}}
\caption{\emph{Contour and profile \(\chi\)² curves of example 3}}\end{figure}

Note: a more parabolic behaviour is achieved
by using the width parameter \(\lambda\)=1/\(\tau\) in the
parametrisation of the exponential function.


\section{Example 4 - average of correlated measurements}
\label{examples:example-4-average-of-correlated-measurements}
The average of a set of measurements can be considered as a fit
of a constant to a set of input data. This example illustrates
how correlated errors are handled in \emph{kafe}.
Measurements can have a common error, which may be absolute
or relative, i. e. depend on the input value.  In more complicated
cases the full covariance matrix must be constructed.

\emph{kafe} has a helper function, \code{build\_dataset()} in module {\hyperref[module_doc:module-fit]{\emph{\code{fit}}}} (\autopageref*{module_doc:module-fit}),
which aids in setting up the covariance matrix and transforming
the input to the default format used by the {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) and {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit})
classes. Two further helper functions in module {\hyperref[module_doc:module-file_tools]{\emph{\code{file\_tools}}}} (\autopageref*{module_doc:module-file_tools})
aid in reading the appropriate information from data files.
\begin{enumerate}
\item {} \begin{description}
\item[{The function  {\hyperref[module_doc:kafe.file_tools.parse_column_data]{\emph{\code{parse\_column\_data()}}}} (\autopageref*{module_doc:kafe.file_tools.parse_column_data}) reads the input values and their}] \leavevmode
independent errors from one file, and optionally covariance
matrices for the x and y axes from additional files. The field ordering
is defined by a control string.

\end{description}

\item {} \begin{description}
\item[{Another helper function, {\hyperref[module_doc:kafe.file_tools.buildDataset_fromFile]{\emph{\code{buildDataset\_fromFile()}}}} (\autopageref*{module_doc:kafe.file_tools.buildDataset_fromFile}), specifies}] \leavevmode
input values or blocks of input data from a single file with
keywords.

\end{description}

\end{enumerate}

The second version needs only very minimal additional user
code, as illustrated here:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{kafe} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{from} \PYG{n+nn}{kafe.function\PYGZus{}library} \PYG{k+kn}{import} \PYG{n}{constant\PYGZus{}1par}
\PYG{k+kn}{from} \PYG{n+nn}{kafe.file\PYGZus{}tools} \PYG{k+kn}{import} \PYG{n}{buildDataset\PYGZus{}fromFile}
\PYG{c}{\PYGZsh{}}
\PYG{c}{\PYGZsh{} =========================================================}
\PYG{n}{fname} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{WData.dat}\PYG{l+s}{\PYGZsq{}}
\PYG{n}{curDataset} \PYG{o}{=} \PYG{n}{buildDataset\PYGZus{}fromFile}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)} \PYG{c}{\PYGZsh{} Dataset from input file}
\PYG{n}{curFit} \PYG{o}{=} \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{curDataset}\PYG{p}{,} \PYG{n}{constant\PYGZus{}1par}\PYG{p}{)}   \PYG{c}{\PYGZsh{} set up the fit object}
\PYG{n}{curFit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{myPlot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{curFit}\PYG{p}{)}
\PYG{n}{myPlot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{myPlot}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{plot.pdf}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{myPlot}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The input file is necessarily more complicated, but holds
the full information on the data set in one place. Refer to
the documentation of the function {\hyperref[module_doc:kafe.file_tools.parse_general_inputfile]{\emph{\code{parse\_general\_inputfile()}}}} (\autopageref*{module_doc:kafe.file_tools.parse_general_inputfile})
in module {\hyperref[module_doc:module-file_tools]{\emph{\code{file\_tools}}}} (\autopageref*{module_doc:module-file_tools}) for a full description of the
currently implemented keywords. The input file for the
averaging example is here:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} Measurements of W boson mass (combined LEP2, 2013)
\PYGZsh{} ==================================================
\PYGZsh{} example to use parse\PYGZus{}general\PYGZus{}inputfile from kafe;
\PYGZsh{}  covariance matrix build from common errors
\PYGZsh{} ==
\PYGZsh{}  Meta data for plotting
*TITLE measurements of the W boson mass
*xLabel number of measurement
*yLabel \PYGZdl{}m\PYGZus{}\PYGZbs{}matrhm\PYGZob{}W\PYGZcb{}\PYGZdl{}
*yUnit GeV/\PYGZdl{}c\PYGZca{}2\PYGZdl{}

\PYGZsh{} x data need not be given for averaging

\PYGZsh{} ============================================================
\PYGZsh{}  Measurements of W mass by ALEPH, DELPI, L3 and OPAL
\PYGZsh{}                              from from LEP2 Report Feb. 2013
\PYGZsh{}  common errors within channels
\PYGZsh{}                     2q2l: 0.021 GeV,
\PYGZsh{}                       4q: 0.044 GeV,
\PYGZsh{}     and between channels: 0.025 GeV
\PYGZsh{} ============================================================

*yData\PYGZus{}SCOV
\PYGZsh{} W\PYGZus{}mass  err     syst    sqrt of the off\PYGZhy{}diagonal
\PYGZsh{} 2q2l channel                           elements of the
80.429  0.055   0.021          \PYGZsh{}         covariance matrix
80.339  0.073   0.021   0.021
80.217  0.068   0.021   0.021 0.021
80.449  0.058   0.021   0.021 0.021 0.021
\PYGZsh{} 4q  channel
80.477  0.069   0.044   0.025 0.025 0.025 0.025 0.044
80.310  0.091   0.044   0.025 0.025 0.025 0.025 0.044 0.044
80.324  0.078   0.044   0.025 0.025 0.025 0.025 0.044 0.044 0.044
80.353  0.068   0.044   0.025 0.025 0.025 0.025 0.044 0.044 0.044 0.044
\end{Verbatim}


\section{Example 5 - non-linear multi-parameter fit (damped oscillation)}
\label{examples:example-5-non-linear-multi-parameter-fit-damped-oscillation}
This example shows the fitting of a more complicated model function
to data collected from a damped harmonic oscillator. In such
non-linear fits, stetting the initial values is sometimes crucial
to let the fit converge at the global minimum. The {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit})
object provides the method {\hyperref[module_doc:kafe.fit.Fit.set_parameters]{\emph{\code{set\_parameters()}}}} (\autopageref*{module_doc:kafe.fit.Fit.set_parameters}) for this
purpose. As the fit function for this problem is not a standard one, it is
defined explicitly making use of the decorator functions available in
\emph{kafe} to provide nice type setting of the parameters. This time,
the function {\hyperref[module_doc:kafe.file_tools.parse_column_data]{\emph{\code{parse\_column\_data()}}}} (\autopageref*{module_doc:kafe.file_tools.parse_column_data}) is used to read
the input, which is given as separate columns with the fields
\begin{quote}

\code{\textless{}time\textgreater{}  \textless{}Amplitude\textgreater{}    \textless{}error on time\textgreater{}   \textless{}error on Amplitude\textgreater{}}
\end{quote}

Here is the example code:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{k+kn}{from} \PYG{n+nn}{kafe} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{from} \PYG{n+nn}{numpy} \PYG{k+kn}{import} \PYG{n}{exp}\PYG{p}{,} \PYG{n}{cos}
\PYG{c}{\PYGZsh{} Model function definition \PYGZsh{}}
\PYG{c}{\PYGZsh{} ===========================}
\PYG{c}{\PYGZsh{} Set an ASCII expression for this function}
\PYG{n+nd}{@ASCII}\PYG{p}{(}\PYG{n}{x\PYGZus{}name}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{t}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{expression}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{A0*exp(\PYGZhy{}t/tau)*cos(omega*t+phi)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Set some LaTeX\PYGZhy{}related parameters for this function}
\PYG{n+nd}{@LaTeX}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{A}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{x\PYGZus{}name}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{t}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
       \PYG{n}{parameter\PYGZus{}names}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{a\PYGZus{}0}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{tau\PYGZob{}\PYGZcb{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{omega\PYGZob{}\PYGZcb{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{varphi\PYGZob{}\PYGZcb{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
       \PYG{n}{expression}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{a\PYGZus{}0}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{exp(\PYGZhy{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{frac\PYGZob{}t\PYGZcb{}\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{tau\PYGZcb{})}\PYG{l+s}{\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s}{\PYGZdq{}}
                  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZbs{}}\PYG{l+s}{cos(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{omega\PYGZob{}\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,t+}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{varphi\PYGZob{}\PYGZcb{})}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nd}{@FitFunction}
\PYG{k}{def} \PYG{n+nf}{damped\PYGZus{}oscillator}\PYG{p}{(}\PYG{n}{t}\PYG{p}{,} \PYG{n}{a0}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{tau}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{omega}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{phi}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{return} \PYG{n}{a0} \PYG{o}{*} \PYG{n}{exp}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{n}{t}\PYG{o}{/}\PYG{n}{tau}\PYG{p}{)} \PYG{o}{*} \PYG{n}{cos}\PYG{p}{(}\PYG{n}{omega}\PYG{o}{*}\PYG{n}{t} \PYG{o}{+} \PYG{n}{phi}\PYG{p}{)}

\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{} Workflow \PYGZsh{}}
\PYG{c}{\PYGZsh{} load the experimental data from a file}
\PYG{n}{my\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{parse\PYGZus{}column\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{damped\PYGZus{}oscillation.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
    \PYG{n}{field\PYGZus{}order}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{x,y,xabserr,yabserr}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Damped Oscillator}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
    \PYG{n}{axis\PYGZus{}labels}\PYG{o}{=}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Time t}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Amplitude}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{} Create the Fit}
\PYG{n}{my\PYGZus{}fit} \PYG{o}{=} \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{damped\PYGZus{}oscillator}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Set the initial values for the fit:}
\PYG{c}{\PYGZsh{}                      a\PYGZus{}0 tau omega phi}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{set\PYGZus{}parameters}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.}\PYG{p}{,} \PYG{l+m+mf}{6.28}\PYG{p}{,} \PYG{l+m+mf}{0.8}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{} Create and output the plots}
\PYG{n}{my\PYGZus{}plot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{my\PYGZus{}fit}\PYG{p}{)}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{}my\PYGZus{}plot.save(\PYGZsq{}plot.pdf\PYGZsq{})}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}correlations}\PYG{p}{(}\PYG{p}{)} \PYG{c}{\PYGZsh{} all contours and profiles}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

This is the resulting output:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example5.png}}
\caption{\emph{Example 5 - fit of the time dependence of the amplitude of a damped harmonic oscillator.}}\end{figure}

The fit function is non-linear, and, furthermore, there ist not a single
local minimum - e.g. a shift in phase of 180° corresonds to a change in
sign of the amplitude, and valid solutions are also obtained for multiples
of the base frequency. Checking of the validity of the fit result is
threfore important. The method
{\hyperref[module_doc:kafe.fit.Fit.plot_correlations]{\emph{\code{plot\_correlations()}}}} (\autopageref*{module_doc:kafe.fit.Fit.plot_correlations}) provides the
contours of all pairs of parameters and the profiles for each of
the parameters and displays them in a matrix-like arrangement.
Distorted contour-ellipses show wether the result is affected
by near-by minima, and the profiles allow to correctly assign
the parameter uncertainties in cases where the parabolic
approximation is not precise enough.
\begin{figure}[htbp]
\centering
\capstart

\scalebox{0.750000}{\includegraphics{kafe_example5_correlations.png}}
\caption{\emph{Confidence contours and profiles for example 5.}}\end{figure}


\section{Example 6 - linear multi-parameter fit}
\label{examples:example-6-linear-multi-parameter-fit}
This example is not much different from the previous one, except that
the fit function, a standard fourth-degree polynomial from the module
{\hyperref[module_doc:module-function_library]{\emph{\code{function\_library}}}} (\autopageref*{module_doc:module-function_library}), is modified to reflect the names of the problem
given, and \code{matplotlib} functionality is used to influence the
output of the plot, e.g. axis names and linear or logarithmic scale.

It is also shown how to circumvent a problem that
often arises when errors depend on the measured values.
For a counting rate, the (statistical) error is typically estimated
as the square root of the (observed) number of entries in each bin.
For large numbers of entries, this is not a problem,
but for small numbers, the correlation between the observed
number of entries and the error derived from it leads to a
bias when fitting functions to the data. This problem can be
avoided by iterating the fit procedure:

In a pre-fit, a first approximation of the model function is
determined, which is then used to calculate
the expected errors, and the original errors are
replaced before performing the final fit. Note that the numbers
of entries in the bins must be sufficiently large to justify
a replacement of the (asymmetric) Poisson uncertainties by
the symmetric uncertainties implied by the \(\chi\)²-method.

The implementation of this  procedure needs accesses some
more fundamental methods of the \emph{Dataset}, \emph{Fit} and
\emph{FitFunction} classes. The code shown below demonstrates
how this can be done with \emph{kafe}, using some of its lower-level,
internal interfaces:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{kafe.function\PYGZus{}library} \PYG{k+kn}{import} \PYG{n}{poly4}
\PYG{c}{\PYGZsh{} modify function\PYGZsq{}s independent variable name to reflect its nature:}
\PYG{n}{poly4}\PYG{o}{.}\PYG{n}{x\PYGZus{}name} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{x=cos(t)}\PYG{l+s}{\PYGZsq{}}
\PYG{n}{poly4}\PYG{o}{.}\PYG{n}{latex\PYGZus{}x\PYGZus{}name} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{x=}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{cos(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{theta)}\PYG{l+s}{\PYGZsq{}}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}

\PYG{c}{\PYGZsh{} Set the axis labels appropriately}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{axis\PYGZus{}labels} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZdl{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{cos(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{theta)\PYGZdl{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{counting rate}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} load the experimental data from a file}
\PYG{n}{my\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{parse\PYGZus{}column\PYGZus{}data}\PYG{p}{(}
  \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{counting\PYGZus{}rate.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}
  \PYG{n}{field\PYGZus{}order}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{x,y,yabserr}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
  \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Counting Rate per Angle}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{} pre\PYGZhy{}fit}
\PYG{c}{\PYGZsh{} error for bins with zero contents is set to 1.}
\PYG{n}{covmat} \PYG{o}{=} \PYG{n}{my\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{get\PYGZus{}cov\PYGZus{}mat}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{covmat}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{n}{covmat}\PYG{p}{[}\PYG{n}{i}\PYG{p}{,} \PYG{n}{i}\PYG{p}{]} \PYG{o}{==} \PYG{l+m+mf}{0.}\PYG{p}{:}
        \PYG{n}{covmat}\PYG{p}{[}\PYG{n}{i}\PYG{p}{,} \PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mf}{1.}
\PYG{n}{my\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{set\PYGZus{}cov\PYGZus{}mat}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{covmat}\PYG{p}{)} \PYG{c}{\PYGZsh{} write it back}

\PYG{c}{\PYGZsh{} Create the Fit}
\PYG{n}{my\PYGZus{}fit} \PYG{o}{=} \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}dataset}\PYG{p}{,} \PYG{n}{poly4}\PYG{p}{)}
\PYG{c}{\PYGZsh{}            fit\PYGZus{}label=\PYGZdq{}Linear Regression \PYGZdq{} + dataset.data\PYGZus{}label[\PYGZhy{}1])}

\PYG{c}{\PYGZsh{} perform an initial fit with temporary errors (minimal output)}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{call\PYGZus{}minimizer}\PYG{p}{(}\PYG{n}{final\PYGZus{}fit}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{)}

\PYG{c}{\PYGZsh{} set errors using model at pre\PYGZhy{}fit parameter values:}
\PYG{c}{\PYGZsh{}       sigma\PYGZus{}i\PYGZca{}2=cov[i, i]=n(x\PYGZus{}i)}
\PYG{n}{fdata} \PYG{o}{=} \PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{fit\PYGZus{}function}\PYG{o}{.}\PYG{n}{evaluate}\PYG{p}{(}\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{xdata}\PYG{p}{,}
                                   \PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{current\PYGZus{}parameter\PYGZus{}values}\PYG{p}{)}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{fill\PYGZus{}diagonal}\PYG{p}{(}\PYG{n}{covmat}\PYG{p}{,} \PYG{n}{fdata}\PYG{p}{)}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{current\PYGZus{}cov\PYGZus{}mat} \PYG{o}{=} \PYG{n}{covmat}  \PYG{c}{\PYGZsh{} write new covariance matrix}
\PYG{c}{\PYGZsh{}\PYGZsh{}\PYGZsh{} end pre\PYGZhy{}fit \PYGZhy{} rest is as usual}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Create the plots and ==}
\PYG{n}{my\PYGZus{}plot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{my\PYGZus{}fit}\PYG{p}{)}
\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{} set the axis labels}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{axis\PYGZus{}labels} \PYG{o}{=} \PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZdl{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{cos(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{theta)\PYGZdl{}}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{counting rate}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}
\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{} set scale linear / log}
\PYG{n}{my\PYGZus{}plot}\PYG{o}{.}\PYG{n}{axes}\PYG{o}{.}\PYG{n}{set\PYGZus{}yscale}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{linear}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

This is the resulting output:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example6.png}}
\caption{\emph{Output of example 6 - counting rate.}}\end{figure}


\section{Example 7 - another non-linear multi-parameter fit (double-slit spectrum)}
\label{examples:example-7-another-non-linear-multi-parameter-fit-double-slit-spectrum}
Again, not much new in this example, except that the
model is now very non-linear, the intensity distribution
of light after passing through a double-slit. The
non-standard model definition again makes use of the
decorator mechanism to provide nice output - the decorators
(expressions beginning with `@') can safely be omitted if \emph{LaTeX}
output is not needed. Setting of appropriate initial
conditions is absolutely mandatory for this example,
because there  exist many local minima of the \(\chi\)² function.

Another problem becomes obvious when carefully inspecting
the fit function definition: only two of the three parameters g,
b or k can be determined, and therefore one must be kept fixed,
or an external constraint must be applied.
Failing to do so will result in large, correlated errors
on the parameters g, b and k as an indication of the problem.

Fixing parameters of a model function is achieved by the method
{\hyperref[module_doc:kafe.fit.Fit.fix_parameters]{\emph{\code{fix\_parameters()}}}} (\autopageref*{module_doc:kafe.fit.Fit.fix_parameters}), and a constraint within a given uncertainty
is achieved by the method {\hyperref[module_doc:kafe.fit.Fit.constrain_parameters]{\emph{\code{constrain\_parameters()}}}} (\autopageref*{module_doc:kafe.fit.Fit.constrain_parameters})
of the {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) class.

Here are the interesting pieces of code:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} Model function definition \PYGZsh{}}
\PYG{c}{\PYGZsh{} Set an ASCII expression for this function}
\PYG{n+nd}{@ASCII}\PYG{p}{(}\PYG{n}{x\PYGZus{}name}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{x}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{expression}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I0*(sin(k/2*b*sin(x))/(k/2*b*sin(x))}\PYG{l+s}{\PYGZdq{}}
                              \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{*cos(k/2*g*sin(x)))\PYGZca{}2}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Set some LaTeX\PYGZhy{}related parameters for this function}
\PYG{n+nd}{@LaTeX}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{x\PYGZus{}name}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{alpha\PYGZob{}\PYGZcb{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
       \PYG{n}{parameter\PYGZus{}names}\PYG{o}{=}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{I\PYGZus{}0}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{g}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{k}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{,}
       \PYG{n}{expression}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{I\PYGZus{}0}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{left(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{frac\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{sin(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{frac\PYGZob{}k\PYGZcb{}\PYGZob{}2\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,b}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{sin\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{alpha\PYGZcb{})\PYGZcb{}}\PYG{l+s}{\PYGZdq{}}
                  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{frac\PYGZob{}k\PYGZcb{}\PYGZob{}2\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,b}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{sin\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{alpha\PYGZcb{}\PYGZcb{}}\PYG{l+s}{\PYGZdq{}}
                  \PYG{l+s}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{cos(}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{frac\PYGZob{}k\PYGZcb{}\PYGZob{}2\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,g}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{,}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{sin\PYGZob{}}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{alpha\PYGZcb{})}\PYG{l+s+se}{\PYGZbs{}\PYGZbs{}}\PYG{l+s}{right)\PYGZca{}2}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n+nd}{@FitFunction}
\PYG{k}{def} \PYG{n+nf}{double\PYGZus{}slit}\PYG{p}{(}\PYG{n}{alpha}\PYG{p}{,} \PYG{n}{I0}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{b}\PYG{o}{=}\PYG{l+m+mf}{10e\PYGZhy{}6}\PYG{p}{,} \PYG{n}{g}\PYG{o}{=}\PYG{l+m+mf}{20e\PYGZhy{}6}\PYG{p}{,} \PYG{n}{k}\PYG{o}{=}\PYG{l+m+mf}{1.e7}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{k\PYGZus{}half\PYGZus{}sine\PYGZus{}alpha} \PYG{o}{=} \PYG{n}{k}\PYG{o}{/}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{alpha}\PYG{p}{)}  \PYG{c}{\PYGZsh{} helper variable}
    \PYG{n}{k\PYGZus{}b} \PYG{o}{=} \PYG{n}{k\PYGZus{}half\PYGZus{}sine\PYGZus{}alpha} \PYG{o}{*} \PYG{n}{b}
    \PYG{n}{k\PYGZus{}g} \PYG{o}{=} \PYG{n}{k\PYGZus{}half\PYGZus{}sine\PYGZus{}alpha} \PYG{o}{*} \PYG{n}{g}
    \PYG{k}{return} \PYG{n}{I0} \PYG{o}{*} \PYG{p}{(}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{k\PYGZus{}b}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{k\PYGZus{}b}\PYG{p}{)} \PYG{o}{*} \PYG{n}{cos}\PYG{p}{(}\PYG{n}{k\PYGZus{}g}\PYG{p}{)}\PYG{p}{)}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}

\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}

\PYG{c}{\PYGZsh{} Set the initial values for the fit}
\PYG{c}{\PYGZsh{}                      I   b      g        k}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{set\PYGZus{}parameters}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{20e\PYGZhy{}6}\PYG{p}{,} \PYG{l+m+mf}{50e\PYGZhy{}6}\PYG{p}{,} \PYG{l+m+mf}{9.67e6}\PYG{p}{)}\PYG{p}{)}
\PYG{c}{\PYGZsh{} fix one of the (redundant) parameters, here \PYGZsq{}k\PYGZsq{}}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{fix\PYGZus{}parameters}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{k}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}

\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

If the parameter \emph{k} in the example above has a (known) uncertainty,
is is more appropriate to constrain it within its uncertainty (which
may be known from an independent measurement or from the specifications
of the laser used in the experiment). To take into account a
wave number \emph{k} known with a precision of 10`000 the
last line in the example above should be replaced by:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{n}{my\PYGZus{}fit}\PYG{o}{.}\PYG{n}{constrain\PYGZus{}parameters}\PYG{p}{(}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{k}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{9.67e6}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.e4}\PYG{p}{]}\PYG{p}{)}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

This is the resulting output:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example7.png}}
\caption{\emph{Example 7 - fit of the intensity distribution of light behind a double slit with fixed or constrained wave length.}}\end{figure}


\section{Example 8 - fit of a Breit-Wigner resonance to data with correlated errors}
\label{examples:example-8}\label{examples:example-8-fit-of-a-breit-wigner-resonance-to-data-with-correlated-errors}
This example illustrates how to define the data and the fit function
in a single file - provided by the helper function {\hyperref[module_doc:kafe.file_tools.buildFit_fromFile]{\emph{\code{buildFit\_fromFile()}}}} (\autopageref*{module_doc:kafe.file_tools.buildFit_fromFile})
in module {\hyperref[module_doc:module-file_tools]{\emph{\code{file\_tools}}}} (\autopageref*{module_doc:module-file_tools}). Parsing of the input file is done by the
function {\hyperref[module_doc:kafe.file_tools.parse_general_inputfile]{\emph{\code{parse\_general\_inputfile()}}}} (\autopageref*{module_doc:kafe.file_tools.parse_general_inputfile}), which had already been introduced
in Example 4. The definition of the fit function as \emph{Python} code
including the \emph{kafe} decorators in the input file, however, is new.
Note: because spaces are used to to separate data  fields in the
input file, spaces needed for proper \emph{Python} indentation have to be
replaced by `\textasciitilde{}'. The last key in the file defines the start values
of the parameters and their initial ranges.

The advantage of this approach is the location of all data
and the fit model in one place, which is strictly separated
from the \emph{Python} code. The \emph{Python} code below is thus very general
and can handle a large large variety of problems without
modification (except for the file name, which could easily be
passed on the command line):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{kafe} \PYG{k+kn}{import} \PYG{o}{*}
\PYG{k+kn}{from} \PYG{n+nn}{kafe.file\PYGZus{}tools} \PYG{k+kn}{import} \PYG{n}{buildFit\PYGZus{}fromFile}
\PYG{c}{\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n}{fname} \PYG{o}{=} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{LEP\PYGZhy{}Data.dat}\PYG{l+s}{\PYGZsq{}}
\PYG{c}{\PYGZsh{} initialize fit object from file}
\PYG{n}{BWfit} \PYG{o}{=} \PYG{n}{buildFit\PYGZus{}fromFile}\PYG{p}{(}\PYG{n}{fname}\PYG{p}{)}
\PYG{n}{BWfit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{}}
\PYG{n}{BWplot} \PYG{o}{=} \PYG{n}{Plot}\PYG{p}{(}\PYG{n}{BWfit}\PYG{p}{)}
\PYG{n}{BWplot}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{BWplot}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{plot.pdf}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{BWplot}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The magic happens in the input file, which now has to provide
all the information needed to perform the fit:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} Measurements of hadronic Z cross sections at LEP
\PYGZsh{} \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYGZsh{} this file is to be parsed with
\PYGZsh{}          kafe.file\PYGZus{}tools.buildFit\PYGZus{}fromFile()

\PYGZsh{}  Meta data for plotting
*TITLE  LEP Hadronic Cross Section (\PYGZdl{}\PYGZbs{}sigma\PYGZca{}0\PYGZus{}\PYGZbs{}mathrm\PYGZob{}had\PYGZcb{}\PYGZdl{})
*BASENAME example8\PYGZus{}BreitWigner
*xLabel \PYGZdl{}E\PYGZus{}\PYGZob{}CM\PYGZcb{}\PYGZdl{}
*xUnit  \PYGZdl{}\PYGZbs{}mathrm\PYGZob{}GeV\PYGZcb{}\PYGZdl{}
*yLabel \PYGZdl{}\PYGZbs{}sigma\PYGZca{}0\PYGZus{}\PYGZob{}\PYGZbs{}mathrm\PYGZob{}had\PYGZcb{}\PYGZcb{}\PYGZdl{}
*yUnit  \PYGZdl{}\PYGZbs{}mathrm\PYGZob{}nb\PYGZcb{}\PYGZdl{}

\PYGZsh{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYGZsh{} DATA: average of hadronic cross sections measured by
\PYGZsh{}  ALEPH, DELPHI, L3 and OPAL around 7 energy points at the Z resonance
\PYGZsh{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}

\PYGZsh{} CMenergy E err
*xData
   88.387  0.005
   89.437  0.0015
   90.223  0.005
   91.238  0.003
   92.059  0.005
   93.004  0.0015
   93.916  0.005

\PYGZsh{} Centre\PYGZhy{}of\PYGZhy{}mass energy has a common uncertainty
*xAbsCor 0.0017

\PYGZsh{} sig\PYGZca{}0\PYGZus{}h  sig err     \PYGZsh{}  rad.cor  sig\PYGZus{}h measured
*yData
   6.803   0.036      \PYGZsh{}  1.7915    5.0114
   13.965  0.013      \PYGZsh{}  4.0213    9.9442
   26.113  0.075      \PYGZsh{}  7.867    18.2460
   41.364  0.010      \PYGZsh{}  10.8617  30.5022
   27.535  0.088      \PYGZsh{}  3.9164   23.6187
   13.362  0.015      \PYGZsh{} \PYGZhy{}0.6933   14.0552
    7.302  0.045      \PYGZsh{} \PYGZhy{}1.8181    9.1196

\PYGZsh{} cross\PYGZhy{}sections have a common relative error
*yRelCor 0.0007

*FITLABEL Breit\PYGZhy{}Wigner\PYGZhy{}Fit \PYGZbs{}, \PYGZob{}\PYGZbs{}large\PYGZob{}(with\PYGZti{}s\PYGZhy{}dependent\PYGZti{}width)\PYGZcb{}\PYGZcb{}

*FitFunction
\PYGZsh{} Breit\PYGZhy{}Wigner with s\PYGZhy{}dependent width
@ASCII(name=\PYGZsq{}sigma\PYGZsq{}, expression=\PYGZsq{}s0*x\PYGZca{}2*G\PYGZca{}2/[(E\PYGZca{}2\PYGZhy{}M\PYGZca{}2)\PYGZca{}2+(E\PYGZca{}4*G\PYGZca{}2/M\PYGZca{}2)]\PYGZsq{})
@LaTeX(name=\PYGZsq{}\PYGZbs{}sigma\PYGZsq{}, parameter\PYGZus{}names=(\PYGZsq{}\PYGZbs{}\PYGZbs{}sigma\PYGZca{}0\PYGZsq{}, \PYGZsq{}M\PYGZus{}Z\PYGZsq{},\PYGZsq{}\PYGZbs{}\PYGZbs{}Gamma\PYGZus{}Z\PYGZsq{}),
expression=\PYGZsq{}\PYGZbs{}\PYGZbs{}frac\PYGZob{}\PYGZbs{}\PYGZbs{}sigma\PYGZca{}0\PYGZbs{}\PYGZbs{}, M\PYGZus{}Z\PYGZca{}2\PYGZbs{}\PYGZbs{}Gamma\PYGZca{}2\PYGZcb{}\PYGZsq{}
                 \PYGZsq{}\PYGZob{}((E\PYGZca{}2\PYGZhy{}M\PYGZus{}Z\PYGZca{}2)\PYGZca{}2+(E\PYGZca{}4\PYGZbs{}\PYGZbs{}Gamma\PYGZca{}2 / M\PYGZus{}Z\PYGZca{}2))\PYGZcb{}\PYGZsq{})
@FitFunction
def BreitWigner(E, s0=41.0, M=91.2, G=2.5):
    return s0*E*E*G*G/((E*E\PYGZhy{}M*M)**2+(E**4*G*G/(M*M)))


*InitialParameters  \PYGZsh{} initial values and range
41.  0.5
91.2 0.1
2.5  0.1

\PYGZsh{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{} official results (LEP Electroweak Working Group):
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{} s0=41.540+/\PYGZhy{}0.037nb  M=91.1875+/\PYGZhy{}0.0021GeV/c\PYGZca{}2  G=2.4952+/\PYGZhy{}0.0023 GeV
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}  uses all decay modes of the Z and full cross\PYGZhy{}section list
\PYGZsh{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}
\end{Verbatim}

Here is the output:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_BreitWignerFit.png}}
\caption{\emph{Output of example 8 - Fit of a Breit-Wigner function.}}\end{figure}

This example also contains a code snippet demonstrating how to plot
contours by calling the {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object's
{\hyperref[module_doc:kafe.fit.Fit.plot_contour]{\emph{\code{plot\_contour()}}}} (\autopageref*{module_doc:kafe.fit.Fit.plot_contour}) method. This is the code:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} plot pairs of contours at 1 sigma, 68\PYGZpc{}, 2 sigma and 95\PYGZpc{}}
\PYG{n}{cont\PYGZus{}fig1} \PYG{o}{=} \PYG{n}{BWfit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{2.3}\PYG{p}{,}\PYG{l+m+mf}{4.}\PYG{p}{,}\PYG{l+m+mf}{5.99}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{cont\PYGZus{}fig2} \PYG{o}{=} \PYG{n}{BWfit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{2.3}\PYG{p}{,}\PYG{l+m+mf}{4.}\PYG{p}{,}\PYG{l+m+mf}{5.99}\PYG{p}{]}\PYG{p}{)}
\PYG{n}{cont\PYGZus{}fig3} \PYG{o}{=} \PYG{n}{BWfit}\PYG{o}{.}\PYG{n}{plot\PYGZus{}contour}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{dchi2}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{2.3}\PYG{p}{,}\PYG{l+m+mf}{4.}\PYG{p}{,}\PYG{l+m+mf}{5.99}\PYG{p}{]}\PYG{p}{)}
\PYG{c}{\PYGZsh{} save to files}
\PYG{n}{cont\PYGZus{}fig1}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{kafe\PYGZus{}BreitWignerFit\PYGZus{}contour12.pdf}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{cont\PYGZus{}fig2}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{kafe\PYGZus{}BreitWignerFit\PYGZus{}contour13.pdf}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{cont\PYGZus{}fig3}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{kafe\PYGZus{}BreitWignerFit\PYGZus{}contour23.pdf}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

The resulting pictures show that parameter correlations are
relatively small:
\begin{figure}[htbp]
\centering
\capstart

\includegraphics{kafe_BreitWignerFit_contours.png}
\caption{\emph{Contours generated in example 8 - Fit of a Breit-Wigner function.}}\end{figure}


\section{Example 9 - fit of a function to histogram data}
\label{examples:example-9-fit-of-a-function-to-histogram-data}
This example brings us to the limit of what is currently
possible with \emph{kafe}. Here, the data represent the
center of a histogram bins ad the number of entries, \(n_i\),
in each bin. The (statistical) error is typically estimated
as the square root of the (observed) number of entries in each bin.
For large numbers of entries, this is not a problem,
but for small numbers, especially for bins with 0 entries,
the correlation between the observed number of entries and
the error derived from it leads to a bias when fitting
functions to the histogram data. In particular, bins with
zero entries cannot be handled in the \(\chi\)²-function, and are
typically omitted to cure the problem.  However, a bias
remains, as bins with downward fluctuations of the
observed numbers of events get assigned smaller errors
and hence larger weights in the fitting procedure - leading
to the aforementioned bias.

These problems are avoided by using a likelihood method for
such use cases, where the Poisson distribution of the uncertainties
and their dependence on the values of the fit model is properly
taken into account. However, the \(\chi\)²-method can be saved to some
extend if the fitting procedure is iterated. In a pre-fit, a
first approximation of the model function is determined, where
the error in bins with zero entries is set to one. The model
function determined from the pre-fit is then used to calculate
the expected errors for each bin, and the original errors are
replaced before performing the final fit. Note that the numbers
of entries in the bins must be sufficiently large to justify
a replacement of the (asymmetric) Poisson uncertainties by
the symmetric uncertainties implied by the \(\chi\)²-method.

The code shown below demonstrates
how to get a grip on such more complex procedures with
more fundamental methods of the \emph{Dataset}, \emph{Fit} and
\emph{FitFunction} classes:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{c}{\PYGZsh{} Load Dataset from file}
\PYG{n}{hdataset} \PYG{o}{=} \PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{input\PYGZus{}file}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{hdataset.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{title}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Data for example 9}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{} error for bins with zero contents is set to 1.}
\PYG{n}{covmat} \PYG{o}{=} \PYG{n}{hdataset}\PYG{o}{.}\PYG{n}{get\PYGZus{}cov\PYGZus{}mat}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n+nb}{len}\PYG{p}{(}\PYG{n}{covmat}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{n}{covmat}\PYG{p}{[}\PYG{n}{i}\PYG{p}{,} \PYG{n}{i}\PYG{p}{]} \PYG{o}{==} \PYG{l+m+mf}{0.}\PYG{p}{:}
        \PYG{n}{covmat}\PYG{p}{[}\PYG{n}{i}\PYG{p}{,} \PYG{n}{i}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mf}{1.}
\PYG{n}{hdataset}\PYG{o}{.}\PYG{n}{set\PYGZus{}cov\PYGZus{}mat}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{covmat}\PYG{p}{)} \PYG{c}{\PYGZsh{} write it back}

\PYG{c}{\PYGZsh{} Create the Fit instance}
\PYG{n}{hfit} \PYG{o}{=} \PYG{n}{Fit}\PYG{p}{(}\PYG{n}{hdataset}\PYG{p}{,} \PYG{n}{gauss}\PYG{p}{,} \PYG{n}{fit\PYGZus{}label}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Fit of a Gaussian to histogram data}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\PYG{c}{\PYGZsh{}}
\PYG{c}{\PYGZsh{} perform an initial fit with temporary errors (minimal output)}
\PYG{n}{hfit}\PYG{o}{.}\PYG{n}{call\PYGZus{}minimizer}\PYG{p}{(}\PYG{n}{final\PYGZus{}fit}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{,} \PYG{n}{verbose}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{)}
\PYG{c}{\PYGZsh{}}
\PYG{c}{\PYGZsh{}re\PYGZhy{}set errors using model at pre\PYGZhy{}fit parameter values:}
\PYG{c}{\PYGZsh{}        sigma\PYGZus{}i\PYGZca{}2=cov[i, i]=n(x\PYGZus{}i)}
\PYG{n}{fdata}\PYG{o}{=}\PYG{n}{hfit}\PYG{o}{.}\PYG{n}{fit\PYGZus{}function}\PYG{o}{.}\PYG{n}{evaluate}\PYG{p}{(}\PYG{n}{hfit}\PYG{o}{.}\PYG{n}{xdata}\PYG{p}{,} \PYG{n}{hfit}\PYG{o}{.}\PYG{n}{current\PYGZus{}parameter\PYGZus{}values}\PYG{p}{)}
\PYG{n}{np}\PYG{o}{.}\PYG{n}{fill\PYGZus{}diagonal}\PYG{p}{(}\PYG{n}{covmat}\PYG{p}{,} \PYG{n}{fdata}\PYG{p}{)}
\PYG{n}{hfit}\PYG{o}{.}\PYG{n}{current\PYGZus{}cov\PYGZus{}mat} \PYG{o}{=} \PYG{n}{covmat} \PYG{c}{\PYGZsh{} write back new covariance matrix}
\PYG{c}{\PYGZsh{}}
\PYG{c}{\PYGZsh{} now do final fit with full output}
\PYG{n}{hfit}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\PYG{c}{\PYGZsh{} and create, draw, save and show plot}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

Here is the output, which shows that the parameters of the
standard normal distribution, from which the data were generated,
are reproduced well by the fit result:
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example9.png}}
\caption{\emph{Output of example 9 - Fit of a Gaussian distribution to histogram data}}\end{figure}


\section{Example 10 - plotting with \emph{kafe}: properties of a Gauss curve}
\label{examples:example-10-plotting-with-kafe-properties-of-a-gauss-curve}
This example shows how to access the \emph{kafe} plot objects
to annotate plots with \code{matplotlib} functionality.

A dummy object {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) is
created with points lying exactly on a Gaussian curve.
The {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) will then converge toward
that very same Gaussian. When plotting, the data points
used to ``support'' the curve can be omitted.
\begin{figure}[htbp]
\centering
\capstart

\scalebox{1.000000}{\includegraphics{kafe_example10.png}}
\caption{\emph{Output of example 10 - properties of a Gauss curve.}}\end{figure}


\chapter{\emph{kafe} reference}
\label{module_doc:kafe-reference}\label{module_doc::doc}
This page contains documentation which was automatically extracted from
docstrings in the source code. All major classes, methods and functions
provided by \emph{kafe} are documented here. For further information, or if in
doubt about the exact functionality, users are invited to consult the source
code itself.


\section{\emph{kafe} in a nutshell}
\label{module_doc:module-kafe.__init__}\label{module_doc:kafe-in-a-nutshell}\index{kafe.\_\_init\_\_ (module)}
\textbf{kafe} \emph{-- a Python package for fitting and plotting for use in physics lab
courses.}

This Python package allows fitting of user-defined functions to data. A dataset
is represented by a \emph{Dataset} object which stores measurement data as \emph{NumPy}
arrays. The uncertainties (errors) of the data are also stored in the \emph{Dataset}
as a list of one or more \emph{ErrorSource} objects, each of which stores a part of
the uncertainty information as a so-called \emph{covariance matrix} (also called an
\emph{error matrix}). This allows \textbf{kafe} to work with uncertainties of different
kinds for a \emph{Dataset}, particularly when there is a degree of correlation
between the uncertainties of the datapoints.

Fitting with \textbf{kafe} in a nutshell goes like this:
\begin{quote}
\begin{enumerate}
\item {} 
create a \emph{Dataset} object from your measurement data

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}d} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.}\PYG{p}{,} \PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.23}\PYG{p}{,} \PYG{l+m+mf}{3.45}\PYG{p}{,} \PYG{l+m+mf}{5.62}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}
\begin{enumerate}
\setcounter{enumi}{1}
\item {} 
add errors (uncertainties) to your \emph{Dataset}

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}d}\PYG{o}{.}\PYG{n}{add\PYGZus{}error\PYGZus{}source}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{simple}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}  \PYG{c}{\PYGZsh{} y errors, all +/\PYGZhy{} 0.5}
\end{Verbatim}
\begin{enumerate}
\setcounter{enumi}{2}
\item {} 
import a model function from \emph{kafe.function\_library} (or define one
yourself)

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k+kn}{from} \PYG{n+nn}{kafe.function\PYGZus{}library} \PYG{k+kn}{import} \PYG{n}{linear\PYGZus{}2par}
\end{Verbatim}
\begin{enumerate}
\setcounter{enumi}{3}
\item {} 
create a \emph{Fit} object from your \emph{Dataset} and your model function

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}f} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Fit}\PYG{p}{(}\PYG{n}{my\PYGZus{}d}\PYG{p}{,} \PYG{n}{linear\PYGZus{}2par}\PYG{p}{)}
\end{Verbatim}
\begin{enumerate}
\setcounter{enumi}{4}
\item {} 
do the fit

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}f}\PYG{o}{.}\PYG{n}{do\PYGZus{}fit}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}
\begin{enumerate}
\setcounter{enumi}{5}
\item {} 
\emph{(optional)} if you want to see a plot of the result, use the \emph{Plot}
object

\end{enumerate}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}p} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Plot}\PYG{p}{(}\PYG{n}{my\PYGZus{}f}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}p}\PYG{o}{.}\PYG{n}{plot\PYGZus{}all}\PYG{p}{(}\PYG{p}{)}
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}p}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}
\end{quote}

For more in-depth information on \textbf{kafe}`s features, feel free to consult the
documentation.


\section{Main modules: \texttt{dataset}, \texttt{fit} and \texttt{plot}}
\label{module_doc:main-modules-dataset-fit-and-plot}

\subsection{\texttt{Dataset}: Collection of data points (\texttt{kafe.dataset})}
\label{module_doc:dataset-collection-of-data-points-kafe-dataset}\label{module_doc:module-kafe.dataset}\index{kafe.dataset (module)}\phantomsection\label{module_doc:module-dataset}\index{dataset (module)}\index{Dataset (class in kafe.dataset)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset}\pysiglinewithargsret{\strong{class }\code{kafe.dataset.}\bfcode{Dataset}}{\emph{data=None, title='Untitled Dataset', axis\_labels={[}'x', `y'{]}, axis\_units={[}'`, `'{]}, **kwargs}}{}
Bases: \code{object}

The \emph{Dataset} object is a data structure for storing measurement and error
data.

It contains the measurement \emph{data} as \emph{NumPy} arrays and the error
information as a list of {\hyperref[module_doc:kafe.dataset.ErrorSource]{\emph{\code{ErrorSource}}}} (\autopageref*{module_doc:kafe.dataset.ErrorSource}) objects for
each axis, each of which represents a separate contribution to the
uncertainty of the measurement data, expressed as a \emph{covariance matrix}.

The \emph{Dataset} object calculates a \emph{total covariance matrix} by adding
up all the individual \emph{ErrorSource} covariance matrices. This
\emph{total covariance matrix} is the one used for fitting.

A \emph{Dataset} can be constructed directly from the measurement data, and can
optionally be given a \emph{title}, \emph{axis labels} and \emph{axis units}, as well as
a \emph{base name} for log or output files:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}d} \PYG{o}{=} \PYG{n}{kafe}\PYG{o}{.}\PYG{n}{Dataset}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{p}{[}\PYG{p}{[}\PYG{l+m+mf}{0.}\PYG{p}{,} \PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.23}\PYG{p}{,} \PYG{l+m+mf}{3.45}\PYG{p}{,} \PYG{l+m+mf}{5.62}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}
\end{Verbatim}

After constructing the \emph{Dataset}, an error model may be added using
{\hyperref[module_doc:kafe.dataset.Dataset.add_error_source]{\emph{\code{add\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.add_error_source}) (here, an absolute
\emph{y}-uncertainty of 0.5):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}d}\PYG{o}{.}\PYG{n}{add\PYGZus{}error\PYGZus{}source}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{y}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{simple}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{l+m+mf}{0.5}\PYG{p}{)}  \PYG{c}{\PYGZsh{} y errors, all +/\PYGZhy{} 0.5}
\end{Verbatim}

The \emph{Dataset} may then be used for fitting. For more information, see the
{\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object documentation.
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{data} (\emph{iterable, optional}) --
the measurement data. Either of the form (xdata, ydata) or
{[}(x1, y1), (x2, y2),... (xn, yn){]}

\item {} 
\textbf{title} (\emph{string, optional}) --
the name of the \emph{Dataset}. If omitted, the \emph{Dataset} will be given the
generic name `Untitled Dataset'.

\item {} 
\textbf{axis\_labels} (\emph{list of strings, optional}) --

labels for the \emph{x} and \emph{y} axes. If omitted, these will be set to
\code{'x'} and \code{'y'}, respectively.

\item {} 
\textbf{axis\_units} (\emph{list of strings, optional}) --

units for the \emph{x} and \emph{y} axes. If omitted, these will be assumed to be
dimensionless, i.e. the unit will be an empty string.

\item {} 
\textbf{basename} (\emph{string}) --

base name of files generated by this Dataset/subsequent Fits...

\end{itemize}

\end{description}\end{quote}
\index{add\_error\_source() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.add_error_source}\pysiglinewithargsret{\bfcode{add\_error\_source}}{\emph{axis}, \emph{err\_type}, \emph{err\_val}, \emph{relative=False}, \emph{correlated=False}, \emph{recompute\_cov\_mat=True}}{}
Add an error source for the data. A \emph{Dataset} can have many
error sources for each axis, each corresponding to a covariance matrix.
The total error model for the axis is represented by the sum of
these matrices.

Note: whenever an ErrorSource is added, the total covariance matrix
is (re-)calculated, unless \emph{recompute\_cov\_mat} is \code{False}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- axis for which to add error source.

\item {} 
\textbf{\texttt{err\_type}} (\code{'simple'} or \code{'matrix'}) -- 
a \code{'simple'} error source is constructed from a single float or
a list of \emph{N} floats (\emph{N} being the size of the \emph{Dataset}),
representing the uncertainty of the corresponding data points.

A \code{'matrix'} error source is a user-constructed covariance
matrix.


\item {} 
\textbf{\texttt{err\_val}} (float/list of floats \emph{or} numpy.matrix) -- 
for a \code{'simple'} error source, a float of a list of \emph{N} floats
(\emph{N} being the size of the \emph{Dataset}). The float/each float in the
list represents the uncertainty of the corresponding data point.

For a \code{'matrix'} error source, the user-constructed covariance
matrix (type: \emph{numpy.matrix}).


\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{relative} (boolean, optional, default \code{False}) --
errors relative to the data (\code{True}) or absolute (\code{False}).

\item {} 
\textbf{correlated} (boolean, optional, default \code{False}) --
errors fully correlated (\code{True}) or totally uncorrelated
(\code{False}).

\item {} 
\textbf{recompute\_cov\_mat} (boolean, optional, default \code{True}) --
recalculate the total covariance matrix after adding the error
source

\end{itemize}

\item[{Returns}] \leavevmode
this integer may later be used to remove or disable/enable the
error source using
{\hyperref[module_doc:kafe.dataset.Dataset.remove_error_source]{\emph{\code{remove\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.remove_error_source}),
{\hyperref[module_doc:kafe.dataset.Dataset.disable_error_source]{\emph{\code{disable\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.disable_error_source}) or
{\hyperref[module_doc:kafe.dataset.Dataset.enable_error_source]{\emph{\code{enable\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.enable_error_source}).

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{calc\_cov\_mats() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.calc_cov_mats}\pysiglinewithargsret{\bfcode{calc\_cov\_mats}}{\emph{axis='all'}}{}
(Re-)Calculate the covariance matrix from the enabled error sources.
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode
\textbf{axis} (\code{'x'} or \code{'y'} or \code{'all'}) --
axis/axes for which to (re-)calcuate covariance matrix.

\end{description}\end{quote}

\end{fulllineitems}

\index{cov\_mat\_is\_regular() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.cov_mat_is_regular}\pysiglinewithargsret{\bfcode{cov\_mat\_is\_regular}}{\emph{axis}}{}
Returns \emph{True} if the covariance matrix for an axis is regular and
\code{False} if it is singular.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- Axis for which to check for regularity of the covariance matrix.

\item[{Returns}] \leavevmode
\code{True} if covariance matrix is regular

\item[{Return type}] \leavevmode
boolean

\end{description}\end{quote}

\end{fulllineitems}

\index{cov\_mats (kafe.dataset.Dataset attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.cov_mats}\pysigline{\bfcode{cov\_mats}\strong{ = None}}
covariance matrices for axes

\end{fulllineitems}

\index{disable\_error\_source() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.disable_error_source}\pysiglinewithargsret{\bfcode{disable\_error\_source}}{\emph{axis}, \emph{err\_src\_id}}{}
Disables an ErrorSource by excluding it from the calculation of the
total covariance matrix.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- axis for which to add error source.

\item {} 
\textbf{\texttt{err\_src\_id}} (\emph{int}) -- error source ID, as returned by
{\hyperref[module_doc:kafe.dataset.Dataset.add_error_source]{\emph{\code{add\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.add_error_source}).

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{enable\_error\_source() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.enable_error_source}\pysiglinewithargsret{\bfcode{enable\_error\_source}}{\emph{axis}, \emph{err\_src\_id}}{}
Enables an ErrorSource by excluding it from the calculation of the
total covariance matrix.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- axis for which to add error source.

\item {} 
\textbf{\texttt{err\_src\_id}} (\emph{int}) -- error source ID, as returned by
{\hyperref[module_doc:kafe.dataset.Dataset.add_error_source]{\emph{\code{add\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.add_error_source}).

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{err\_src (kafe.dataset.Dataset attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.err_src}\pysigline{\bfcode{err\_src}\strong{ = None}}
lists of ErrorSource objects

\end{fulllineitems}

\index{error\_source\_is\_enabled() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.error_source_is_enabled}\pysiglinewithargsret{\bfcode{error\_source\_is\_enabled}}{\emph{axis}, \emph{err\_src\_id}}{}
Returns \code{True} if an ErrorSource is enabled, that is if it is included
in the total covariance matrix.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- Axis for which to load the error matrix.

\item {} 
\textbf{\texttt{err\_src\_id}} (\emph{int}) -- error source ID, as returned by
{\hyperref[module_doc:kafe.dataset.Dataset.add_error_source]{\emph{\code{add\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.add_error_source}).

\end{itemize}

\item[{Returns}] \leavevmode
\begin{itemize}
\item {} 
\emph{bool} --
\emph{True} if the specified error source is enables

\item {} 
\textbf{TODO} (\emph{\#\#DocString\#\#})

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{get\_axis() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.get_axis}\pysiglinewithargsret{\bfcode{get\_axis}}{\emph{axis\_alias}}{}
Get axis id from an alias.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis\_alias}} (\emph{string or int}) -- Alias of the axis whose id should be returned. This is for example
either \code{'0'} or \code{'x'} for the \emph{x}-axis (id 0).

\item[{Returns}] \leavevmode
the axis ID

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_cov\_mat() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.get_cov_mat}\pysiglinewithargsret{\bfcode{get\_cov\_mat}}{\emph{axis}, \emph{fallback\_on\_singular=None}}{}
Get the error matrix for an axis.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- Axis for which to load the error matrix.

\item[{Keyword Arguments}] \leavevmode
\textbf{fallback\_on\_singular} (\emph{numpy.matrix} or string, optional) --
What to return if the matrix is singular. If this is \code{None}
(default), the matrix is returned anyway. If this is a
\emph{numpy.matrix} object or similar, that is returned istead.
Alternatively, the shortcuts \code{'identity'} or \code{1} and \code{'zero'}
or \code{0} can be used to return the identity and zero matrix
respectively.

\item[{Returns}] \leavevmode
the current covariance matrix

\item[{Return type}] \leavevmode
\emph{numpy.matrix}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_data() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.get_data}\pysiglinewithargsret{\bfcode{get\_data}}{\emph{axis}}{}
Get the measurement data for an axis.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis}} (\emph{string}) -- Axis for which to get the measurement data. Can be \code{'x'} or
\code{'y'}.

\item[{Returns}] \leavevmode
the measurement data for the axis

\item[{Return type}] \leavevmode
\emph{numpy.array}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_data\_span() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.get_data_span}\pysiglinewithargsret{\bfcode{get\_data\_span}}{\emph{axis}, \emph{include\_error\_bars=False}}{}
Get the data span for an axis. The data span is a tuple (\emph{min}, \emph{max})
containing the smallest and highest coordinates for an axis.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- Axis for which to get the data span.

\item[{Keyword Arguments}] \leavevmode
\textbf{include\_error\_bars} (\emph{boolean, optional}) --
\code{True} if the returned span should be enlarged to
contain the error bars of the smallest and largest datapoints
(default: \code{False})

\item[{Returns}] \leavevmode
the data span for the axis

\item[{Return type}] \leavevmode
a tuple (\emph{min}, \emph{max})

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_formatted() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.get_formatted}\pysiglinewithargsret{\bfcode{get\_formatted}}{\emph{format\_string='.06e'}, \emph{delimiter='\textbackslash{}t'}}{}
Returns the dataset in a plain-text format which is human-readable and
can later be used as an input file for the creation of a new \emph{Dataset}.

The format is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{} x data
x\PYGZus{}1  sigma\PYGZus{}x\PYGZus{}1
x\PYGZus{}2  sigma\PYGZus{}x\PYGZus{}2  cor\PYGZus{}x\PYGZus{}12
...  ...        ...       ...
x\PYGZus{}N  sigma\PYGZus{}x\PYGZus{}N  cor\PYGZus{}x\PYGZus{}1N  ...  cor\PYGZus{}x\PYGZus{}NN

\PYGZsh{} y data
y\PYGZus{}1  sigma\PYGZus{}y\PYGZus{}1
y\PYGZus{}2  sigma\PYGZus{}y\PYGZus{}2  cor\PYGZus{}y\PYGZus{}12
...  ...        ...       ...
y\PYGZus{}N  sigma\PYGZus{}y\PYGZus{}N  cor\PYGZus{}y\PYGZus{}1N  ...  cor\PYGZus{}y\PYGZus{}NN
\end{Verbatim}

Here, the \code{x\_i} and \code{y\_i} represent the measurement data, the
\code{sigma\_?\_i} are the statistical uncertainties of each data point, and
the \code{cor\_?\_ij} are the correlation coefficients between the \emph{i}-th
and \emph{j}-th data point.

If the \code{x} or \code{y} errors are not correlated, then the entire
correlation coefficient matrix can be omitted. If there are no
statistical uncertainties for an axis, the second column can also be
omitted. A blank line is required at the end of each data block!
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{format\_string} (\emph{string, optional}) --
A format string with which each entry will be rendered. Default is
\code{'.06e'}, which means the numbers are represented in scientific
notation with six significant digits.

\item {} 
\textbf{delimiter} (\emph{string, optional}) --
A delimiter used to separate columns in the output.

\end{itemize}

\item[{Returns}] \leavevmode
a plain-text representation of the \emph{Dataset}

\item[{Return type}] \leavevmode
str

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_size() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.get_size}\pysiglinewithargsret{\bfcode{get\_size}}{}{}
Get the size of the \emph{Dataset}. This is equivalent to the length of the
\emph{x}-axis data.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
the number of datapoints in the \emph{Dataset}.

\item[{Return type}] \leavevmode
int

\end{description}\end{quote}

\end{fulllineitems}

\index{has\_correlations() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.has_correlations}\pysiglinewithargsret{\bfcode{has\_correlations}}{\emph{axis=None}}{}
Returns \emph{True} if the specified axis has correlation data, \code{False} if
not.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'} or \code{None}, optional) -- Axis for which to check for correlations. If \code{None},
returns true if there are correlations for at least one axis.

\item[{Returns}] \leavevmode
\emph{True} if the specified axis has correlation data

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{has\_errors() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.has_errors}\pysiglinewithargsret{\bfcode{has\_errors}}{\emph{axis=None}}{}
Returns \emph{True} if the specified axis has any kind of error data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'} or \code{None}, optional) -- Axis for which to check for error data. If \code{None},
returns true if there are errors for at least one axis.

\item[{Returns}] \leavevmode
\emph{True} if the specified axis has any kind of error data.

\item[{Return type}] \leavevmode
bool

\end{description}\end{quote}

\end{fulllineitems}

\index{n\_datapoints (kafe.dataset.Dataset attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.n_datapoints}\pysigline{\bfcode{n\_datapoints}\strong{ = None}}
number of data points in the \emph{Dataset}

\end{fulllineitems}

\index{read\_from\_file() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.read_from_file}\pysiglinewithargsret{\bfcode{read\_from\_file}}{\emph{input\_file}}{}
Reads the \emph{Dataset} object from a file.

One way to construct a Dataset is to specify an input file containing
a plain-text representation of the dataset:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{read\PYGZus{}from\PYGZus{}file}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{/path/to/file}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\end{Verbatim}

or

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{read\PYGZus{}from\PYGZus{}file}\PYG{p}{(}\PYG{n}{my\PYGZus{}file\PYGZus{}object}\PYG{p}{)}
\end{Verbatim}

For details on the format, see
{\hyperref[module_doc:kafe.dataset.Dataset.get_formatted]{\emph{\code{get\_formatted()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.get_formatted})
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{input\_file}} (\emph{str}) -- path to the file

\item[{Returns}] \leavevmode
\code{True} if the read succeeded, \code{False} if not.

\item[{Return type}] \leavevmode
boolean

\end{description}\end{quote}

\end{fulllineitems}

\index{remove\_error\_source() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.remove_error_source}\pysiglinewithargsret{\bfcode{remove\_error\_source}}{\emph{axis}, \emph{err\_src\_id}, \emph{recompute\_cov\_mat=True}}{}
Remove the error source from the \emph{Dataset}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- axis for which to add error source.

\item {} 
\textbf{\texttt{err\_src\_id}} (\emph{int}) -- error source ID, as returned by
{\hyperref[module_doc:kafe.dataset.Dataset.add_error_source]{\emph{\code{add\_error\_source()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.add_error_source}).

\end{itemize}

\item[{Keyword Arguments}] \leavevmode
\textbf{recompute\_cov\_mat} (boolean, optional, default \code{True}) --
recalculate the total covariance matrix after removing the error
source

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_axis\_data() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.set_axis_data}\pysiglinewithargsret{\bfcode{set\_axis\_data}}{\emph{axis}, \emph{data}}{}
Set the measurement data for a single axis.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- Axis for which to set the measurement data.

\item {} 
\textbf{\texttt{data}} (\emph{iterable}) -- Measurement data for axis.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_cov\_mat() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.set_cov_mat}\pysiglinewithargsret{\bfcode{set\_cov\_mat}}{\emph{axis}, \emph{mat}}{}
Forcibly set the error matrix for an axis, ignoring {\hyperref[module_doc:kafe.dataset.ErrorSource]{\emph{\code{ErrorSource}}}} (\autopageref*{module_doc:kafe.dataset.ErrorSource})
objects. This is useful for adjusting the covariance matrix during the
fit process.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\code{'x'} or \code{'y'}) -- Axis for which to load the error matrix.

\item {} 
\textbf{\texttt{mat}} (\emph{numpy.matrix} or \code{None}) -- Error matrix for the axis. Passing \code{None} unsets the error
matrix.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_data() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.set_data}\pysiglinewithargsret{\bfcode{set\_data}}{\emph{data}}{}
Set the measurement data for both axes.

Each element of \textbf{data} must be iterable and be of the same length.
The first element of the \textbf{data} tuple/list is assumed to be the \emph{x}
data, and the second to be the \emph{y} data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{set\PYGZus{}data}\PYG{p}{(}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.}\PYG{p}{,} \PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{l+m+mf}{2.}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.23}\PYG{p}{,} \PYG{l+m+mf}{3.45}\PYG{p}{,} \PYG{l+m+mf}{5.62}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

Alternatively, \emph{x}-\emph{y} value pairs can also be passed as \textbf{data}. The
following is equivalent to the above:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}dataset}\PYG{o}{.}\PYG{n}{set\PYGZus{}data}\PYG{p}{(}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{1.23}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{l+m+mf}{3.45}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{2.0}\PYG{p}{,} \PYG{l+m+mf}{5.62}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

In case the \emph{Dataset} contains two data points, the ordering is
ambiguous. In this case, the first ordering (\emph{x} data first, then \emph{y}
data) is assumed.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{data}} (\emph{iterable}) -- the measurement data. Either of the form (xdata, ydata) or
{[}(x1, y1), (x2, y2),... (xn, yn){]}

\end{description}\end{quote}

\end{fulllineitems}

\index{write\_formatted() (kafe.dataset.Dataset method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.Dataset.write_formatted}\pysiglinewithargsret{\bfcode{write\_formatted}}{\emph{file\_path}, \emph{format\_string='.06e'}, \emph{delimiter='\textbackslash{}t'}}{}
Writes the dataset to a plain-text file. For details on the format, see
{\hyperref[module_doc:kafe.dataset.Dataset.read_from_file]{\emph{\code{read\_from\_file()}}}} (\autopageref*{module_doc:kafe.dataset.Dataset.read_from_file}).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{file\_path}} (\emph{string}) -- Path of the file object to write. \textbf{WARNING}: \emph{overwrites existing
files}!

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{format\_string} (\emph{string, optional}) --
A format string with which each entry will be rendered. Default is
\code{'.06e'}, which means the numbers are represented in scientific
notation with six significant digits.

\item {} 
\textbf{delimiter} (\emph{string, optional}) --
A delimiter used to separate columns in the output.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{ErrorSource (class in kafe.dataset)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.ErrorSource}\pysigline{\strong{class }\code{kafe.dataset.}\bfcode{ErrorSource}}
Bases: \code{object}

This object stores the error information for a \code{Dataset} as a
\emph{covariance matrix} \(C\) (sometimes also referred to as the \emph{error
matrix}). This has several advantages: it allows calculating the function
to minimize (e.g. the chi-square) for a fit as a matrix product, and it
allows specifying multiple error sources for a \emph{Dataset} by simply adding
up the corresponding matrices.

The object contains methods to generate a covariance matrix for some
simple cases, such as when all points have the same relative or absolute
errors and the errors are either not correlated or fully correlated. For
more complicated error models, a covariance matrix can be specified
directly.
\index{get\_matrix() (kafe.dataset.ErrorSource method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.ErrorSource.get_matrix}\pysiglinewithargsret{\bfcode{get\_matrix}}{\emph{size=None}}{}
Returns/Generates the covariance matrix for this ErrorSource.

If the user specified the matrix using
{\hyperref[module_doc:kafe.dataset.ErrorSource.make_from_matrix]{\emph{\code{make\_from\_matrix()}}}} (\autopageref*{module_doc:kafe.dataset.ErrorSource.make_from_matrix}),
returns that matrix. If a simple error model is specified, a matrix is
constructed as follows:

For \emph{uncorrelated} errors, the covariance matrix is always diagonal.

If a single float \(\sigma\) is given as the error, the diagonal
entries will be equal to \(\sigma^2\). In this case, the matrix
size needs to be specified via the \code{size} parameter.

If a list of floats \(\sigma_i\) is given as the error, the
\emph{i}-th entry will be equal to \({\sigma_i}^2\). In this case,
the size of the matrix is inferred from the size of the list.

For \emph{fully correlated} errors, the covariance matrix is the outer
product of the error array \(\sigma_i\) with itself, i.e. the
\((i,j)\)-th matrix entry will be equal to
\(\sigma_i\sigma_j\).
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode
\textbf{size} (\emph{int (sometimes required)}) --
Size of the matrix to return. Only relevant if the error value
is a single float, since in that case there is no way to deduce
the matrix size.

\end{description}\end{quote}

\end{fulllineitems}

\index{make\_from\_matrix() (kafe.dataset.ErrorSource method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.ErrorSource.make_from_matrix}\pysiglinewithargsret{\bfcode{make\_from\_matrix}}{\emph{cov\_mat}, \emph{check\_singular=False}}{}
Sets the covariance matrix manually.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{cov\_mat}} (\emph{numpy.matrix}) -- A \emph{square}, \emph{symmetric} (and usually \emph{regular}) matrix.

\item[{Keyword Arguments}] \leavevmode
\textbf{check\_singular} (\emph{boolean, optional}) --
Whether to force singularity check. Defaults to \code{False}.

\end{description}\end{quote}

\end{fulllineitems}

\index{make\_from\_val() (kafe.dataset.ErrorSource method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset.ErrorSource.make_from_val}\pysiglinewithargsret{\bfcode{make\_from\_val}}{\emph{err\_val}, \emph{fully\_correlated=False}}{}
Sets information required to construct the covariance matrix.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{err\_val}} (\emph{float or sequence of floats}) -- If all data points have the same uncertainty

\item[{Keyword Arguments}] \leavevmode
\textbf{fully\_correlated} (\emph{boolean, optional}) --
Whether the errors are fully correlated. Defaults to \code{False}.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsection{\texttt{Fit}: Fit of model functions to a \texttt{Dataset} (\texttt{kafe.fit})}
\label{module_doc:fit-fit-of-model-functions-to-a-dataset-kafe-fit}\label{module_doc:module-kafe.fit}\index{kafe.fit (module)}\phantomsection\label{module_doc:module-fit}\index{fit (module)}\index{CL2Chi2() (in module kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.CL2Chi2}\pysiglinewithargsret{\code{kafe.fit.}\bfcode{CL2Chi2}}{\emph{CL}}{}
Helper function to calculate DeltaChi2 from confidence level CL

\end{fulllineitems}

\index{Chi22CL() (in module kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Chi22CL}\pysiglinewithargsret{\code{kafe.fit.}\bfcode{Chi22CL}}{\emph{dc2}}{}
Helper function to calculate confidence level CL from DeltaChi2

\end{fulllineitems}

\index{Fit (class in kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit}\pysiglinewithargsret{\strong{class }\code{kafe.fit.}\bfcode{Fit}}{\emph{dataset}, \emph{fit\_function}, \emph{external\_fcn=\textless{}function chi2\textgreater{}}, \emph{fit\_name=None}, \emph{fit\_label=None}, \emph{minimizer\_to\_use='iminuit'}}{}
Bases: \code{object}

Object representing a fit. This object references the fitted \emph{Dataset},
the fit function and the resulting fit parameters.

Necessary arguments are a \emph{Dataset} object and a fit function (which should
be fitted to the \emph{Dataset}). Optionally, an external function \emph{FCN} (the
minimum of which should be located to find the best fit) can be specified.
If not given, the \emph{FCN} function defaults to \(\chi^2\).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{dataset}} (\emph{Dataset}) -- A \emph{Dataset} object containing all information about the data

\item {} 
\textbf{\texttt{fit\_function}} (\emph{function}) -- 
A user-defined Python function to fit to the data. This
function's first argument must be the independent variable \emph{x}. All
other arguments \emph{must} be named and have default values given. These
defaults are used as a starting point for the actual minimization. For
example, a simple linear function would be defined like:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{k}{def} \PYG{n+nf}{linear\PYGZus{}2par}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{slope}\PYG{o}{=}\PYG{l+m+mf}{1.}\PYG{p}{,} \PYG{n}{y\PYGZus{}intercept}\PYG{o}{=}\PYG{l+m+mf}{0.}\PYG{p}{)}\PYG{p}{:}
\PYG{g+gp}{... }    \PYG{k}{return} \PYG{n}{slope} \PYG{o}{*} \PYG{n}{x} \PYG{o}{+} \PYG{n}{y\PYGZus{}intercept}
\end{Verbatim}

Be aware that choosing sensible initial values for the parameters is
often crucial for a succesful fit, particularly for functions of many
parameters.


\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{external\_fcn} (\emph{function, optional}) --
An external \emph{FCN} (function to minimize). This function must have the
following call signature:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{FCN}\PYG{p}{(}\PYG{n}{xdata}\PYG{p}{,} \PYG{n}{ydata}\PYG{p}{,} \PYG{n}{cov\PYGZus{}mat}\PYG{p}{,} \PYG{n}{fit\PYGZus{}function}\PYG{p}{,} \PYG{n}{parameter\PYGZus{}values}\PYG{p}{)}
\end{Verbatim}

It should return a float. If not specified, the default \(\chi^2\)
\emph{FCN} is used. This should be sufficient for most fits.

\item {} 
\textbf{fit\_name} (\emph{string, optional}) --
An ASCII name for this fit. This is used as a label for the the
matplotlib figure window and for naming the fit output file. If
omitted, the fit will take over the name of the parent dataset.

\item {} 
\textbf{fit\_label} (\(LaTeX\)-formatted string, optional) --
A name/label/short description of the fit function. This appears in the
legend describing the fitter curve. If omitted, this defaults to the
fit function's \(LaTeX\) expression.

\item {} 
\textbf{minimizer\_to\_use} (\emph{`ROOT' or `minuit', optional}) --
Which minimizer to use. This defaults to whatever is set in the config
file, but can be specifically overridden for some fits using this
keyword argument

\end{itemize}

\end{description}\end{quote}
\index{call\_external\_fcn() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.call_external_fcn}\pysiglinewithargsret{\bfcode{call\_external\_fcn}}{\emph{*parameter\_values}}{}
Wrapper for the external \emph{FCN}. Since the actual fit process depends on
finding the right parameter values and keeping everything else constant
we can use the \emph{Dataset} object to pass known, fixed information to the
external \emph{FCN}, varying only the parameter values.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{parameter\_values}} (\emph{sequence of values}) -- the parameter values at which \emph{FCN} is to be evaluated

\end{description}\end{quote}

\end{fulllineitems}

\index{call\_minimizer() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.call_minimizer}\pysiglinewithargsret{\bfcode{call\_minimizer}}{\emph{final\_fit=True}, \emph{verbose=False}, \emph{quiet=False}}{}
Instructs the minimizer to do a minimization.

\end{fulllineitems}

\index{constrain\_parameters() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.constrain_parameters}\pysiglinewithargsret{\bfcode{constrain\_parameters}}{\emph{parameters}, \emph{parvals}, \emph{parerrs}, \emph{cor\_mat=None}}{}
Constrain the parameter with the given name to \(c\pm\sigma\).
This is achieved by adding an appropriate \emph{penalty term} to the
\(\chi^2\) function, see function {\hyperref[module_doc:kafe.fit.chi2]{\emph{\code{chi2()}}}} (\autopageref*{module_doc:kafe.fit.chi2}).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{parameters}} (\emph{list of int}) -- list of paramter id's or names to constrain

\item {} 
\textbf{\texttt{parvals}} (\emph{list of float}) -- list of parameter values

\item {} 
\textbf{\texttt{parerrs}} (\emph{list of float}) -- list of errors on parameters

\end{itemize}

\item[{Keyword Arguments}] \leavevmode
\textbf{**cor\_mat**} (\emph{numpy.matrix} optional) --
correlation matrix of the parameters

\end{description}\end{quote}

\end{fulllineitems}

\index{contours (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.contours}\pysigline{\bfcode{contours}\strong{ = None}}
Parameter Contours {[}id1, id2, dchi2, {[}xc{]}, {[}yc{]}{]}

\end{fulllineitems}

\index{current\_cov\_mat (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.current_cov_mat}\pysigline{\bfcode{current\_cov\_mat}\strong{ = None}}
the current covariance matrix used for the \emph{Fit}

\end{fulllineitems}

\index{dataset (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.dataset}\pysigline{\bfcode{dataset}\strong{ = None}}
this Fit instance's child \emph{Dataset}

\end{fulllineitems}

\index{do\_fit() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.do_fit}\pysiglinewithargsret{\bfcode{do\_fit}}{\emph{quiet=False}, \emph{verbose=False}}{}
Runs the fit algorithm for this \emph{Fit} object.

First, the \code{Dataset} is fitted considering only uncertainties
in the
\emph{y} direction. If the \emph{Dataset} has no uncertainties in the \emph{y}
direction, they are assumed to be equal to 1.0 for this preliminary
fit, as there is no better information available.

Next, the fit errors in the \emph{x} direction (if they exist) are taken
into account by projecting the covariance matrix for the \emph{x} errors
onto the \emph{y} covariance matrix. This is done by taking the first
derivative of the fit function in each point and ``projecting'' the \emph{x}
error onto the resulting tangent to the curve.

This last step is repeated until the change in the error matrix caused
by the projection becomes negligible.
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{quiet} (\emph{boolean, optional}) --
Set to \code{True} if no output should be printed.

\item {} 
\textbf{verbose} (\emph{boolean, optional}) --
Set to \code{True} if more output should be printed.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{external\_fcn (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.external_fcn}\pysigline{\bfcode{external\_fcn}\strong{ = None}}
the (external) function to be minimized for this \emph{Fit}

\end{fulllineitems}

\index{final\_fcn (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.final_fcn}\pysigline{\bfcode{final\_fcn}\strong{ = None}}
Final minimum of fcn (chi2)

\end{fulllineitems}

\index{final\_parameter\_errors (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.final_parameter_errors}\pysigline{\bfcode{final\_parameter\_errors}\strong{ = None}}
Final parameter errors

\end{fulllineitems}

\index{final\_parameter\_values (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.final_parameter_values}\pysigline{\bfcode{final\_parameter\_values}\strong{ = None}}
Final parameter values

\end{fulllineitems}

\index{fit\_function (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.fit_function}\pysigline{\bfcode{fit\_function}\strong{ = None}}
the fit function used for this \emph{Fit}

\end{fulllineitems}

\index{fix\_parameters() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.fix_parameters}\pysiglinewithargsret{\bfcode{fix\_parameters}}{\emph{*parameters\_to\_fix}}{}
Fix the given parameters so that the minimizer works without them
when {\hyperref[module_doc:kafe.fit.Fit.do_fit]{\emph{\code{do\_fit()}}}} (\autopageref*{module_doc:kafe.fit.Fit.do_fit}) is called next. Parameters can be
given by their names or by their IDs.

\end{fulllineitems}

\index{get\_current\_fit\_function() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.get_current_fit_function}\pysiglinewithargsret{\bfcode{get\_current\_fit\_function}}{}{}
This method returns a function object corresponding to the fit function
for the current parameter values. The returned function is a function
of a single variable.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A function of a single variable corresponding to the fit function
at the current parameter values.

\item[{Return type}] \leavevmode
function handle

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_error\_matrix() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.get_error_matrix}\pysiglinewithargsret{\bfcode{get\_error\_matrix}}{}{}
This method returns the covariance matrix of the fit parameters which
is obtained by querying the minimizer object for this \emph{Fit}
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
The covariance matrix of the parameters.

\item[{Return type}] \leavevmode
\emph{numpy.matrix}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_function\_error() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.get_function_error}\pysiglinewithargsret{\bfcode{get\_function\_error}}{\emph{x}}{}
This method uses the parameter error matrix of the fit to calculate
a symmetric (parabolic) error on the function value itself. Note that
this method takes the entire parameter error matrix into account, so
that it also accounts for correlations.

The method is useful if, e.g., you want to draw a confidence band
around the function in your plot routine.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{x}} (\emph{float} or sequence of \emph{float}) -- the values at which the function error is to be estimated

\item[{Returns}] \leavevmode
the estimated error at the given point(s)

\item[{Return type}] \leavevmode
float or sequence of float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_parameter\_errors() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.get_parameter_errors}\pysiglinewithargsret{\bfcode{get\_parameter\_errors}}{\emph{rounding=False}}{}
Get the current parameter uncertainties from the minimizer.
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode
\textbf{rounding} (\emph{boolean, optional}) --
Whether or not to round the returned values to significance.

\item[{Returns}] \leavevmode
A tuple of the parameter uncertainties

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_parameter\_values() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.get_parameter_values}\pysiglinewithargsret{\bfcode{get\_parameter\_values}}{\emph{rounding=False}}{}
Get the current parameter values from the minimizer.
\begin{quote}\begin{description}
\item[{Keyword Arguments}] \leavevmode
\textbf{rounding} (\emph{boolean, optional}) --
Whether or not to round the returned values to significance.

\item[{Returns}] \leavevmode
A tuple of the parameter values

\item[{Return type}] \leavevmode
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_results() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.get_results}\pysiglinewithargsret{\bfcode{get\_results}}{}{}
Return results from Fit

\end{fulllineitems}

\index{latex\_parameter\_names (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.latex_parameter_names}\pysigline{\bfcode{latex\_parameter\_names}\strong{ = None}}
\(LaTeX\) parameter names

\end{fulllineitems}

\index{minos\_errors (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.minos_errors}\pysigline{\bfcode{minos\_errors}\strong{ = None}}
MINOS Errors {[}err, err+, err-, gcor{]}

\end{fulllineitems}

\index{number\_of\_parameters (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.number_of_parameters}\pysigline{\bfcode{number\_of\_parameters}\strong{ = None}}
the total number of parameters

\end{fulllineitems}

\index{par\_cov\_mat (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.par_cov_mat}\pysigline{\bfcode{par\_cov\_mat}\strong{ = None}}
Parameter covariance matrix (\emph{numpy.matrix})

\end{fulllineitems}

\index{parabolic\_errors (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.parabolic_errors}\pysigline{\bfcode{parabolic\_errors}\strong{ = None}}
\code{True} if \(\chi^2\) is approx. parabolic (boolean)

\end{fulllineitems}

\index{parameter\_is\_fixed() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.parameter_is_fixed}\pysiglinewithargsret{\bfcode{parameter\_is\_fixed}}{\emph{parameter}}{}
Check whether a parameter is fixed. Accepts a parameter's name or ID
and returns a boolean value.

\end{fulllineitems}

\index{parameter\_names (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.parameter_names}\pysigline{\bfcode{parameter\_names}\strong{ = None}}
the names of the parameters

\end{fulllineitems}

\index{plot\_contour() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.plot_contour}\pysiglinewithargsret{\bfcode{plot\_contour}}{\emph{parameter1}, \emph{parameter2}, \emph{dchi2=2.3}, \emph{n\_points=100}, \emph{color='gray'}, \emph{alpha=0.1}, \emph{show=False}, \emph{axes=None}}{}
Plots one or more two-dimensional contours for this fit into
a separate figure and returns the figure object.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{parameter1}} (\emph{int or string}) -- ID or name of the parameter to appear on the \emph{x}-axis.

\item {} 
\textbf{\texttt{parameter2}} (\emph{int or string}) -- ID or name of the parameter to appear on the \emph{y}-axis.

\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{dchi2} (\emph{float or list of floats (otpional)}) --
delta-chi\textasciicircum{}2 value(s) used to evaluate contour(s)
1. = 1 sigma
2.3 = 68.0\% (default)
4.  = 2 sigma
5.99 = 95.0\%

\item {} 
\textbf{n\_points} (\emph{int, optional}) --
Number of plot points to use for the contour. Higher
values yield smoother contours but take longer to
render. Default is 100.

\item {} 
\textbf{color} (\emph{string, optional}) --
A \code{matplotlib} color identifier specifying the fill color
of the contour. Default is `gray'.

\item {} 
\textbf{alpha} (\emph{float, optional}) --
Transparency of the contour fill color ranging from 0. (fully
transparent) to 1. (fully opaque). Default is 0.25

\item {} 
\textbf{show} (\emph{boolean, optional}) --
Specify whether to show the figure before returning it. Defaults
to \code{False}.

\item {} 
\textbf{axes} (\emph{maplotlib.pyplot.axes}) --
Sub-plot axes to add plot to

\end{itemize}

\item[{Returns}] \leavevmode
A figure object containing the contour plot.

\item[{Return type}] \leavevmode
\code{matplotlib} figure object if no axes given

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_correlations() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.plot_correlations}\pysiglinewithargsret{\bfcode{plot\_correlations}}{}{}
Plots two-dimensional contours for all pairs of parameters
and profile for all parameters, arranges as a matrix.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
A figure object containing the matrix of plots.

\item[{Return type}] \leavevmode
\code{matplotlib} figure object

\end{description}\end{quote}

\end{fulllineitems}

\index{plot\_profile() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.plot_profile}\pysiglinewithargsret{\bfcode{plot\_profile}}{\emph{parid}, \emph{n\_points=21}, \emph{color='blue'}, \emph{alpha=0.5}, \emph{show=False}, \emph{axes=None}}{}
Plots a profile \(\\chi^2\) for this fit into
a separate figure and returns the figure object.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{parid}} (\emph{int or string}) -- ID or name of parameter

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{n\_points} (\emph{int, optional}) --
Number of plot points to use for the profile curve.

\item {} 
\textbf{color} (\emph{string, optional}) --
A \code{matplotlib} color identifier specifying the line
color. Default is `blue'.

\item {} 
\textbf{alpha} (\emph{float, optional}) --
Transparency of the contour fill color ranging from 0. (fully
transparent) to 1. (fully opaque). Default is 0.25

\item {} 
\textbf{show} (\emph{boolean, optional}) --
Specify whether to show the figure before returning it. Defaults
to \code{False}.

\item {} 
\textbf{axes} (\emph{sub-plot axes to put plot})

\end{itemize}

\item[{Returns}] \leavevmode
A figure object containing the profile plot.

\item[{Return type}] \leavevmode
\code{matplotlib} figure object if axes is None

\end{description}\end{quote}

\end{fulllineitems}

\index{print\_fit\_details() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.print_fit_details}\pysiglinewithargsret{\bfcode{print\_fit\_details}}{}{}
prints some fit goodness details

\end{fulllineitems}

\index{print\_fit\_results() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.print_fit_results}\pysiglinewithargsret{\bfcode{print\_fit\_results}}{}{}
prints fit results

\end{fulllineitems}

\index{print\_raw\_results() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.print_raw_results}\pysiglinewithargsret{\bfcode{print\_raw\_results}}{}{}
unformatted print-out of all fit results in

\end{fulllineitems}

\index{print\_rounded\_fit\_parameters() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.print_rounded_fit_parameters}\pysiglinewithargsret{\bfcode{print\_rounded\_fit\_parameters}}{}{}
prints the fit parameters

\end{fulllineitems}

\index{profiles (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.profiles}\pysigline{\bfcode{profiles}\strong{ = None}}
Parameter Profiles {[}id1, {[}xp{]}, {[}dchi1(xp){]}{]}

\end{fulllineitems}

\index{project\_x\_covariance\_matrix() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.project_x_covariance_matrix}\pysiglinewithargsret{\bfcode{project\_x\_covariance\_matrix}}{}{}
Project elements of the \emph{x} covariance matrix onto the total
matrix.

This is done element-wise, according to the formula:
\begin{gather}
\begin{split}C_{\text{tot}, ij} = C_{y, ij} + C_{x, ij}
\frac{\partial f}{\partial x_i}  \frac{\partial f}{\partial x_j}\end{split}\notag
\end{gather}
\end{fulllineitems}

\index{release\_parameters() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.release_parameters}\pysiglinewithargsret{\bfcode{release\_parameters}}{\emph{*parameters\_to\_release}}{}
Release the given parameters so that the minimizer begins to work with
them when \code{do\_fit()} is called next. Parameters can be given by
their
names or by their IDs. If no arguments are provied, then release all
parameters.

\end{fulllineitems}

\index{set\_parameters() (kafe.fit.Fit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.set_parameters}\pysiglinewithargsret{\bfcode{set\_parameters}}{\emph{*args}, \emph{**kwargs}}{}
Sets the parameter values (and optionally errors) for this fit.
This is usually called just before the fit is done, to establish
the initial parameters. If a parameter error is omitted, it is
set to 1/10th of the parameter values themselves. If the default
value of the parameter is 0, it is set, by exception, to 0.1.

This method accepts up to two positional arguments and several
keyword arguments.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{args{[}0{]}}} (\emph{tuple/list of floats, optional}) -- The first positional argument is expected to be
a tuple/list containing the parameter values.

\item {} 
\textbf{\texttt{args{[}1{]}}} (\emph{tuple/list of floats, optional}) -- The second positional argument is expected to be a
tuple/list of parameter errors, which can also be set as an
approximate estimate of the problem's uncertainty.

\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{no\_warning} (\emph{boolean, optional}) --
Whether to issue warnings (\code{False}) or not (\code{True}) when
communicating with the minimizer fails. Defaults to \code{False}.

\item {} 
\textbf{Valid keyword argument names are parameter names. The keyword arguments}

\item {} 
\textbf{themselves may be floats (parameter values) or 2-tuples containing the}

\item {} 
\textbf{parameter values and the parameter error in that order}

\item {} 
\textbf{*\textless{}parameter\_name\textgreater{}*} (\emph{float or 2-tuple of floats, optional}) --
Set the parameter with the name \textless{}'parameter\_name'\textgreater{} to the value
given. If a 2-tuple is given, the first element is understood
to be the value and the second to be the parameter error.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{xdata (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.xdata}\pysigline{\bfcode{xdata}\strong{ = None}}
the \emph{x} coordinates of the data points used for this \emph{Fit}

\end{fulllineitems}

\index{ydata (kafe.fit.Fit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.Fit.ydata}\pysigline{\bfcode{ydata}\strong{ = None}}
the \emph{y} coordinates of the data points used for this \emph{Fit}

\end{fulllineitems}


\end{fulllineitems}

\index{GaussianConstraint (class in kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.GaussianConstraint}\pysiglinewithargsret{\strong{class }\code{kafe.fit.}\bfcode{GaussianConstraint}}{\emph{constraint}, \emph{cov\_mat=None}}{}
Bases: \code{object}

Object used to constrain parameters. The object stores for each constrain
the constrained parameters, the errors, the id of the parameter (the place
at which each parameter is located in parameter\_constrain) and the inverse
covariance matrix of the constrained parameters.
The class gives a tool to calculate the chi2 penalty term for the given
constrained parameters, where the fitted parameter\_values must be given.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{constraint}} (\emph{list of two iterables}) -- The first iterable (\({c_i}\)) contains the constrained parameters'
expected values and the second iterable (\({\sigma_i}\)) contains
the constraint uncertainties. A parameter with constraint uncertainty
set to 0 remains unconstrained.

\item[{Keyword Arguments}] \leavevmode
\textbf{cov\_mat} (\emph{`numpy matrix'}) --
Contains the covariance matrix of the constrains. The inverse covariance
matrix will be saved to safe computing time.

\end{description}\end{quote}
\index{calculate\_chi2\_penalty() (kafe.fit.GaussianConstraint method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.GaussianConstraint.calculate_chi2_penalty}\pysiglinewithargsret{\bfcode{calculate\_chi2\_penalty}}{\emph{parameter\_values}}{}
Calculates the \(\chi^2\) penalty for the given constraint
parameter. This function gets called in the \(\chi^2\) function
and returns a penalty term.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{parameter\_values}} (\emph{list/tuple}) -- The values of the parameters at which \(f(x)\) should be evaluated.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{build\_fit() (in module kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.build_fit}\pysiglinewithargsret{\code{kafe.fit.}\bfcode{build\_fit}}{\emph{dataset}, \emph{fit\_function}, \emph{fit\_label='untitled'}, \emph{fit\_name=None}, \emph{initial\_fit\_parameters=None}, \emph{constrained\_parameters=None}}{}
This helper fuction creates a {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) from a series of
keyword arguments.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{dataset}} (a \emph{kafe} {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset})) -- 

\item {} 
\textbf{\texttt{fit\_function}} (\emph{a Python function, optionally with}) -- \code{@FitFunction}, \code{@LATEX} and \code{@FitFunction} decorators

\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{fit\_label} (\emph{LaTeX label for this fit, optional}) --
Defaults to ``untitled''

\item {} 
\textbf{fit\_name} (\emph{name for this fit, optional}) --
Defaults to the dataset name

\item {} 
\textbf{initial\_fit\_parameters} (\code{None} or 2-tuple of list, sequence of floats) --
specifying initial parameter values and errors

\item {} 
\textbf{constrained\_parameters} (\code{None} or 3-tuple of list, tuple/\emph{np.array}) --
of one string and 2 floats specifiying the names, values and
uncertainties of constraints to apply to model parameters

\end{itemize}

\item[{Returns}] \leavevmode


\item[{Return type}] \leavevmode
{\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object

\end{description}\end{quote}

\end{fulllineitems}

\index{chi2() (in module kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.chi2}\pysiglinewithargsret{\code{kafe.fit.}\bfcode{chi2}}{\emph{xdata}, \emph{ydata}, \emph{cov\_mat}, \emph{fit\_function}, \emph{parameter\_values}, \emph{constrain=None}}{}
The \(\chi^2\) implementation. Calculates \(\chi^2\) according
to the formula:
\begin{gather}
\begin{split}\chi^2 = \lambda^T C^{-1} \lambda\end{split}\notag
\end{gather}
Here, \(\lambda\) is the residual vector \(\lambda = \vec{y} -
\vec{f}(\vec{x})\) and \(C\) is the covariance matrix.

If a constraint \(c_i\pm\sigma_i\) is applied to a parameter \(p_i\),
a \emph{penalty term} is added for each constrained parameter:
\begin{gather}
\begin{split}\chi^2_{\text{cons}} = \chi^2 + \sum_i{ \left( \frac{p_i - c_i}{\sigma_i} \right)^2 }\end{split}\notag
\end{gather}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{xdata}} (\emph{iterable}) -- The \emph{x} measurement data

\item {} 
\textbf{\texttt{ydata}} (\emph{iterable}) -- The \emph{y} measurement data

\item {} 
\textbf{\texttt{cov\_mat}} (\emph{numpy.matrix}) -- The total covariance matrix

\item {} 
\textbf{\texttt{fit\_function}} (\emph{function}) -- The fit function \(f(x)\)

\item {} 
\textbf{\texttt{parameter\_values}} (\emph{list/tuple}) -- The values of the parameters at which \(f(x)\) should be evaluated.

\end{itemize}

\item[{Keyword Arguments}] \leavevmode
\textbf{constrain} (\code{None} or dictionary , optional) --
The key of the dictionary holds the parameter ids,
while the values are GaussianConstraint objects
with values, errors and correlation of the parameters.

\end{description}\end{quote}

\end{fulllineitems}

\index{round\_to\_significance() (in module kafe.fit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.fit.round_to_significance}\pysiglinewithargsret{\code{kafe.fit.}\bfcode{round\_to\_significance}}{\emph{value}, \emph{error}, \emph{significance=2}}{}
Rounds the error to the established number of significant digits, then
rounds the value to the same order of magnitude as the error.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{value}} (\emph{float}) -- value to round to significance

\item {} 
\textbf{\texttt{error}} (\emph{float}) -- uncertainty of the value

\end{itemize}

\item[{Keyword Arguments}] \leavevmode
\textbf{significance} (\emph{int, optional}) --
number of significant digits of the error to consider

\end{description}\end{quote}

\end{fulllineitems}



\subsection{\texttt{Plot}: Graphical representation of a \texttt{Fit} (\texttt{kafe.plot})}
\label{module_doc:module-kafe.plot}\label{module_doc:plot-graphical-representation-of-a-fit-kafe-plot}\index{kafe.plot (module)}\phantomsection\label{module_doc:module-plot}\index{plot (module)}\index{Plot (class in kafe.plot)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot}\pysiglinewithargsret{\strong{class }\code{kafe.plot.}\bfcode{Plot}}{\emph{*fits}, \emph{**kwargs}}{}
Bases: \code{object}

The constuctor accepts a series of \emph{Fit} objects as positional
arguments. Some keyword arguments can be provided to override
the defaults.
\index{axis\_labels (kafe.plot.Plot attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.axis_labels}\pysigline{\bfcode{axis\_labels}\strong{ = None}}
axis labels

\end{fulllineitems}

\index{compute\_plot\_range() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.compute_plot_range}\pysiglinewithargsret{\bfcode{compute\_plot\_range}}{\emph{include\_error\_bars=True}}{}
Compute the span of all child datasets and sets the plot range to that

\end{fulllineitems}

\index{draw\_fit\_parameters\_box() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.draw_fit_parameters_box}\pysiglinewithargsret{\bfcode{draw\_fit\_parameters\_box}}{\emph{plot\_spec=0}, \emph{force\_show\_uncertainties=False}}{}
Draw the parameter box to the canvas
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{plot\_spec}} (\emph{int, list of ints, string or None (optional, default: 0)}) -- Specify the plot id of the plot for which to draw the parameters.
Passing 0 will only draw the parameter box for the first plot, and
so on. Passing a list of ints will only draw the parameters for
plot ids inside the list. Passing \code{'all'} will print parameters
for all plots. Passing \code{None} will return immediately doing
nothing.

\item {} 
\textbf{\texttt{force\_show\_uncertainties}} (\emph{boolean (optional, default: False)}) -- If \code{True}, shows uncertainties even for Datasets without error
data. Note that in that case these values are meaningless!

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{draw\_legend() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.draw_legend}\pysiglinewithargsret{\bfcode{draw\_legend}}{}{}
Draw the plot legend to the canvas

\end{fulllineitems}

\index{extend\_span() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.extend_span}\pysiglinewithargsret{\bfcode{extend\_span}}{\emph{axis}, \emph{new\_span}}{}
Expand the span of the current plot.

This method extends the current plot span to include \emph{new\_span}

\end{fulllineitems}

\index{fits (kafe.plot.Plot attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.fits}\pysigline{\bfcode{fits}\strong{ = None}}
list of \code{Fit} objects to plot

\end{fulllineitems}

\index{init\_plots() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.init_plots}\pysiglinewithargsret{\bfcode{init\_plots}}{\emph{**kwargs}}{}
Initialize the plots for each fit.

\end{fulllineitems}

\index{on\_draw() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.on_draw}\pysiglinewithargsret{\bfcode{on\_draw}}{\emph{event}}{}
Function to call when a draw event occurs.

\end{fulllineitems}

\index{plot() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.plot}\pysiglinewithargsret{\bfcode{plot}}{\emph{p\_id}, \emph{show\_data=True}, \emph{show\_function=True}, \emph{show\_band=True}}{}
Plot the \emph{Fit} object with the number \emph{p\_id} to its figure.

\end{fulllineitems}

\index{plot\_all() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.plot_all}\pysiglinewithargsret{\bfcode{plot\_all}}{\emph{show\_info\_for='all'}, \emph{show\_data\_for='all'}, \emph{show\_function\_for='all'}, \emph{show\_band\_for='meaningful'}}{}
Plot every \emph{Fit} object to its figure.

\end{fulllineitems}

\index{plot\_range (kafe.plot.Plot attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.plot_range}\pysigline{\bfcode{plot\_range}\strong{ = None}}
plot range

\end{fulllineitems}

\index{plot\_style (kafe.plot.Plot attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.plot_style}\pysigline{\bfcode{plot\_style}\strong{ = None}}
plot style

\end{fulllineitems}

\index{save() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.save}\pysiglinewithargsret{\bfcode{save}}{\emph{output\_file}}{}
Save the \emph{Plot} to a file.

\end{fulllineitems}

\index{set\_axis\_scale() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.set_axis_scale}\pysiglinewithargsret{\bfcode{set\_axis\_scale}}{\emph{axis}, \emph{scale\_type}, \emph{**kwargs}}{}
Set the scale for an axis.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{axis}} (\emph{`'x'' or `'y'`}) -- Axis for which to set the scale.

\item {} 
\textbf{\texttt{scale\_type}} (\emph{`'linear'' or `'log'`}) -- Type of scale to set for the axis.

\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{**basex**} (\emph{int}) --
Base of the `'x'' axis scale logarithm. Only relevant for log
scales.

\item {} 
\textbf{**basey**} (\emph{int}) --
Base of the `'y'' axis scale logarithm. Only relevant for log
scales.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{show() (kafe.plot.Plot method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.show}\pysiglinewithargsret{\bfcode{show}}{}{}
Show graphics in one or more matplotlib interactive windows.

\begin{notice}{note}{Note:}
This shows all figures/plots generated before it is called. Because
of the way \code{matplotlib} handles some plotting parameters
(\code{matplotlib.rcParams}) these cannot be set individually for each
figure before it is displayed. This means that all figures will be
shown with the same plot style: that of the \emph{Plot} object from
which show() is called.
\end{notice}

\end{fulllineitems}

\index{show\_legend (kafe.plot.Plot attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.Plot.show_legend}\pysigline{\bfcode{show\_legend}\strong{ = None}}
whether to show the plot legend (\code{True}) or not (\code{False})

\end{fulllineitems}


\end{fulllineitems}

\index{PlotStyle (class in kafe.plot)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.PlotStyle}\pysigline{\strong{class }\code{kafe.plot.}\bfcode{PlotStyle}}
Class for specifying a style for a specific plot. This object stores a
progression of marker and line types and colors, as well as preferences
relating to point size and label size. These can be overriden by
overwriting the instance variables directly. A series of \emph{get\_...} methods
are provided which go through these lists cyclically.
\index{get\_line() (kafe.plot.PlotStyle method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.PlotStyle.get_line}\pysiglinewithargsret{\bfcode{get\_line}}{\emph{idm}}{}
Get a specific line type. This runs cyclically through the defined
defaults.

\end{fulllineitems}

\index{get\_linecolor() (kafe.plot.PlotStyle method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.PlotStyle.get_linecolor}\pysiglinewithargsret{\bfcode{get\_linecolor}}{\emph{idm}}{}
Get a specific line color. This runs cyclically through the defined
defaults.

\end{fulllineitems}

\index{get\_marker() (kafe.plot.PlotStyle method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.PlotStyle.get_marker}\pysiglinewithargsret{\bfcode{get\_marker}}{\emph{idm}}{}
Get a specific marker type. This runs cyclically through the defined
defaults.

\end{fulllineitems}

\index{get\_markercolor() (kafe.plot.PlotStyle method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.PlotStyle.get_markercolor}\pysiglinewithargsret{\bfcode{get\_markercolor}}{\emph{idm}}{}
Get a specific marker color. This runs cyclically through the
defined defaults.

\end{fulllineitems}

\index{get\_pointsize() (kafe.plot.PlotStyle method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.PlotStyle.get_pointsize}\pysiglinewithargsret{\bfcode{get\_pointsize}}{\emph{idm}}{}
Get a specific point size. This runs cyclically through the defined
defaults.

\end{fulllineitems}


\end{fulllineitems}

\index{label\_to\_latex() (in module kafe.plot)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.label_to_latex}\pysiglinewithargsret{\code{kafe.plot.}\bfcode{label\_to\_latex}}{\emph{label}}{}
Generates a simple LaTeX-formatted label from a plain-text label.
This treats isolated characters and words beginning with a backslash
as mathematical expressions and surround them with \$ signs accordingly.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{label}} (\emph{string}) -- Plain-text string to convert to LaTeX.

\end{description}\end{quote}

\end{fulllineitems}

\index{pad\_span() (in module kafe.plot)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.pad_span}\pysiglinewithargsret{\code{kafe.plot.}\bfcode{pad\_span}}{\emph{span}, \emph{pad\_coeff=1}, \emph{additional\_pad=None}}{}
Enlarges the interval \emph{span} (list of two floats) symmetrically around
its center to length \emph{pad\_coeff}. Optionally, an \emph{additional\_pad} argument
can be specified. The returned span is then additionally enlarged by that
amount.

\emph{additional\_pad} can also be a list of two floats which specifies an
asymmetric amount by which to enlarge the span. Note that in this case,
positive entries in \emph{additional\_pad} will enlarge the span (move the
interval end away from the interval center) and negative amounts will
shorten it (move the interval end towards the interval center).

\end{fulllineitems}

\index{pad\_span\_log() (in module kafe.plot)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.plot.pad_span_log}\pysiglinewithargsret{\code{kafe.plot.}\bfcode{pad\_span\_log}}{\emph{span}, \emph{pad\_coeff=1}, \emph{additional\_pad=None}, \emph{base=10}}{}
\end{fulllineitems}



\section{Interfaces to external packages}
\label{module_doc:interfaces-to-external-packages}

\subsection{Interface to ROOT's \texttt{TMinuit} (\texttt{kafe.minuit})}
\label{module_doc:module-kafe.minuit}\label{module_doc:interface-to-root-s-tminuit-kafe-minuit}\index{kafe.minuit (module)}\phantomsection\label{module_doc:module-minuit}\index{minuit (module)}\index{D\_MATRIX\_ERROR (in module kafe.minuit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.D_MATRIX_ERROR}\pysigline{\code{kafe.minuit.}\bfcode{D\_MATRIX\_ERROR}\strong{ = \{0: `Error matrix not calculated', 1: `Error matrix approximate!', 2: `Error matrix forced positive definite!', 3: `Error matrix accurate'\}}}
Error matrix status codes

\end{fulllineitems}

\index{Minuit (class in kafe.minuit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit}\pysiglinewithargsret{\strong{class }\code{kafe.minuit.}\bfcode{Minuit}}{\emph{number\_of\_parameters}, \emph{function\_to\_minimize}, \emph{parameter\_names}, \emph{start\_parameters}, \emph{parameter\_errors}, \emph{quiet=True}, \emph{verbose=False}}{}
A class for communicating with ROOT's function minimizer tool Minuit.
\index{FCN\_wrapper() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.FCN_wrapper}\pysiglinewithargsret{\bfcode{FCN\_wrapper}}{\emph{number\_of\_parameters}, \emph{derivatives}, \emph{f}, \emph{parameters}, \emph{internal\_flag}}{}
This is actually a function called in \emph{ROOT} and acting as a C wrapper
for our \emph{FCN}, which is implemented in Python.

This function is called by \emph{Minuit} several times during a fit. It
doesn't return anything but modifies one of its arguments (\emph{f}).
This is \emph{ugly}, but it's how \emph{ROOT}`s \code{TMinuit} works. Its argument
structure is fixed and determined by \emph{Minuit}:
\begin{description}
\item[{\textbf{number\_of\_parameters}}] \leavevmode{[}int{]}
The number of parameters of the current fit

\item[{\textbf{derivatives}}] \leavevmode{[}C array{]}
If the user chooses to calculate the first derivative of the
function inside the \emph{FCN}, this value should be written here. This
interface to \emph{Minuit} ignores this derivative, however, so
calculating this inside the \emph{FCN} has no effect (yet).

\item[{\textbf{f}}] \leavevmode{[}C array{]}
The desired function value is in f{[}0{]} after execution.

\item[{\textbf{parameters}}] \leavevmode{[}C array{]}
A C array of parameters. Is cast to a Python list

\item[{\textbf{internal\_flag}}] \leavevmode{[}int{]}
A flag allowing for different behaviour of the function.
Can be any integer from 1 (initial run) to 4(normal run). See
\emph{Minuit}`s specification.

\end{description}

\end{fulllineitems}

\index{fix\_parameter() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.fix_parameter}\pysiglinewithargsret{\bfcode{fix\_parameter}}{\emph{parameter\_number}}{}
Fix parameter number \textless{}\emph{parameter\_number}\textgreater{}.
\begin{description}
\item[{\textbf{parameter\_number}}] \leavevmode{[}int{]}
Number of the parameter to fix.

\end{description}

\end{fulllineitems}

\index{function\_to\_minimize (kafe.minuit.Minuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.function_to_minimize}\pysigline{\bfcode{function\_to\_minimize}\strong{ = None}}
the actual \emph{FCN} called in \code{FCN\_wrapper}

\end{fulllineitems}

\index{get\_chi2\_probability() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_chi2_probability}\pysiglinewithargsret{\bfcode{get\_chi2\_probability}}{\emph{n\_deg\_of\_freedom}}{}
Returns the probability that an observed \(\chi^2\) exceeds
the calculated value of \(\chi^2\) for this fit by chance,
even for a correct model. In other words, returns the probability that
a worse fit of the model to the data exists. If this is a small value
(typically \textless{}5\%), this means the fit is pretty bad. For values below
this threshold, the model very probably does not fit the data.
\begin{description}
\item[{n\_def\_of\_freedom}] \leavevmode{[}int{]}
The number of degrees of freedom. This is typically
\(n_   ext{datapoints} - n_    ext{parameters}\).

\end{description}

\end{fulllineitems}

\index{get\_contour() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_contour}\pysiglinewithargsret{\bfcode{get\_contour}}{\emph{parameter1}, \emph{parameter2}, \emph{n\_points=21}}{}
Returns a list of points (2-tuples) representing a sampling of
the \(1\sigma\) contour of the TMinuit fit. The \code{FCN} has
to be minimized before calling this.
\begin{description}
\item[{\textbf{parameter1}}] \leavevmode{[}int{]}
ID of the parameter to be displayed on the \emph{x}-axis.

\item[{\textbf{parameter2}}] \leavevmode{[}int{]}
ID of the parameter to be displayed on the \emph{y}-axis.

\item[{\emph{n\_points}}] \leavevmode{[}int (optional){]}
number of points used to draw the contour. Default is 21.

\item[{\emph{returns}}] \leavevmode{[}2-tuple of tuples{]}
a 2-tuple (x, y) containing \code{n\_points+1} points sampled
along the contour. The first point is repeated at the end
of the list to generate a closed contour.

\end{description}

\end{fulllineitems}

\index{get\_error\_matrix() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_error_matrix}\pysiglinewithargsret{\bfcode{get\_error\_matrix}}{}{}
Retrieves the parameter error matrix from TMinuit.

return : \emph{numpy.matrix}

\end{fulllineitems}

\index{get\_fit\_info() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_fit_info}\pysiglinewithargsret{\bfcode{get\_fit\_info}}{\emph{info}}{}
Retrieves other info from \emph{Minuit}.
\begin{description}
\item[{\textbf{info}}] \leavevmode{[}string{]}
Information about the fit to retrieve.
This can be any of the following:
\begin{itemize}
\item {} 
\code{'fcn'}: \emph{FCN} value at minimum,

\item {} 
\code{'edm'}: estimated distance to minimum

\item {} 
\code{'err\_def'}: \emph{Minuit} error matrix status code

\item {} 
\code{'status\_code'}: \emph{Minuit} general status code

\end{itemize}

\end{description}

\end{fulllineitems}

\index{get\_parameter\_errors() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_parameter_errors}\pysiglinewithargsret{\bfcode{get\_parameter\_errors}}{}{}
Retrieves the parameter errors from TMinuit.
\begin{description}
\item[{return}] \leavevmode{[}tuple{]}
Current \emph{Minuit} parameter errors

\end{description}

\end{fulllineitems}

\index{get\_parameter\_info() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_parameter_info}\pysiglinewithargsret{\bfcode{get\_parameter\_info}}{}{}
Retrieves parameter information from TMinuit.
\begin{description}
\item[{return}] \leavevmode{[}list of tuples{]}
\code{(parameter\_name, parameter\_val, parameter\_error)}

\end{description}

\end{fulllineitems}

\index{get\_parameter\_name() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_parameter_name}\pysiglinewithargsret{\bfcode{get\_parameter\_name}}{\emph{parameter\_nr}}{}
Gets the name of parameter number \code{parameter\_nr}
\begin{description}
\item[{\textbf{parameter\_nr}}] \leavevmode{[}int{]}
Number of the parameter whose name to get.

\end{description}

\end{fulllineitems}

\index{get\_parameter\_values() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_parameter_values}\pysiglinewithargsret{\bfcode{get\_parameter\_values}}{}{}
Retrieves the parameter values from TMinuit.
\begin{description}
\item[{return}] \leavevmode{[}tuple{]}
Current \emph{Minuit} parameter values

\end{description}

\end{fulllineitems}

\index{get\_profile() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.get_profile}\pysiglinewithargsret{\bfcode{get\_profile}}{\emph{parid}, \emph{n\_points=21}}{}
Returns a list of points (2-tuples) the profile
the \(\chi^2\)  of the TMinuit fit.
\begin{description}
\item[{\textbf{parid}}] \leavevmode{[}int{]}
ID of the parameter to be displayed on the \emph{x}-axis.

\item[{\emph{n\_points}}] \leavevmode{[}int (optional){]}
number of points used for profile. Default is 21.

\item[{\emph{returns}}] \leavevmode{[}two arrays, par. values and corresp. \(\chi^2\){]}
containing \code{n\_points} sampled profile points.

\end{description}

\end{fulllineitems}

\index{max\_iterations (kafe.minuit.Minuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.max_iterations}\pysigline{\bfcode{max\_iterations}\strong{ = None}}
maximum number of iterations until \code{TMinuit} gives up

\end{fulllineitems}

\index{minimize() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.minimize}\pysiglinewithargsret{\bfcode{minimize}}{\emph{final\_fit=True}, \emph{log\_print\_level=2}}{}
Do the minimization. This calls \emph{Minuit}`s algorithms \code{MIGRAD}
for minimization and, if \emph{final\_fit} is \emph{True}, also \code{HESSE}
for computing/checking the parameter error matrix.

\end{fulllineitems}

\index{minos\_errors() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.minos_errors}\pysiglinewithargsret{\bfcode{minos\_errors}}{\emph{log\_print\_level=1}}{}
Get (asymmetric) parameter uncertainties from MINOS
algorithm. This calls \emph{Minuit}`s algorithms \code{MINOS},
which determines parameter uncertainties using profiling
of the chi2 function.
\begin{description}
\item[{returns}] \leavevmode{[}tuple{]}
A tuple of {[}err+, err-, parabolic error, global correlation{]}

\end{description}

\end{fulllineitems}

\index{name (kafe.minuit.Minuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.name}\pysigline{\bfcode{name}\strong{ = None}}
the name of this minimizer type

\end{fulllineitems}

\index{number\_of\_parameters (kafe.minuit.Minuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.number_of_parameters}\pysigline{\bfcode{number\_of\_parameters}\strong{ = None}}
number of parameters to minimize for

\end{fulllineitems}

\index{release\_parameter() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.release_parameter}\pysiglinewithargsret{\bfcode{release\_parameter}}{\emph{parameter\_number}}{}
Release parameter number \textless{}\emph{parameter\_number}\textgreater{}.
\begin{description}
\item[{\textbf{parameter\_number}}] \leavevmode{[}int{]}
Number of the parameter to release.

\end{description}

\end{fulllineitems}

\index{reset() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.reset}\pysiglinewithargsret{\bfcode{reset}}{}{}
Execute TMinuit's \emph{mnrset} method.

\end{fulllineitems}

\index{set\_err() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.set_err}\pysiglinewithargsret{\bfcode{set\_err}}{\emph{up\_value=1.0}}{}
Sets the \code{UP} value for Minuit.
\begin{description}
\item[{\emph{up\_value}}] \leavevmode{[}float (optional, default: 1.0){]}
This is the value by which \emph{FCN} is expected to change.

\end{description}

\end{fulllineitems}

\index{set\_parameter\_errors() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.set_parameter_errors}\pysiglinewithargsret{\bfcode{set\_parameter\_errors}}{\emph{parameter\_errors=None}}{}
Sets the fit parameter errors. If parameter\_values={}`None{}`, sets the
error to 10\% of the parameter value.

\end{fulllineitems}

\index{set\_parameter\_names() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.set_parameter_names}\pysiglinewithargsret{\bfcode{set\_parameter\_names}}{\emph{parameter\_names}}{}
Sets the fit parameters. If parameter\_values={}`None{}`, tries to infer
defaults from the function\_to\_minimize.

\end{fulllineitems}

\index{set\_parameter\_values() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.set_parameter_values}\pysiglinewithargsret{\bfcode{set\_parameter\_values}}{\emph{parameter\_values}}{}~\begin{description}
\item[{Sets the fit parameters. If parameter\_values={}`None{}`, tries to infer}] \leavevmode
defaults from the function\_to\_minimize.

\end{description}

\end{fulllineitems}

\index{set\_print\_level() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.set_print_level}\pysiglinewithargsret{\bfcode{set\_print\_level}}{\emph{print\_level=1}}{}
Sets the print level for Minuit.
\begin{description}
\item[{\emph{print\_level}}] \leavevmode{[}int (optional, default: 1 (frugal output)){]}
Tells \code{TMinuit} how much output to generate. The higher this
value, the more output it generates.

\end{description}

\end{fulllineitems}

\index{set\_strategy() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.set_strategy}\pysiglinewithargsret{\bfcode{set\_strategy}}{\emph{strategy\_id=1}}{}
Sets the strategy Minuit.
\begin{description}
\item[{\emph{strategy\_id}}] \leavevmode{[}int (optional, default: 1 (optimized)){]}
Tells \code{TMinuit} to use a certain strategy. Refer to \code{TMinuit}`s
documentation for available strategies.

\end{description}

\end{fulllineitems}

\index{tolerance (kafe.minuit.Minuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.tolerance}\pysigline{\bfcode{tolerance}\strong{ = None}}
\code{TMinuit} tolerance

\end{fulllineitems}

\index{update\_parameter\_data() (kafe.minuit.Minuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.Minuit.update_parameter_data}\pysiglinewithargsret{\bfcode{update\_parameter\_data}}{\emph{show\_warnings=False}}{}
(Re-)Sets the parameter names, values and step size on the
C++ side of Minuit.

\end{fulllineitems}


\end{fulllineitems}

\index{P\_DETAIL\_LEVEL (in module kafe.minuit)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.minuit.P_DETAIL_LEVEL}\pysigline{\code{kafe.minuit.}\bfcode{P\_DETAIL\_LEVEL}\strong{ = 1}}
default level of detail for TMinuit's output
(typical range: -1 to 3, default: 1)

\end{fulllineitems}



\subsection{Interface to \texttt{iminuit} (\texttt{kafe.iminuit\_wrapper})}
\label{module_doc:module-kafe.iminuit_wrapper}\label{module_doc:interface-to-iminuit-kafe-iminuit-wrapper}\index{kafe.iminuit\_wrapper (module)}\phantomsection\label{module_doc:module-iminuit}\index{iminuit (module)}\index{D\_MATRIX\_ERROR (in module kafe.iminuit\_wrapper)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.D_MATRIX_ERROR}\pysigline{\code{kafe.iminuit\_wrapper.}\bfcode{D\_MATRIX\_ERROR}\strong{ = \{0: `Error matrix not calculated', 1: `Error matrix approximate!', 2: `Error matrix forced positive definite!', 3: `Error matrix accurate'\}}}
Error matrix status codes

\end{fulllineitems}

\index{IMinuit (class in kafe.iminuit\_wrapper)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit}\pysiglinewithargsret{\strong{class }\code{kafe.iminuit\_wrapper.}\bfcode{IMinuit}}{\emph{number\_of\_parameters}, \emph{function\_to\_minimize}, \emph{parameter\_names}, \emph{start\_parameters}, \emph{parameter\_errors}, \emph{quiet=True}, \emph{verbose=False}}{}
A wrapper class for iminuit.
\index{FCN\_wrapper() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.FCN_wrapper}\pysiglinewithargsret{\bfcode{FCN\_wrapper}}{\emph{**kw\_parameters}}{}
This wrapper converts from the ``keyword argument'' way of calling the
function to a ``positional argument'' way, taking into account the order
of the parameters as they appear in \emph{self.parameter\_names}.

This mapping is done for each call, so it's quite resource intensive,
but this is unavoidable, since external FCNs to minimize expect
positional arguments.
\begin{description}
\item[{\textbf{kw\_parameters}}] \leavevmode{[}dict{]}
Map of parameter name to parameter value.

\end{description}

\end{fulllineitems}

\index{errordef (kafe.iminuit\_wrapper.IMinuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.errordef}\pysigline{\bfcode{errordef}\strong{ = None}}
\code{iminuit} errordef

\end{fulllineitems}

\index{fix\_parameter() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.fix_parameter}\pysiglinewithargsret{\bfcode{fix\_parameter}}{\emph{parameter}}{}
Fix parameter \textless{}\emph{parameter}\textgreater{}.
\begin{description}
\item[{\textbf{parameter}}] \leavevmode{[}string{]}
Name of the parameter to fix.

\end{description}

\end{fulllineitems}

\index{function\_to\_minimize (kafe.iminuit\_wrapper.IMinuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.function_to_minimize}\pysigline{\bfcode{function\_to\_minimize}\strong{ = None}}
the actual \emph{FCN} called in \code{FCN\_wrapper}

\end{fulllineitems}

\index{get\_chi2\_probability() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_chi2_probability}\pysiglinewithargsret{\bfcode{get\_chi2\_probability}}{\emph{n\_deg\_of\_freedom}}{}
Returns the probability that an observed \(\chi^2\) exceeds
the calculated value of \(\chi^2\) for this fit by chance,
even for a correct model. In other words, returns the probability that
a worse fit of the model to the data exists. If this is a small value
(typically \textless{}5\%), this means the fit is pretty bad. For values below
this threshold, the model very probably does not fit the data.
\begin{description}
\item[{n\_def\_of\_freedom}] \leavevmode{[}int{]}
The number of degrees of freedom. This is typically
\(n_   ext{datapoints} - n_    ext{parameters}\).

\end{description}

\end{fulllineitems}

\index{get\_contour() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_contour}\pysiglinewithargsret{\bfcode{get\_contour}}{\emph{parameter1}, \emph{parameter2}, \emph{n\_points=21}}{}
Returns a list of points (2-tuples) representing a sampling of
the \(1\sigma\) contour of the iminuit fit. The \code{FCN} has
to be minimized before calling this.
\begin{description}
\item[{\textbf{parameter1}}] \leavevmode{[}int{]}
ID of the parameter to be displayed on the \emph{x}-axis.

\item[{\textbf{parameter2}}] \leavevmode{[}int{]}
ID of the parameter to be displayed on the \emph{y}-axis.

\item[{\emph{n\_points}}] \leavevmode{[}int (optional){]}
number of points used to draw the contour. Default is 21.

\item[{\emph{returns}}] \leavevmode{[}2-tuple of tuples{]}
a 2-tuple (x, y) containing \code{n\_points+1} points sampled
along the contour. The first point is repeated at the end
of the list to generate a closed contour.

\end{description}

\end{fulllineitems}

\index{get\_error\_matrix() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_error_matrix}\pysiglinewithargsret{\bfcode{get\_error\_matrix}}{\emph{correlation=False}}{}
Retrieves the parameter error matrix from iminuit.
\begin{description}
\item[{correlation}] \leavevmode{[}boolean (optional, default \code{False}){]}
If \code{True}, return correlation matrix, else return
covariance matrix.

\end{description}

return : \emph{numpy.matrix}

\end{fulllineitems}

\index{get\_fit\_info() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_fit_info}\pysiglinewithargsret{\bfcode{get\_fit\_info}}{\emph{info}}{}
Retrieves other info from \emph{Minuit}.
\begin{description}
\item[{\textbf{info}}] \leavevmode{[}string{]}
Information about the fit to retrieve.
This can be any of the following:
\begin{itemize}
\item {} 
\code{'fcn'}: \emph{FCN} value at minimum,

\item {} 
\code{'edm'}: estimated distance to minimum

\item {} 
\code{'err\_def'}: \emph{Minuit} error matrix status code

\item {} 
\code{'status\_code'}: \emph{Minuit} general status code

\end{itemize}

\end{description}

\end{fulllineitems}

\index{get\_parameter\_errors() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_parameter_errors}\pysiglinewithargsret{\bfcode{get\_parameter\_errors}}{}{}
Retrieves the parameter errors from iminuit.
\begin{description}
\item[{return}] \leavevmode{[}tuple{]}
Current \emph{Minuit} parameter errors

\end{description}

\end{fulllineitems}

\index{get\_parameter\_info() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_parameter_info}\pysiglinewithargsret{\bfcode{get\_parameter\_info}}{}{}
Retrieves parameter information from iminuit.
\begin{description}
\item[{return}] \leavevmode{[}list of tuples{]}
\code{(parameter\_name, parameter\_val, parameter\_error)}

\end{description}

\end{fulllineitems}

\index{get\_parameter\_name() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_parameter_name}\pysiglinewithargsret{\bfcode{get\_parameter\_name}}{\emph{parameter\_nr}}{}
Gets the name of parameter number \code{parameter\_nr}
\begin{description}
\item[{\textbf{parameter\_nr}}] \leavevmode{[}int{]}
Number of the parameter whose name to get.

\end{description}

\end{fulllineitems}

\index{get\_parameter\_values() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_parameter_values}\pysiglinewithargsret{\bfcode{get\_parameter\_values}}{}{}
Retrieves the parameter values from iminuit.
\begin{description}
\item[{return}] \leavevmode{[}tuple{]}
Current \emph{Minuit} parameter values

\end{description}

\end{fulllineitems}

\index{get\_profile() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.get_profile}\pysiglinewithargsret{\bfcode{get\_profile}}{\emph{parameter}, \emph{n\_points=21}}{}
Returns a list of points (2-tuples) the profile
the \(\chi^2\)  of the iminuit fit.
\begin{description}
\item[{\textbf{parid}}] \leavevmode{[}int{]}
ID of the parameter to be displayed on the \emph{x}-axis.

\item[{\emph{n\_points}}] \leavevmode{[}int (optional){]}
number of points used for profile. Default is 21.

\item[{\emph{returns}}] \leavevmode{[}two arrays, par. values and corresp. \(\chi^2\){]}
containing \code{n\_points} sampled profile points.

\end{description}

\end{fulllineitems}

\index{max\_iterations (kafe.iminuit\_wrapper.IMinuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.max_iterations}\pysigline{\bfcode{max\_iterations}\strong{ = None}}
maximum number of iterations until \code{iminuit} gives up

\end{fulllineitems}

\index{minimize() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.minimize}\pysiglinewithargsret{\bfcode{minimize}}{\emph{final\_fit=True}, \emph{log\_print\_level=2}}{}
Do the minimization. This calls \emph{Minuit}`s algorithms \code{MIGRAD}
for minimization and, if \emph{final\_fit} is \emph{True}, also \code{HESSE}
for computing/checking the parameter error matrix.

\end{fulllineitems}

\index{minos\_errors() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.minos_errors}\pysiglinewithargsret{\bfcode{minos\_errors}}{\emph{log\_print\_level=1}}{}
Get (asymmetric) parameter uncertainties from MINOS
algorithm. This calls \emph{Minuit}`s algorithms \code{MINOS},
which determines parameter uncertainties using profiling
of the chi2 function.
\begin{description}
\item[{returns}] \leavevmode{[}tuple{]}
A tuple of (err+, err-, parabolic error, global correlation)

\end{description}

\end{fulllineitems}

\index{name (kafe.iminuit\_wrapper.IMinuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.name}\pysigline{\bfcode{name}\strong{ = None}}
the name of this minimizer type

\end{fulllineitems}

\index{number\_of\_parameters (kafe.iminuit\_wrapper.IMinuit attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.number_of_parameters}\pysigline{\bfcode{number\_of\_parameters}\strong{ = None}}
number of parameters to minimize for

\end{fulllineitems}

\index{release\_parameter() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.release_parameter}\pysiglinewithargsret{\bfcode{release\_parameter}}{\emph{parameter}}{}
Release parameter \textless{}\emph{parameter}\textgreater{}.
\begin{description}
\item[{\textbf{parameter}}] \leavevmode{[}string{]}
Name of the parameter to release.

\end{description}

\end{fulllineitems}

\index{reset() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.reset}\pysiglinewithargsret{\bfcode{reset}}{}{}
Resets iminuit by re-creating the minimizer.

\end{fulllineitems}

\index{set\_err() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_err}\pysiglinewithargsret{\bfcode{set\_err}}{\emph{up\_value=1.0}}{}
Sets the \code{UP} value for Minuit.
\begin{description}
\item[{\emph{up\_value}}] \leavevmode{[}float (optional, default: 1.0){]}
This is the value by which \emph{FCN} is expected to change.

\end{description}

\end{fulllineitems}

\index{set\_parameter\_errors() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_parameter_errors}\pysiglinewithargsret{\bfcode{set\_parameter\_errors}}{\emph{parameter\_errors=None}, \emph{update\_iminuit=True}}{}
Sets the fit parameter errors. If parameter\_values={}`None{}`, sets the
error to 10\% of the parameter value.

\end{fulllineitems}

\index{set\_parameter\_names() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_parameter_names}\pysiglinewithargsret{\bfcode{set\_parameter\_names}}{\emph{parameter\_names}, \emph{update\_iminuit=True}}{}
Sets the fit parameter names.

\end{fulllineitems}

\index{set\_parameter\_values() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_parameter_values}\pysiglinewithargsret{\bfcode{set\_parameter\_values}}{\emph{parameter\_values}, \emph{update\_iminuit=True}}{}~\begin{description}
\item[{Sets the fit parameters. If parameter\_values={}`None{}`, tries to infer}] \leavevmode
defaults from the function\_to\_minimize.

\end{description}

\end{fulllineitems}

\index{set\_print\_level() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_print_level}\pysiglinewithargsret{\bfcode{set\_print\_level}}{\emph{print\_level=1}}{}
Sets the print level for Minuit.
\begin{description}
\item[{\emph{print\_level}}] \leavevmode{[}int (optional, default: 1 (frugal output)){]}
Tells \code{iminuit} how much output to generate. The higher this
value, the more output it generates.

\end{description}

\end{fulllineitems}

\index{set\_strategy() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_strategy}\pysiglinewithargsret{\bfcode{set\_strategy}}{\emph{strategy\_id=1}}{}
Sets the strategy Minuit.
\begin{description}
\item[{\emph{strategy\_id}}] \leavevmode{[}int (optional, default: 1 (optimized)){]}
Tells \code{iminuit} to use a certain strategy. Refer to \code{iminuit}`s
documentation for available strategies.

\end{description}

\end{fulllineitems}

\index{set\_tolerance() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.set_tolerance}\pysiglinewithargsret{\bfcode{set\_tolerance}}{\emph{tol}}{}
Sets the tolerance value for Minuit.
\begin{description}
\item[{\textbf{tol}}] \leavevmode{[}float{]}
The tolerance

\end{description}

\end{fulllineitems}

\index{update\_parameter\_data() (kafe.iminuit\_wrapper.IMinuit method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.IMinuit.update_parameter_data}\pysiglinewithargsret{\bfcode{update\_parameter\_data}}{\emph{show\_warnings=False}}{}
(Re-)Sets the parameter names, values and step size in iminuit.

\end{fulllineitems}


\end{fulllineitems}

\index{P\_DETAIL\_LEVEL (in module kafe.iminuit\_wrapper)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.iminuit_wrapper.P_DETAIL_LEVEL}\pysigline{\code{kafe.iminuit\_wrapper.}\bfcode{P\_DETAIL\_LEVEL}\strong{ = 1}}
default level of detail for iminuit's output
(typical range: -1 to 3, default: 1)

\end{fulllineitems}



\section{\emph{kafe} configuration}
\label{module_doc:kafe-configuration}

\subsection{\emph{kafe} configuration (\texttt{kafe.config})}
\label{module_doc:kafe-configuration-kafe-config}\label{module_doc:module-kafe.config}\index{kafe.config (module)}\phantomsection\label{module_doc:module-config}\index{config (module)}\index{create\_config\_file() (in module kafe.config)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.config.create_config_file}\pysiglinewithargsret{\code{kafe.config.}\bfcode{create\_config\_file}}{\emph{config\_type}, \emph{force=False}}{}
Create a kafe config file.
\begin{description}
\item[{\textbf{config\_type}}] \leavevmode{[}`user' or `local'{]}
Create a `user' config file in `\textasciitilde{}/.config/kafe' or a
`local' one in the current directory.

\item[{\emph{force}}] \leavevmode{[}boolean (optional){]}
If true, overwrites existing files.

\end{description}

\end{fulllineitems}

\index{log\_file() (in module kafe.config)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.config.log_file}\pysiglinewithargsret{\code{kafe.config.}\bfcode{log\_file}}{\emph{file\_relative\_path}}{}
Returns correct location for placing log files.

\end{fulllineitems}



\section{Modules with helper tools}
\label{module_doc:modules-with-helper-tools}

\subsection{For building datasets (\texttt{kafe.dataset\_tools})}
\label{module_doc:module-kafe.dataset_tools}\label{module_doc:for-building-datasets-kafe-dataset-tools}\index{kafe.dataset\_tools (module)}\phantomsection\label{module_doc:module-dataset_tools}\index{dataset\_tools (module)}\index{build\_dataset() (in module kafe.dataset\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.dataset_tools.build_dataset}\pysiglinewithargsret{\code{kafe.dataset\_tools.}\bfcode{build\_dataset}}{\emph{xdata}, \emph{ydata}, \emph{cov\_mats=None}, \emph{xabserr=0.0}, \emph{xrelerr=0.0}, \emph{xabscor=0.0}, \emph{xrelcor=0.0}, \emph{yabserr=0.0}, \emph{yrelerr=0.0}, \emph{yabscor=0.0}, \emph{yrelcor=0.0}, \emph{title=None}, \emph{axis\_labels=None}, \emph{axis\_units=None}, \emph{**kwargs}}{}
This helper function creates a \emph{Dataset} from a series of keyword
arguments.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{xdata}} (list/tuple/\emph{np.array} of floats) -- This keyword argument is mandatory and should be an iterable
containing \emph{x}-axis the measurement data.

\item {} 
\textbf{\texttt{ydata}} (list/tuple/\emph{np.array} of floats) -- This keyword argument is mandatory and should be an iterable
containing \emph{y}-axis the measurement data.

\item {} 
\textbf{\texttt{cov\_mats}} (\code{None} or 2-tuple, optional) -- 
This argument defaults to \code{None}, which means no covariance matrices
are used. If covariance matrices are needed, a tuple with two entries
(the first for \emph{x} covariance matrices, the second for \emph{y}) must be
passed.

Each element of this tuple may be either \code{None} or a NumPy matrix
object containing a covariance matrix for the respective axis.


\end{itemize}

\item[{Keyword Arguments}] \leavevmode\begin{itemize}
\item {} 
\textbf{error specification keywords} (\emph{iterable or numeric (see below)}) --
In addition to covariance matrices, errors can be specified for each
axis (\emph{x} or \emph{y}) according to a simplified error model.

In this respect, a valid keyword is composed of an axis, an error
relativity specification (\emph{abs} or \emph{rel}) and error correlation type
(\emph{err} or \emph{cor}). The errors are then set as follows:
\begin{enumerate}
\item {} \begin{description}
\item[{For totally uncorrelated errors (\emph{err}):}] \leavevmode\begin{itemize}
\item {} 
if keyword argument is iterable, the error list is set to that

\item {} 
if keyword argument is a number, an error list with identical entries is generated

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{For fully correlated errors (\emph{cor}):}] \leavevmode\begin{itemize}
\item {} 
keyword argument \emph{must} be a single number. The global correlated error for the axis is then set to that.

\end{itemize}

\end{description}

\end{enumerate}

So, for example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{my\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{build\PYGZus{}dataset}\PYG{p}{(}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{,} \PYG{n}{yabserr}\PYG{o}{=}\PYG{l+m+mf}{0.3}\PYG{p}{,} \PYG{n}{yrelcor}\PYG{o}{=}\PYG{l+m+mf}{0.1}\PYG{p}{)}
\end{Verbatim}

creates a Dataset with an uncorrelated error of 0.3 for each \emph{y}
coordinate and a fully correlated (systematic) error of \emph{y} of 0.1.

\item {} 
\textbf{title} (\emph{string, optional}) --
The title of the \emph{Dataset}.

\item {} 
\textbf{axis\_labels} (\emph{2-tuple of strings, optional}) --
a 2-tuple containing the axis labels for the \emph{Dataset}. This is
relevant when plotting \emph{Fits} of the \emph{Dataset}, but is ignored when
plotting more than one \emph{Fit} in the same \emph{Plot}.

\item {} 
\textbf{axis\_units} (\emph{2-tuple of strings, optional}) --
a 2-tuple containing the axis units for the \emph{Dataset}. This is
relevant when plotting \emph{Fits} of the \emph{Dataset}, but is ignored when
plotting more than one \emph{Fit} in the same \emph{Plot}.

\end{itemize}

\item[{Returns}] \leavevmode
\emph{Dataset} object constructed from data and error information

\item[{Return type}] \leavevmode
{\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset})

\end{description}\end{quote}

\end{fulllineitems}



\subsection{For parsing files (\texttt{kafe.file\_tools})}
\label{module_doc:module-kafe.file_tools}\label{module_doc:for-parsing-files-kafe-file-tools}\index{kafe.file\_tools (module)}\phantomsection\label{module_doc:module-file_tools}\index{file\_tools (module)}\index{buildDataset\_fromFile() (in module kafe.file\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.file_tools.buildDataset_fromFile}\pysiglinewithargsret{\code{kafe.file\_tools.}\bfcode{buildDataset\_fromFile}}{\emph{file\_to\_parse}}{}
Build a kafe {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) object from input file
with key words and file format defined in
{\hyperref[module_doc:kafe.file_tools.parse_general_inputfile]{\emph{\code{parse\_general\_inputfile()}}}} (\autopageref*{module_doc:kafe.file_tools.parse_general_inputfile})
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{file\_to\_parse}} (\emph{file-like object or string containing a file path}) -- The file to parse.

\item[{Returns}] \leavevmode
a {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) object
constructed with the help of the method
\code{kafe.dataset.Dataset.build\_dataset()}

\item[{Return type}] \leavevmode
py:class:\emph{\textasciitilde{}kafe.dataset.Dataset}

\end{description}\end{quote}

\end{fulllineitems}

\index{buildFit\_fromFile() (in module kafe.file\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.file_tools.buildFit_fromFile}\pysiglinewithargsret{\code{kafe.file\_tools.}\bfcode{buildFit\_fromFile}}{\emph{file\_to\_parse}}{}
Build a kafe {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object from input file with
keywords and file format defined in
{\hyperref[module_doc:kafe.file_tools.parse_general_inputfile]{\emph{\code{parse\_general\_inputfile()}}}} (\autopageref*{module_doc:kafe.file_tools.parse_general_inputfile})
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{file\_to\_parse}} (\emph{file-like object or string containing a file path}) -- The file to parse.

\item[{Returns}] \leavevmode
a {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object
constructed with the help of the methods
\code{build\_dataset()} and
\code{build\_fit()}

\item[{Return type}] \leavevmode
py:class:\emph{\textasciitilde{}kafe.fit.Fit}

\end{description}\end{quote}

\end{fulllineitems}

\index{parse\_column\_data() (in module kafe.file\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.file_tools.parse_column_data}\pysiglinewithargsret{\code{kafe.file\_tools.}\bfcode{parse\_column\_data}}{\emph{file\_to\_parse, field\_order='x,y', delimiter=' `, cov\_mat\_files=None, title='Untitled Dataset', basename=None, axis\_labels={[}'x', `y'{]}, axis\_units={[}'`, `'{]}}}{}
Parses a file which contains measurement data in a one-measurement-per-row
format. The field (column) order can be specified. It defaults to
\code{"x,y"}.
Valid field names are \emph{x}, \emph{y}, \emph{xabserr}, \emph{yabserr}, \emph{xrelerr},
\emph{yrelerr}. Another valid field name is \emph{ignore} which can be used to skip
a field.

A certain type of field can appear several times. If this is the case, all
specified errors are added in quadrature:
\begin{gather}
\begin{split}\sigma_{\text{tot}} = \sqrt{{\sigma_1}^2+{\sigma_2}^2+\dots}\end{split}\notag
\end{gather}
Every valid measurement data file \emph{must} have an \emph{x} and a \emph{y} field.

For more complex error models, errors and correlations may be specified as
covariance matrices. If this is desired, then any number of covariance
matrices (stored in separate files) may be specified for an axis by
using the \emph{cov\_mat\_files} argument.

Additionally, a delimiter can be specified. If this is a whitespace
character or omitted, any sequence of whitespace characters is assumed to
separate the data.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\textbf{\texttt{file\_to\_parse}} (\emph{file-like object or string containing a file path}) -- The file to parse.

\item {} 
\textbf{\texttt{field\_order}} (\emph{string, optional}) -- A string of comma-separated field names giving the order of the columns
in the file. Defaults to \code{'x,y'}.

\item {} 
\textbf{\texttt{delimiter}} (\emph{string, optional}) -- The field delimiter used in the file. Defaults to any whitespace.

\item {} 
\textbf{\texttt{cov\_mat\_files}} (\emph{several} (see below), optional) -- 
This argument defaults to \code{None}, which means no covariance matrices
are used. If covariance matrices are needed, a tuple with two entries
(the first for \emph{x} covariance matrices, the second for \emph{y}) must be
passed.

Each element of this tuple may be either \code{None}, a file or file-like
object, or an iterable containing files and file-like objects. Each
file should contain a covariance matrix for the respective axis.

When creating the \code{Dataset}, all given matrices are summed over.


\item {} 
\textbf{\texttt{title}} (\emph{string, optional}) -- The title of the \code{Dataset}.

\item {} 
\textbf{\texttt{basename}} (string or \code{None}, optional) -- A basename for the \code{Dataset}. All output files related to this dataset
will use this as a basename. If this is \code{None} (default), the
basename will be inferred from the filename.

\item {} 
\textbf{\texttt{axis\_labels}} (\emph{2-tuple of strings, optional}) -- a 2-tuple containing the axis labels for the \code{Dataset}. This is
relevant when plotting \code{Fits} of the \code{Dataset}, but is ignored when
plotting more than one \code{Fit} in the same \code{Plot}.

\item {} 
\textbf{\texttt{axis\_units}} (\emph{2-tuple of strings, optional}) -- a 2-tuple containing the axis units for the \code{Dataset}. This is
relevant when plotting \code{Fits} of the \code{Dataset}, but is ignored when
plotting more than one \code{Fit} in the same \code{Plot}.

\end{itemize}

\item[{Returns}] \leavevmode
A \emph{Dataset} built from the parsed file.

\item[{Return type}] \leavevmode
{\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset})

\end{description}\end{quote}

\end{fulllineitems}

\index{parse\_general\_inputfile() (in module kafe.file\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.file_tools.parse_general_inputfile}\pysiglinewithargsret{\code{kafe.file\_tools.}\bfcode{parse\_general\_inputfile}}{\emph{file\_to\_parse}}{}
This function can be used to specify \emph{kafe}
{\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) or {\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) objects
in a single input file, thus requiring minimal Python code. Keywords as
specified in a dictionary \code{tokens} specify all objects and parameters
needed by the functions {\hyperref[module_doc:kafe.dataset_tools.build_dataset]{\emph{\code{build\_dataset()}}}} (\autopageref*{module_doc:kafe.dataset_tools.build_dataset}) in
module {\hyperref[module_doc:module-kafe.dataset]{\emph{\code{dataset}}}} (\autopageref*{module_doc:module-kafe.dataset}) and {\hyperref[module_doc:kafe.fit.build_fit]{\emph{\code{build\_fit()}}}} (\autopageref*{module_doc:kafe.fit.build_fit}) in
module {\hyperref[module_doc:module-kafe.fit]{\emph{\code{fit}}}} (\autopageref*{module_doc:module-kafe.fit}).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\textbf{\texttt{file\_to\_parse}} (\emph{file-like object or string containing a file path}) -- The file to parse.

\item[{Returns}] \leavevmode
keyword lists to build a kafe {\hyperref[module_doc:kafe.dataset.Dataset]{\emph{\code{Dataset}}}} (\autopageref*{module_doc:kafe.dataset.Dataset}) or
{\hyperref[module_doc:kafe.fit.Fit]{\emph{\code{Fit}}}} (\autopageref*{module_doc:kafe.fit.Fit}) object with the helper functions
\emph{build\_dataset} or \emph{build\_fit}

\item[{Return type}] \leavevmode
(dataset\_kwargs, fit\_kwargs)

\end{description}\end{quote}

\textbf{Input file format}

The interpretation of the input data is driven by \emph{keywords}. All data
following a key must be of the same kind. A block of data ends when a
new key is specified. Comments can be introduced by \code{\#}.

Some keys only expect a single float or string-type value, given
on the same line, separated by a space (\code{' '}):

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZlt{}key\PYGZgt{} \PYGZlt{}value\PYGZgt{}
\end{Verbatim}

Other keys require multiple lines of input. For instance, the keys
\code{*xData} and \code{*yData} expect the following lines to be a table where
the first column corresponds to the data values and the second column
corresponds to the uncertainties:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZlt{}key\PYGZgt{}
\PYGZlt{}value1\PYGZgt{}  \PYGZlt{}uncertainty1\PYGZgt{}
\PYGZlt{}value2\PYGZgt{}  \PYGZlt{}uncertainty2\PYGZgt{}
...
\PYGZlt{}valueN\PYGZgt{}  \PYGZlt{}uncertaintyN\PYGZgt{}
\end{Verbatim}

The column separator is space (\code{' '}). For more details about input
data specification, see {\hyperref[module_doc:specifying-input-data]{\emph{\DUspan{}{below}}}} (\autopageref*{module_doc:specifying-input-data}).

\textbf{Specifying metadata}
\begin{quote}

\begin{tabulary}{\linewidth}{|l|l|}
\hline
\textsf{\relax 
\textbf{Key}
} & \textsf{\relax 
\textbf{Description}
}\\
\hline
\code{*TITLE}
 & 
name of the dataset
\\
\hline
\code{*BASENAME}
 & 
name from which output
file names is derived
\\
\hline
\code{*FITLABEL}
 & 
fit label
\\
\hline
\code{*xLabel}
 & 
x axis label
\\
\hline
\code{*xUnit}
 & 
x axis unit
\\
\hline
\code{*yLabel}
 & 
y axis label
\\
\hline
\code{*yUnit}
 & 
y axis unit
\\
\hline\end{tabulary}

\end{quote}

The fit label may be set using the key \code{*FITLABEL}, followed by the
desired name for the fit.
\phantomsection\label{module_doc:specifying-input-data}
\textbf{Specifying input data}

Input data are given as a list of values (one datapoint per row). For a
simple uncertainty model (no correlations), the keys \code{*xData} and
\code{*yData} are used. The second column indicates the uncertainty of the
measurement:

\begin{Verbatim}[commandchars=\\\{\}]
*xData
1.2
3.4
6.9

*yData
2.1       0.2
3.9       0.3
8.2       0.5
\end{Verbatim}

\begin{notice}{note}{Note:}
Uncertainties always have to be specified for \code{*yData}. For
\code{*xData}, they are optional.
\end{notice}

For input data with correlated uncertainties, the alternative keys
\code{*xData\_COR} and \code{*yData\_COR} are provided. For these, additional
columns must be given. The second and third column indicate the
uncorrelated and correlated uncertainties, respectively. The subequent
columns contain the correlation matrix (a lower triangular matrix
containing the correlation coefficients):

\begin{Verbatim}[commandchars=\\\{\}]
*yData\PYGZus{}COR
\PYGZsh{} value  indep.uncert.  syst.uncert.  elements of corr. matrix.
2.1      0.2            0.1
3.9      0.3            0.2           1.0
8.2      0.5            0.3           1.0        1.0
\end{Verbatim}

\begin{notice}{note}{Note:}
Only elements below the main diagonal of the correlation matrix have
to be specified. Since the matrix is symmetric by construction, the
elements above the main diagonal can be inferred from those below.
Additionally, since the diagonal elements of a correlation matrix are
always equal to 1 by definition, they are also omitted.
\end{notice}

As an alternative to specifying the correlation matrix, the covariance
matrix may be specified directly. There are two ways to do this:

The keys \code{*xData\_SCOV} and \code{*yData\_SCOV} allow specifying the
covariance matrix by providing a correlated uncertainty (third column)
and the square root of the elements below the main diagonal. This is
useful if the pairwise covariance of two measurements cannot be
expressed using the correlation coefficient and needs to be provided
explicitly.

In the example below, there is a correlation between the first two and
the last two measurements, which is estimated under the assumption that
the smaller of the two uncertainties represents a common error:

\begin{Verbatim}[commandchars=\\\{\}]
*yData\PYGZus{}SCOV
\PYGZsh{} mH      err    syst   sqrt(cov)
124.51   0.52    0.06
125.60   0.40    0.20   0.06
125.98   0.42    0.28   0.   0.
124.70   0.31    0.15   0.   0.  0.15
\end{Verbatim}

A second possibility is specifying the full covariance matrix directly.
This is achieved using the \code{*xData\_COV} and \code{*yData\_COV} keywords.
In this case, only the data values and the uncorrelated uncertainties
(first and second columns, respectively) must be specified in addition
to the covariance matrix (all other columns). All entries starting with
the third column are assumed to be covariance matrix elements. The
matrix is symmetric, so elements above the diagonal are omitted. Note
that the diagonal must be specified and corresponds to the squares of
the correlated errors:

\begin{Verbatim}[commandchars=\\\{\}]
*yData\PYGZus{}COV
\PYGZsh{} mH      err    cov\PYGZus{}ij
124.51   0.52    0.0036
125.60   0.40    0.0036  0.04
125.98   0.42    0.      0.    0.0784
124.70   0.31    0.      0.    0.0225  0.0225
\end{Verbatim}

\textbf{Specifying additional uncertainties}

In addition to the uncertainties already specified in the
{\hyperref[module_doc:specifying-input-data]{\emph{\DUspan{}{input data table}}}} (\autopageref*{module_doc:specifying-input-data}), other systematic
uncertainties may be provided. These are assumed be fully correlated and
common to all data points. This can be achieved by using the following
keys:
\begin{quote}

\begin{tabulary}{\linewidth}{|L|L|}
\hline
\textsf{\relax 
\textbf{Key}
} & \textsf{\relax 
\textbf{Description}
}\\
\hline
\code{*xAbsCor}
 & 
common fully correlated x-uncertainty (absolute)
\\
\hline
\code{*yAbsCor}
 & 
common fully correlated y-uncertainty (absolute)
\\
\hline
\code{*xRelCor}
 & 
common fully correlated x-uncertainty (relative)
\\
\hline
\code{*yRelCor}
 & 
common fully correlated y-uncertainty (relative)
\\
\hline\end{tabulary}

\end{quote}

\textbf{Specifying a fit function}

To specify the fit function, the key \code{*FitFunction} is provided. This
key should be followed by \emph{Python} code:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k}{def} \PYG{n+nf}{fitf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{)}\PYG{p}{:}
    \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
    \PYG{k}{return} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{Verbatim}

\begin{notice}{note}{Note:}
Only one Python function may be defined after the \code{*FitFunction}
keyword. Also, any function name can be used instead of \code{fitf}.

Additionally, the decorators \code{@ASCII}, \code{@LaTeX} and
\code{@FitFunction} are supported (see
{\hyperref[module_doc:kafe.function_tools.ASCII]{\emph{\code{ASCII}}}} (\autopageref*{module_doc:kafe.function_tools.ASCII}),
{\hyperref[module_doc:kafe.function_tools.LaTeX]{\emph{\code{LaTeX}}}} (\autopageref*{module_doc:kafe.function_tools.LaTeX}) and
{\hyperref[module_doc:kafe.function_tools.FitFunction]{\emph{\code{FitFunction}}}} (\autopageref*{module_doc:kafe.function_tools.FitFunction}))
\end{notice}

\textbf{Specifying initial values for parameters}

Initial values for fit parameters may be set using the keyword
\code{*InitialParameters}. This keyword expects to be followed by a table
with two columns containing floating-point values.

Each line in the table corresponds to one fit parameter, in the order
they are given in the fit function signature. The first column should
contain the initial value of the parameters and the second column the
``initial uncertainty'', which controls the initial variation range of
the parameter at the beginning of the fit:

\begin{Verbatim}[commandchars=\\\{\}]
*InitialParameters
\PYGZlt{}initial value par 1\PYGZgt{}  \PYGZlt{}initial uncert par 1\PYGZgt{}
\PYGZlt{}initial value par 2\PYGZgt{}  \PYGZlt{}initial uncert par 2\PYGZgt{}
...
\PYGZlt{}initial value par N\PYGZgt{}  \PYGZlt{}initial uncert par N\PYGZgt{}
\end{Verbatim}

\textbf{Constraining parameters}

If there is any prior knowledge about model parameters' values on
uncertainties, these may be constrained during the fit.

During the fit, model parameters can be constrained within their
uncertainties if there is any prior knowledge about their values and
uncertainties.

This may be specified using the keyword \code{*ConstrainedParameters}, followed
by a table containing the parameter name, value and uncertainty for each parameter
to be constrained:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZlt{}parameter name\PYGZgt{}  \PYGZlt{}parameter value\PYGZgt{}  \PYGZlt{}parameter uncert.\PYGZgt{},
\end{Verbatim}

\begin{notice}{note}{Note:}
The parameter name must be the one specified in the fit function definition.
\end{notice}

\textbf{Example}

Here is an example of an input file to calculate the average of four
partly correlated measurements (see {\hyperref[examples:example-8]{\emph{\DUspan{}{Example 8}}}} (\autopageref*{examples:example-8})):

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZsh{}  Meta data for plotting
*TITLE Higgs\PYGZhy{}mass measurements
*xLabel number of measurement
*yLabel \PYGZdl{}m\PYGZus{}\PYGZbs{}mathrm\PYGZob{}H\PYGZcb{}\PYGZdl{}
*yUnit GeV/\PYGZdl{}c\PYGZca{}2\PYGZdl{}

\PYGZsh{}*xData  \PYGZsh{} commented out, as not needed for simple average

*yData\PYGZus{}SCOV  \PYGZsh{} assume that minimum of syst. errors is a common error
\PYGZsh{} mH      err     syst as sqrt(cov)
124.51   0.52    0.06
125.60   0.40    0.20  0.06
125.98   0.42    0.28  0.   0.
124.70   0.31    0.15  0.   0.  0.15

*FitFunction  \PYGZsh{} Python code of fit function

\PYGZsh{}  kafe fit function decorators are supported
@ASCII(expression=\PYGZsq{}av\PYGZsq{})
@LaTeX(name=\PYGZsq{}f\PYGZsq{}, parameter\PYGZus{}names=(\PYGZsq{}av\PYGZsq{}), expression=\PYGZsq{}av\PYGZsq{})
@FitFunction
def fitf(x, av=1.0): \PYGZsh{} fit an average
    return av

*FITLABEL Average

*InitialParameters
120. 1.
\end{Verbatim}

\end{fulllineitems}



\subsection{For specifying and decorating fit functions (\texttt{kafe.function\_tools})}
\label{module_doc:module-kafe.function_tools}\label{module_doc:for-specifying-and-decorating-fit-functions-kafe-function-tools}\index{kafe.function\_tools (module)}\phantomsection\label{module_doc:module-function_tools}\index{function\_tools (module)}\index{ASCII() (in module kafe.function\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.ASCII}\pysiglinewithargsret{\code{kafe.function\_tools.}\bfcode{ASCII}}{\emph{**kwargs}}{}
Optional decorator for fit functions. This overrides a FitFunction's
plain-text (ASCII) attributes. The new values for these attributes must be
passed as keyword arguments to the decorator. Possible arguments:
\begin{description}
\item[{\emph{name}}] \leavevmode{[}string{]}
Plain-text representation of the function name.

\item[{\emph{parameter\_names}}] \leavevmode{[}list of strings{]}
List of plain-text representations of the function's arguments.
The length of this list must be equal to the function's argument
number. The argument names should be in the same order as in the
function definition.

\item[{\emph{x\_name}}] \leavevmode{[}string{]}
Plain-text representation of the independent variable's name.

\item[{\emph{expression}}] \leavevmode{[}string{]}
Plain-text-formatted expression representing the
function's formula.

\end{description}

\end{fulllineitems}

\index{FitFunction (class in kafe.function\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction}\pysiglinewithargsret{\strong{class }\code{kafe.function\_tools.}\bfcode{FitFunction}}{\emph{f}}{}
Decorator class for fit functions. If a function definition is decorated
using this class, some information is collected about the function which
is relevant to the fitting process, such as the number of parameters,
their names and default values. Some details pertaining to display and
representation are also set, such as \(LaTeX\) representations of
the parameter names and the function name. Other decorators can be applied
to a function object to specify things such as a \(LaTeX\) or
plain-text expression for the fit function.
\index{derive\_by\_parameters() (kafe.function\_tools.FitFunction method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.derive_by_parameters}\pysiglinewithargsret{\bfcode{derive\_by\_parameters}}{\emph{x\_0}, \emph{precision\_spec}, \emph{parameter\_list}}{}
Returns the gradient of \emph{func} with respect to its parameters, i.e.
with respect to every variable of \emph{func} except the first one.
\begin{description}
\item[{\textbf{precision\_spec}}] \leavevmode{[}\code{float} or iterable of \code{floats}{]}
An array of floats indicating the initial point spacing for
numerically evaluating the derivative. Can be a single float
value to use the same spacing for every derivation.

\end{description}

\end{fulllineitems}

\index{derive\_by\_x() (kafe.function\_tools.FitFunction method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.derive_by_x}\pysiglinewithargsret{\bfcode{derive\_by\_x}}{\emph{x\_0}, \emph{precision\_list}, \emph{parameter\_list}}{}
If \emph{x\_0} is iterable, gives the array of derivatives of a function
\(f(x, par_1, par_2, \ldots)\) around \(x = x_i\) at every
\(x_i\) in \(\vec{x}\). If \emph{x\_0} is not iterable, gives the
derivative of a function \(f(x, par_1, par_2, \ldots)\) around
\(x = \verb!x_0!\).

\end{fulllineitems}

\index{evaluate() (kafe.function\_tools.FitFunction method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.evaluate}\pysiglinewithargsret{\bfcode{evaluate}}{\emph{x\_0}, \emph{parameter\_list}}{}
Evaluate the fit function at an x-value or at an array of
x-values for the parameter values in \emph{prarameter\_list}.
\begin{quote}

\textbf{x\_0} float or array of floats

\textbf{parameter\_list} values of function parameters

\textbf{returns} function value(s)
\end{quote}

\end{fulllineitems}

\index{expression (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.expression}\pysigline{\bfcode{expression}\strong{ = None}}
a math expression (string) representing the function's result

\end{fulllineitems}

\index{get\_function\_equation() (kafe.function\_tools.FitFunction method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.get_function_equation}\pysiglinewithargsret{\bfcode{get\_function\_equation}}{\emph{equation\_format='latex'}, \emph{equation\_type='full'}, \emph{ensuremath=True}}{}
Returns a string representing the function equation. Supported formats
are \(LaTeX\) and ASCII inline math. Note that \(LaTeX\)
math is wrapped by default in an \code{\textbackslash{}ensuremath\{\}} expression. If this
is not desired behaviour, the flag \code{ensuremath} can be set to
\code{False}.
\begin{description}
\item[{\emph{equation\_format}}] \leavevmode{[}string (optional){]}
Can be either ``latex'' (default) or ``ascii''.

\item[{\emph{equation\_type}}] \leavevmode{[}string (optional){]}
Can be either ``full'' (default), ``short'' or ``name''. A ``name''-type
equation returns a representation of the function name:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{f}
\end{Verbatim}

A ``short''-type equation limits itself to the function name and
variables:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{par1}\PYG{p}{,} \PYG{n}{par2}\PYG{p}{)}
\end{Verbatim}

A ``full''-type equation includes the expression which the function
calculates:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{f}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{par1}\PYG{p}{,} \PYG{n}{par2}\PYG{p}{)} \PYG{o}{=} \PYG{n}{par1} \PYG{o}{*} \PYG{n}{x} \PYG{o}{+} \PYG{n}{par2}
\end{Verbatim}

\item[{\emph{ensuremath}}] \leavevmode{[}boolean (optional){]}
If a \(LaTeX\) math equation is requested, \code{True}
(default) will wrap the resulting expression in an
\code{\textbackslash{}ensuremath\{\}} tag. Otherwise, no wrapping is done.

\end{description}

\end{fulllineitems}

\index{latex\_expression (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.latex_expression}\pysigline{\bfcode{latex\_expression}\strong{ = None}}
a \(LaTeX\) math expression, the function's result

\end{fulllineitems}

\index{latex\_name (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.latex_name}\pysigline{\bfcode{latex\_name}\strong{ = None}}
The function's name in \(LaTeX\)

\end{fulllineitems}

\index{latex\_parameter\_names (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.latex_parameter_names}\pysigline{\bfcode{latex\_parameter\_names}\strong{ = None}}
A list of parameter names in \(LaTeX\)

\end{fulllineitems}

\index{latex\_x\_name (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.latex_x_name}\pysigline{\bfcode{latex\_x\_name}\strong{ = None}}
A \(LaTeX\) symbol for the independent variable.

\end{fulllineitems}

\index{name (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.name}\pysigline{\bfcode{name}\strong{ = None}}
The name of the function

\end{fulllineitems}

\index{number\_of\_parameters (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.number_of_parameters}\pysigline{\bfcode{number\_of\_parameters}\strong{ = None}}
The number of parameters

\end{fulllineitems}

\index{parameter\_defaults (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.parameter_defaults}\pysigline{\bfcode{parameter\_defaults}\strong{ = None}}
The default values of the parameters

\end{fulllineitems}

\index{parameter\_names (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.parameter_names}\pysigline{\bfcode{parameter\_names}\strong{ = None}}
The names of the parameters

\end{fulllineitems}

\index{x\_name (kafe.function\_tools.FitFunction attribute)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.FitFunction.x_name}\pysigline{\bfcode{x\_name}\strong{ = None}}
The name given to the independent variable

\end{fulllineitems}


\end{fulllineitems}

\index{LaTeX() (in module kafe.function\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.LaTeX}\pysiglinewithargsret{\code{kafe.function\_tools.}\bfcode{LaTeX}}{\emph{**kwargs}}{}
Optional decorator for fit functions. This overrides a FitFunction's
\emph{latex\_} attributes. The new values for the \emph{latex\_} attributes must be
passed as keyword arguments to the decorator. Possible arguments:
\begin{description}
\item[{\emph{name}}] \leavevmode{[}string{]}
\(LaTeX\) representation of the function name.

\item[{\emph{parameter\_names}}] \leavevmode{[}list of strings{]}
List of \(LaTeX\) representations of the function's arguments.
The length of this list must be equal to the function's argument
number. The argument names should be in the same order as in the
function definition.

\item[{\emph{x\_name}}] \leavevmode{[}string{]}
\(LaTeX\) representation of the independent variable's name.

\item[{\emph{expression}}] \leavevmode{[}string{]}
\(LaTeX\)-formatted expression representing the
function's formula.

\end{description}

\end{fulllineitems}

\index{derivative() (in module kafe.function\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.derivative}\pysiglinewithargsret{\code{kafe.function\_tools.}\bfcode{derivative}}{\emph{func}, \emph{derive\_by\_index}, \emph{variables\_tuple}, \emph{derivative\_spacing}}{}
Gives \(\frac{\partial f}{\partial x_k}\) for \(f = f(x_0, x_1,
\ldots)\). \emph{func} is \(f\), \emph{variables\_tuple} is \(\{x_i\}\) and
\emph{derive\_by\_index} is \(k\).

\end{fulllineitems}

\index{outer\_product() (in module kafe.function\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.function_tools.outer_product}\pysiglinewithargsret{\code{kafe.function\_tools.}\bfcode{outer\_product}}{\emph{input\_array}}{}
Takes a \emph{NumPy} array and returns the outer (dyadic, Kronecker) product
with itself. If \emph{input\_array} is a vector \(\mathbf{x}\), this returns
\(\mathbf{x}\mathbf{x}^T\).

\end{fulllineitems}



\subsection{For working with LaTeX strings (\texttt{kafe.latex\_tools})}
\label{module_doc:for-working-with-latex-strings-kafe-latex-tools}\label{module_doc:module-kafe.latex_tools}\index{kafe.latex\_tools (module)}\phantomsection\label{module_doc:module-latex_tools}\index{latex\_tools (module)}\index{ascii\_to\_latex\_math() (in module kafe.latex\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.latex_tools.ascii_to_latex_math}\pysiglinewithargsret{\code{kafe.latex\_tools.}\bfcode{ascii\_to\_latex\_math}}{\emph{str\_ascii}, \emph{monospace=True}, \emph{ensuremath=True}}{}
Escapes certain characters in an ASCII input string so that the result
can be included in math mode without error.
\begin{description}
\item[{\textbf{str\_ascii}}] \leavevmode{[}string{]}
A plain-text string containing characters to be escaped for
\(LaTeX\) math mode.

\item[{\emph{monospace}}] \leavevmode{[}boolean (optional){]}
Whether to render the whole expression as monospace. Defaults to
\code{True}.

\item[{\emph{ensuremath}}] \leavevmode{[}boolean (optional){]}
If this is \code{True}, the resulting formula is wrapped in
an \code{\textbackslash{}ensuremath\{\}} tag. Defaults to \code{True}.

\end{description}

\end{fulllineitems}



\subsection{For routine numeric tasks (\texttt{kafe.numeric\_tools})}
\label{module_doc:module-kafe.numeric_tools}\label{module_doc:for-routine-numeric-tasks-kafe-numeric-tools}\index{kafe.numeric\_tools (module)}\phantomsection\label{module_doc:module-numeric_tools}\index{numeric\_tools (module)}\index{MinuitCov\_to\_cor() (in module kafe.numeric\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.numeric_tools.MinuitCov_to_cor}\pysiglinewithargsret{\code{kafe.numeric\_tools.}\bfcode{MinuitCov\_to\_cor}}{\emph{cov\_mat}}{}
Converts a covariance matrix as returned by Minuit to the
corresponding correlation matrix; note that the Minuit
covariance matrix may contain lines/rows with zeroes if
parameters are fixed
\begin{description}
\item[{\textbf{cov\_mat}}] \leavevmode{[}\emph{numpy.matrix}{]}
The Minuit covariance matrix to convert.

\end{description}

\end{fulllineitems}

\index{cor\_to\_cov() (in module kafe.numeric\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.numeric_tools.cor_to_cov}\pysiglinewithargsret{\code{kafe.numeric\_tools.}\bfcode{cor\_to\_cov}}{\emph{cor\_mat}, \emph{error\_list}}{}
Converts a correlation matrix to a covariance matrix according to the
formula
\begin{gather}
\begin{split}\text{Cov}_{ij} = \text{Cor}_{ij}\, \sigma_i \, \sigma_j\end{split}\notag
\end{gather}\begin{description}
\item[{\textbf{cor\_mat}}] \leavevmode{[}\emph{numpy.matrix}{]}
The correlation matrix to convert.

\item[{\textbf{error\_list}}] \leavevmode{[}sequence of floats{]}
A sequence of statistical errors. Must be of the same length
as the diagonal of \emph{cor\_mat}.

\end{description}

\end{fulllineitems}

\index{cov\_to\_cor() (in module kafe.numeric\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.numeric_tools.cov_to_cor}\pysiglinewithargsret{\code{kafe.numeric\_tools.}\bfcode{cov\_to\_cor}}{\emph{cov\_mat}}{}
Converts a covariance matrix to a correlation matrix according to the
formula
\begin{gather}
\begin{split}\text{Cor}_{ij} = \frac{\text{Cov}_{ij}}
    {\sqrt{ \text{Cov}_{ii}\,\text{Cov}_{jj}}}\end{split}\notag
\end{gather}\begin{description}
\item[{\textbf{cov\_mat}}] \leavevmode{[}\emph{numpy.matrix}{]}
The covariance matrix to convert.

\end{description}

\end{fulllineitems}

\index{extract\_statistical\_errors() (in module kafe.numeric\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.numeric_tools.extract_statistical_errors}\pysiglinewithargsret{\code{kafe.numeric\_tools.}\bfcode{extract\_statistical\_errors}}{\emph{cov\_mat}}{}
Extracts the statistical errors from a covariance matrix. This means
it returns the (elementwise) square root of the diagonal entries
\begin{description}
\item[{\textbf{cov\_mat}}] \leavevmode
The covariance matrix to extract errors from. Type: \emph{numpy.matrix}

\end{description}

\end{fulllineitems}

\index{make\_symmetric\_lower() (in module kafe.numeric\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.numeric_tools.make_symmetric_lower}\pysiglinewithargsret{\code{kafe.numeric\_tools.}\bfcode{make\_symmetric\_lower}}{\emph{mat}}{}
Copies the matrix entries below the main diagonal to the upper triangle
half of the matrix. Leaves the diagonal unchanged. Returns a \emph{NumPy} matrix
object.
\begin{description}
\item[{\textbf{mat}}] \leavevmode{[}\emph{numpy.matrix}{]}
A lower diagonal matrix.

\item[{returns}] \leavevmode{[}\emph{numpy.matrix}{]}
The lower triangle matrix.

\end{description}

\end{fulllineitems}

\index{zero\_pad\_lower\_triangle() (in module kafe.numeric\_tools)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.numeric_tools.zero_pad_lower_triangle}\pysiglinewithargsret{\code{kafe.numeric\_tools.}\bfcode{zero\_pad\_lower\_triangle}}{\emph{triangle\_list}}{}
Converts a list of lists into a lower triangle matrix. The list members
should be lists of increasing length from 1 to N, N being the dimension of
the resulting lower triangle matrix. Returns a \emph{NumPy} matrix object.

For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\PYGZgt{}\PYGZgt{}\PYGZgt{} }\PYG{n}{zero\PYGZus{}pad\PYGZus{}lower\PYGZus{}triangle}\PYG{p}{(}\PYG{p}{[} \PYG{p}{[}\PYG{l+m+mf}{1.0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{0.2}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{]}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mf}{0.01}\PYG{p}{,} \PYG{l+m+mf}{0.4}\PYG{p}{,} \PYG{l+m+mf}{3.0}\PYG{p}{]} \PYG{p}{]}\PYG{p}{)}
\PYG{g+go}{matrix([[ 1.  ,  0.  ,  0.  ],}
\PYG{g+go}{        [ 0.2 ,  1.  ,  0.  ],}
\PYG{g+go}{        [ 0.01,  0.4 ,  3.  ]])}
\end{Verbatim}
\begin{description}
\item[{\textbf{triangle\_list}}] \leavevmode{[}list{]}
A list containing lists of increasing length.

\item[{returns}] \leavevmode{[}\emph{numpy.matrix}{]}
The lower triangle matrix.

\end{description}

\end{fulllineitems}



\section{Auxilliary modules}
\label{module_doc:auxilliary-modules}

\subsection{Collection of ready-to-use fit functions (\texttt{kafe.function\_library})}
\label{module_doc:module-kafe.function_library}\label{module_doc:collection-of-ready-to-use-fit-functions-kafe-function-library}\index{kafe.function\_library (module)}\phantomsection\label{module_doc:module-function_library}\index{function\_library (module)}
Collection of model functions


\subsection{File/stream manipulation (\texttt{kafe.stream})}
\label{module_doc:file-stream-manipulation-kafe-stream}\label{module_doc:module-kafe.stream}\index{kafe.stream (module)}\phantomsection\label{module_doc:module-stream}\index{stream (module)}\index{StreamDup (class in kafe.stream)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup}\pysiglinewithargsret{\strong{class }\code{kafe.stream.}\bfcode{StreamDup}}{\emph{out\_file}, \emph{suppress\_stdout=False}}{}
Bases: \code{object}

Object for simultaneous logging to stdout and files.
This object provides a file/like object for the outout to be written to.
Writing to this object will write to stdout (usually the console) and to
a file.
\begin{description}
\item[{\textbf{out\_file}}] \leavevmode{[}file path or file-like object or list of file paths ...{]}
File(s) to which to log the output, along with stdout. If a file exists
on disk, it will be appended to.

\item[{\emph{suppress\_stdout}}] \leavevmode{[}boolean{]}
Whether to log to stdout simultaneously (\code{False}) or suppress output
to stdout (\code{True}). Default to \code{False}.

\end{description}
\index{fileno() (kafe.stream.StreamDup method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup.fileno}\pysiglinewithargsret{\bfcode{fileno}}{}{}
Returns the file handler id of the main (first) output file.

\end{fulllineitems}

\index{flush() (kafe.stream.StreamDup method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup.flush}\pysiglinewithargsret{\bfcode{flush}}{}{}
\end{fulllineitems}

\index{write() (kafe.stream.StreamDup method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup.write}\pysiglinewithargsret{\bfcode{write}}{\emph{message}}{}
\end{fulllineitems}

\index{write\_timestamp() (kafe.stream.StreamDup method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup.write_timestamp}\pysiglinewithargsret{\bfcode{write\_timestamp}}{\emph{prefix}}{}
\end{fulllineitems}

\index{write\_to\_file() (kafe.stream.StreamDup method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup.write_to_file}\pysiglinewithargsret{\bfcode{write\_to\_file}}{\emph{message}}{}
\end{fulllineitems}

\index{write\_to\_stdout() (kafe.stream.StreamDup method)}

\begin{fulllineitems}
\phantomsection\label{module_doc:kafe.stream.StreamDup.write_to_stdout}\pysiglinewithargsret{\bfcode{write\_to\_stdout}}{\emph{message}, \emph{check\_if\_suppressed=False}}{}
Explicitly write to stdout. This method will not check by default
whether \code{suppress\_stdout} is set for this \emph{StreamDup}. If
\code{check\_if\_suppressed} is explicitly set to \code{True}, then this
check occurs.

\end{fulllineitems}


\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{c}
\item {\texttt{config}} \emph{(Unix)}, \pageref{module_doc:module-config}
\indexspace
\bigletter{d}
\item {\texttt{dataset}} \emph{(Unix)}, \pageref{module_doc:module-dataset}
\item {\texttt{dataset\_tools}} \emph{(Unix)}, \pageref{module_doc:module-dataset_tools}
\indexspace
\bigletter{f}
\item {\texttt{file\_tools}} \emph{(Unix)}, \pageref{module_doc:module-file_tools}
\item {\texttt{fit}} \emph{(Unix)}, \pageref{module_doc:module-fit}
\item {\texttt{function\_library}} \emph{(Unix)}, \pageref{module_doc:module-function_library}
\item {\texttt{function\_tools}} \emph{(Unix)}, \pageref{module_doc:module-function_tools}
\indexspace
\bigletter{i}
\item {\texttt{iminuit}} \emph{(Unix)}, \pageref{module_doc:module-iminuit}
\indexspace
\bigletter{k}
\item {\texttt{kafe.\_\_init\_\_}}, \pageref{module_doc:module-kafe.__init__}
\item {\texttt{kafe.config}}, \pageref{module_doc:module-kafe.config}
\item {\texttt{kafe.dataset}}, \pageref{module_doc:module-kafe.dataset}
\item {\texttt{kafe.dataset\_tools}}, \pageref{module_doc:module-kafe.dataset_tools}
\item {\texttt{kafe.file\_tools}}, \pageref{module_doc:module-kafe.file_tools}
\item {\texttt{kafe.fit}}, \pageref{module_doc:module-kafe.fit}
\item {\texttt{kafe.function\_library}}, \pageref{module_doc:module-kafe.function_library}
\item {\texttt{kafe.function\_tools}}, \pageref{module_doc:module-kafe.function_tools}
\item {\texttt{kafe.iminuit\_wrapper}}, \pageref{module_doc:module-kafe.iminuit_wrapper}
\item {\texttt{kafe.latex\_tools}}, \pageref{module_doc:module-kafe.latex_tools}
\item {\texttt{kafe.minuit}}, \pageref{module_doc:module-kafe.minuit}
\item {\texttt{kafe.numeric\_tools}}, \pageref{module_doc:module-kafe.numeric_tools}
\item {\texttt{kafe.plot}}, \pageref{module_doc:module-kafe.plot}
\item {\texttt{kafe.stream}}, \pageref{module_doc:module-kafe.stream}
\indexspace
\bigletter{l}
\item {\texttt{latex\_tools}} \emph{(Unix)}, \pageref{module_doc:module-latex_tools}
\indexspace
\bigletter{m}
\item {\texttt{minuit}} \emph{(Unix)}, \pageref{module_doc:module-minuit}
\indexspace
\bigletter{n}
\item {\texttt{numeric\_tools}} \emph{(Unix)}, \pageref{module_doc:module-numeric_tools}
\indexspace
\bigletter{p}
\item {\texttt{plot}} \emph{(Unix)}, \pageref{module_doc:module-plot}
\indexspace
\bigletter{s}
\item {\texttt{stream}} \emph{(Unix)}, \pageref{module_doc:module-stream}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
